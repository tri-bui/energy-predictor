{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Energy Predictor - Featurization\n",
    "#### Hosted by: ASHRAE\n",
    "##### Source: https://www.kaggle.com/c/ashrae-energy-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section I: Dependencies and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import gc\n",
    "import holidays\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from feature_engine.encoding import RareLabelEncoder, MeanEncoder, OrdinalEncoder\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import f_regression, RFE, SelectFromModel, SelectKBest, SelectPercentile\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "import src.utils as udf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "# Plot settings\n",
    "mpl.style.use('seaborn')\n",
    "mpl.rcParams['figure.figsize'] = (15, 3)\n",
    "mpl.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/02-prep-out'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data path\n",
    "data_path = os.path.join('..', 'data', '02-prep-out')\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18205342 entries, 72 to 20216099\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   building_id    uint16        \n",
      " 1   meter          uint8         \n",
      " 2   timestamp      datetime64[ns]\n",
      " 3   meter_reading  float32       \n",
      " 4   site_id        uint8         \n",
      " 5   meter_type     object        \n",
      " 6   dayofyear      uint16        \n",
      " 7   month          uint8         \n",
      " 8   day            uint8         \n",
      " 9   dayofweek      uint8         \n",
      " 10  hour           uint8         \n",
      "dtypes: datetime64[ns](1), float32(1), object(1), uint16(2), uint8(6)\n",
      "memory usage: 659.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Meter data\n",
    "meter = pd.read_pickle(os.path.join(data_path, 'meter.pkl'))\n",
    "meter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140544 entries, 0 to 140543\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   site_id             140544 non-null  uint8         \n",
      " 1   timestamp           140544 non-null  datetime64[ns]\n",
      " 2   air_temperature     140544 non-null  float32       \n",
      " 3   dew_temperature     140544 non-null  float32       \n",
      " 4   sea_level_pressure  140544 non-null  float32       \n",
      " 5   wind_direction      140544 non-null  uint16        \n",
      " 6   wind_speed          140544 non-null  float32       \n",
      "dtypes: datetime64[ns](1), float32(4), uint16(1), uint8(1)\n",
      "memory usage: 3.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Weather data\n",
    "weather = pd.read_pickle(os.path.join(data_path, 'weather.pkl'))\n",
    "weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1449 entries, 0 to 1448\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   site_id       1449 non-null   uint8 \n",
      " 1   building_id   1449 non-null   uint16\n",
      " 2   primary_use   1449 non-null   object\n",
      " 3   square_feet   1449 non-null   uint32\n",
      " 4   year_built    1449 non-null   uint16\n",
      " 5   missing_year  1449 non-null   uint8 \n",
      "dtypes: object(1), uint16(2), uint32(1), uint8(2)\n",
      "memory usage: 25.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Building data\n",
    "building = pd.read_pickle(os.path.join(data_path, 'building.pkl'))\n",
    "building.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean vars\n",
    "del data_path\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section II: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert `wind_direction` to Cartesian components\n",
    "\n",
    "In the weather data, the `wind_direction` was recorded as a compass direction, which is in the polar coordinate system. This won't work in the context of machine learning because the numeric values imply that this feature has an ordinal nature, and that's simply not true. A direction of 300 degrees is not more than a direction of 100 degrees; it's just in a different direction.\n",
    "\n",
    "In order for machine learning models to be able to interpret `wind_direction` correctly, it needs to be using Cartesian coordinates. We will make this conversion by extracting the x and y components of the direction values, which together would describe the `wind_direction`.\n",
    "\n",
    "Note: `wind_direction` contains both values of 0 and 360, which are the same direction. But in this case, a `wind_direction` of 0 just means that there was no wind, as evident by the 0 `wind_speed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction_x</th>\n",
       "      <th>wind_direction_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.4</td>\n",
       "      <td>1019.400024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>21.1</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1019.400024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>21.1</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1018.799988</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_id           timestamp  air_temperature  dew_temperature  \\\n",
       "0        0 2016-01-01 00:00:00             19.4             19.4   \n",
       "1        0 2016-01-01 01:00:00             21.1             21.1   \n",
       "2        0 2016-01-01 02:00:00             21.1             21.1   \n",
       "\n",
       "   sea_level_pressure  wind_speed  wind_direction_x  wind_direction_y  \n",
       "0         1019.400024         0.0          0.000000               0.0  \n",
       "1         1019.400024         0.0          0.000000               0.0  \n",
       "2         1018.799988         1.5         -0.866025              -0.5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract x and y components from wind direction\n",
    "weather = udf.polar_to_cartesian(weather, 'wind_direction')\n",
    "weather.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new feature for relative humidity\n",
    "\n",
    "The weather data contains both `air_temperature` and `dew_temperature`, which are highly correlated. Relative humidity is a weather feature that can be calculated using both `air_temperature` and `dew_temperature`. Relative humidity may effectively replace both by incorporating the information from both features and eliminating the multicollinearity. The calculation for this new feature follows the source below.\n",
    "\n",
    "We won't be dropping `air_temperature` and `dew_temperature` just yet because we don't actually know which feature will be the most useful in building machine learning models until actually building them.\n",
    "\n",
    "Source: https://www.weather.gov/media/epz/wxcalc/vaporPressure.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction_x</th>\n",
       "      <th>wind_direction_y</th>\n",
       "      <th>rel_humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>140544.000000</td>\n",
       "      <td>140544.000000</td>\n",
       "      <td>140544.000000</td>\n",
       "      <td>140544.000000</td>\n",
       "      <td>140544.000000</td>\n",
       "      <td>140544.000000</td>\n",
       "      <td>1.405440e+05</td>\n",
       "      <td>140544.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>14.356584</td>\n",
       "      <td>7.297376</td>\n",
       "      <td>1016.131287</td>\n",
       "      <td>3.562700</td>\n",
       "      <td>-0.037601</td>\n",
       "      <td>-9.005360e-02</td>\n",
       "      <td>67.503700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.609789</td>\n",
       "      <td>10.669369</td>\n",
       "      <td>9.826284</td>\n",
       "      <td>7.883689</td>\n",
       "      <td>2.334334</td>\n",
       "      <td>0.663424</td>\n",
       "      <td>6.739621e-01</td>\n",
       "      <td>21.754589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-28.900000</td>\n",
       "      <td>-35.000000</td>\n",
       "      <td>968.200012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>3.751658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.750000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1011.599976</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>-0.642788</td>\n",
       "      <td>-7.660444e-01</td>\n",
       "      <td>52.516804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>1016.400024</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>71.740288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.250000</td>\n",
       "      <td>22.200001</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>1020.900024</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>85.883133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>47.200001</td>\n",
       "      <td>26.100000</td>\n",
       "      <td>1045.500000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>119.269371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             site_id  air_temperature  dew_temperature  sea_level_pressure  \\\n",
       "count  140544.000000    140544.000000    140544.000000       140544.000000   \n",
       "mean        7.500000        14.356584         7.297376         1016.131287   \n",
       "std         4.609789        10.669369         9.826284            7.883689   \n",
       "min         0.000000       -28.900000       -35.000000          968.200012   \n",
       "25%         3.750000         7.200000         0.600000         1011.599976   \n",
       "50%         7.500000        15.000000         8.200000         1016.400024   \n",
       "75%        11.250000        22.200001        14.400000         1020.900024   \n",
       "max        15.000000        47.200001        26.100000         1045.500000   \n",
       "\n",
       "          wind_speed  wind_direction_x  wind_direction_y   rel_humidity  \n",
       "count  140544.000000     140544.000000      1.405440e+05  140544.000000  \n",
       "mean        3.562700         -0.037601     -9.005360e-02      67.503700  \n",
       "std         2.334334          0.663424      6.739621e-01      21.754589  \n",
       "min         0.000000         -1.000000     -1.000000e+00       3.751658  \n",
       "25%         2.100000         -0.642788     -7.660444e-01      52.516804  \n",
       "50%         3.100000          0.000000     -2.449294e-16      71.740288  \n",
       "75%         5.000000          0.500000      5.000000e-01      85.883133  \n",
       "max        19.000000          1.000000      1.000000e+00     119.269371  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add feat for relative humidity\n",
    "weather['rel_humidity'] = udf.calc_rel_humidity(weather['air_temperature'], weather['dew_temperature'])\n",
    "weather.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a boolean indicator for weekends\n",
    "\n",
    "As seen in the EDA, there was a bit of difference in energy usage between weekdays and weekends for some buildings, especially with electricity meters. It would be useful to have a boolean feature that indicates whether the meter reading was during the weekend. We will create this weekend indicator by checking if the `dayofweek` is 5 (Saturday) or 6 (Sunday)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>site_id</th>\n",
       "      <th>meter_type</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20216096</th>\n",
       "      <td>1445</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 23:00:00</td>\n",
       "      <td>4.825000</td>\n",
       "      <td>15</td>\n",
       "      <td>electricity</td>\n",
       "      <td>366</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216098</th>\n",
       "      <td>1447</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 23:00:00</td>\n",
       "      <td>159.574997</td>\n",
       "      <td>15</td>\n",
       "      <td>electricity</td>\n",
       "      <td>366</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216099</th>\n",
       "      <td>1448</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 23:00:00</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>15</td>\n",
       "      <td>electricity</td>\n",
       "      <td>366</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          building_id  meter           timestamp  meter_reading  site_id  \\\n",
       "20216096         1445      0 2016-12-31 23:00:00       4.825000       15   \n",
       "20216098         1447      0 2016-12-31 23:00:00     159.574997       15   \n",
       "20216099         1448      0 2016-12-31 23:00:00       2.850000       15   \n",
       "\n",
       "           meter_type  dayofyear  month  day  dayofweek  hour  is_weekend  \n",
       "20216096  electricity        366     12   31          5    23           1  \n",
       "20216098  electricity        366     12   31          5    23           1  \n",
       "20216099  electricity        366     12   31          5    23           1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create weekend feat\n",
    "meter['is_weekend'] = meter['dayofweek'].apply(lambda d: int(d in [5, 6])).astype('uint8')\n",
    "meter.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a boolean indicator for holidays\n",
    "\n",
    "Just as with weekends, energy usage is likely different on holidays so we will create a boolean feature that indicates whether the meter reading was during a holiday. In order to do this, we must first label each site with its respective country in order to correctly identify which holidays to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>site_id</th>\n",
       "      <th>meter_type</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>12.603682</td>\n",
       "      <td>0</td>\n",
       "      <td>electricity</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>15.364478</td>\n",
       "      <td>0</td>\n",
       "      <td>electricity</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>23.303600</td>\n",
       "      <td>1</td>\n",
       "      <td>electricity</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     building_id  meter  timestamp  meter_reading  site_id   meter_type  \\\n",
       "72            74      0 2016-01-01      12.603682        0  electricity   \n",
       "91            93      0 2016-01-01      15.364478        0  electricity   \n",
       "103          105      0 2016-01-01      23.303600        1  electricity   \n",
       "\n",
       "     dayofyear  month  day  dayofweek  hour  is_weekend country  \n",
       "72           1      1    1          4     0           0      US  \n",
       "91           1      1    1          4     0           0      US  \n",
       "103          1      1    1          4     0           0      UK  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add country feat\n",
    "site_countries = {0: 'US', 1: 'UK', 2: 'US', 3: 'US', 4: 'US', 5: 'UK', 6: 'US', 7: 'CA', \n",
    "                  8: 'US', 9: 'US', 10: 'US', 11: 'CA', 12: 'IE', 13: 'US', 14: 'US', 15: 'US'}\n",
    "meter['country'] = meter.site_id.map(site_countries)\n",
    "meter.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Year's Day\n",
      "New Year's Day\n",
      "New Year's Day\n",
      "New Year's Day\n"
     ]
    }
   ],
   "source": [
    "# Holiday dates for each country\n",
    "US_holidays = holidays.UnitedStates()     # sites 0, 2, 3, 4, 6, 8, 9, 10, 13, 14, 15 \n",
    "CA_holidays = holidays.Canada()           # sites 7, 11\n",
    "UK_holidays = holidays.UnitedKingdom()    # sites 1, 5\n",
    "IE_holidays = holidays.Ireland()          # site 12\n",
    "\n",
    "# Initialize holiday year\n",
    "print(US_holidays['2016-01-01'])\n",
    "print(CA_holidays['2016-01-01'])\n",
    "print(UK_holidays['2016-01-01'])\n",
    "print(IE_holidays['2016-01-01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2016-07-12</td>\n",
       "      <td>UK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>IE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date country  is_holiday\n",
       "0   2016-01-01      US           1\n",
       "15  2016-07-01      CA           1\n",
       "30  2016-07-12      UK           1\n",
       "45  2016-12-27      IE           1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert holiday lists to dfs\n",
    "US_holiday_df = pd.DataFrame(zip(US_holidays.keys(), ['US'] * len(US_holidays), [1] * len(US_holidays)), \n",
    "                              columns=['date', 'country', 'is_holiday'])\n",
    "CA_holiday_df = pd.DataFrame(zip(CA_holidays.keys(), ['CA'] * len(CA_holidays), [1] * len(CA_holidays)), \n",
    "                              columns=['date', 'country', 'is_holiday'])\n",
    "UK_holiday_df = pd.DataFrame(zip(UK_holidays.keys(), ['UK'] * len(UK_holidays), [1] * len(UK_holidays)), \n",
    "                              columns=['date', 'country', 'is_holiday'])\n",
    "IE_holiday_df = pd.DataFrame(zip(IE_holidays.keys(), ['IE'] * len(IE_holidays), [1] * len(IE_holidays)), \n",
    "                              columns=['date', 'country', 'is_holiday'])\n",
    "\n",
    "# Concat holiday dfs\n",
    "holiday_df = pd.concat([US_holiday_df, CA_holiday_df, UK_holiday_df, IE_holiday_df]).reset_index(drop=True)\n",
    "holiday_df.loc[[0, 15, 30, 45]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync date cols in both dfs\n",
    "meter['date'] = meter['timestamp'].dt.date\n",
    "\n",
    "# Merge holiday feat into meter df\n",
    "meter = pd.merge(meter, holiday_df, on=['date', 'country'], how='left')\n",
    "meter['is_holiday'] = meter['is_holiday'].fillna(0).astype('int8')\n",
    "meter.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create holiday feat\n",
    "# meter['is_holiday'] = meter.apply(lambda r: r['timestamp'] in eval(r['country'] + '_holidays'), axis=1).astype('uint8')\n",
    "# meter.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group UK and IE into 1 label: EU\n",
    "\n",
    "Now that the `country` has been used to create the `is_holiday` feature, we can update it in a way that minimizes rare labels. Only 1 site is in Ireland, so Ireland will be grouped with the United Kingdom to make \"EU\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"UK\" and \"IE\" into \"EU\" in country\n",
    "meter['country'] = meter['country'].str.replace(r'UK|IE', 'EU')\n",
    "meter.country.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop `day` and `date`\n",
    "\n",
    "The `day` feature is being dropped because it will no longer be used. It is not as important to know what `day` of the month it is as to know what `dayofweek` or `dayoryear` it is. The `date` feature is also being dropped because it was only created for the holiday merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop day feat\n",
    "meter.drop(['day', 'date'], axis=1, inplace=True)\n",
    "meter.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean vars\n",
    "del site_countries, US_holidays, CA_holidays, UK_holidays, IE_holidays, \\\n",
    "    US_holiday_df, CA_holiday_df, UK_holiday_df, IE_holiday_df, holiday_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section III: Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new subdir in data dir\n",
    "output_dir = os.path.join('..', 'data', '03-feat-out')\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save meter data\n",
    "meter_path = os.path.join(output_dir, 'meter.pkl')\n",
    "meter.to_pickle(meter_path)\n",
    "pd.read_pickle(meter_path).info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weather data\n",
    "weather_path = os.path.join(output_dir, 'weather.pkl')\n",
    "weather.to_pickle(weather_path)\n",
    "pd.read_pickle(weather_path).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save building data\n",
    "building_path = os.path.join(output_dir, 'building.pkl')\n",
    "building.to_pickle(building_path)\n",
    "pd.read_pickle(building_path).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all 3 dataframes into 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge meter and building data\n",
    "metr_bldg = pd.merge(meter.drop('site_id', axis=1), building, on='building_id', how='left')\n",
    "metr_bldg.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add weather data to the merged data\n",
    "train = pd.merge(metr_bldg, weather, on=['site_id', 'timestamp'], how='left')\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder cols\n",
    "cols = ['site_id', 'building_id', 'meter', 'meter_type', 'timestamp', 'meter_reading', \n",
    "        'air_temperature', 'dew_temperature', 'rel_humidity', 'sea_level_pressure', \n",
    "        'wind_speed', 'wind_direction_x', 'wind_direction_y',  \n",
    "        'primary_use', 'square_feet', 'year_built', 'missing_year', 'country', \n",
    "        'dayofyear', 'month', 'hour', 'dayofweek', 'is_weekend', 'is_holiday']\n",
    "train = train[cols].copy()\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train set by meter type\n",
    "\n",
    "We saw in the EDA that different meter types had different usage patterns, so we will be splitting the dataset up into 4 parts (one for each meter type) and building a separate model for each meter type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split meter types into separate dfs\n",
    "train_dfs = dict()\n",
    "for m in ['electricity', 'chilledwater', 'steam', 'hotwater']:\n",
    "    train_df = train[train['meter_type'] == m].drop(['meter', 'meter_type'], axis=1).copy()\n",
    "    train_df.to_pickle(os.path.join(output_dir, m + '.pkl'))\n",
    "    train_dfs[m] = train_df\n",
    "    print(f'{m} meter: {train_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean vars\n",
    "del meter, meter_path, weather, weather_path, building, building_path, metr_bldg, cols, m, train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section IV: Feature Elimination - Electricity Meter\n",
    "\n",
    "As more than half of the data are meter readings from electricity meters, we will be looking at electricity meters. The processed used here will be followed for the other 3 meter types.\n",
    "\n",
    "Note: The letter \"e\" will be appended to variables to indicate that we are working with electricity meter data. For example, the variable data X will be called `Xe` and the target label y will be called `ye`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split - train, validation, test\n",
    "\n",
    "The data is being split into 3 sets:\n",
    "1. Training set - the machine learning model will be trained on this set\n",
    "2. Validation set - model performance will be evaluated on this set during model tuning\n",
    "3. Test set - this will be the holdout set for final testing once we have a finished model\n",
    "\n",
    "We are splitting the data before the model selection process to minimize data leakage, that is, information from the validation or test set leaking into the training data in any way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split feats and target for electricity meter data\n",
    "Xe = train_dfs['electricity'].drop('meter_reading', axis=1).copy()\n",
    "ye = train_dfs['electricity']['meter_reading'].copy()\n",
    "Xe.shape, ye.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/val/test split (70/12/18)\n",
    "Xe_train, Xe_test, ye_train, ye_test = train_test_split(Xe, ye, test_size=0.3, random_state=30)\n",
    "Xe_val, Xe_test, ye_val, ye_test = train_test_split(Xe_test, ye_test, test_size=0.6, random_state=30)\n",
    "\n",
    "print('Train set:', Xe_train.shape, ye_train.shape)\n",
    "print('Validation set:', Xe_val.shape, ye_val.shape)\n",
    "print('Test set:', Xe_test.shape, ye_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean vars\n",
    "del Xe, ye\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rare label categorical encoding\n",
    "The `primary_use` feature has a total of 16 categories, more than half of which would be considered \"rare\" in the data. That is, they occur less than a certain threshold (I will use the threshold 5%). This could be a problem for splitting the data because some rare labels may end up in the validation or test set, but not the training set. The model would not know what to do if it has never seen that label before.\n",
    "\n",
    "To resolve this issue, we will group all these rare categories (any categories with a count less than 5% of the total data) into 1 label called \"Rare\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect primary use categories\n",
    "udf.plot_rare_cats(Xe_train, 'primary_use')\n",
    "plt.title('Counts of Primary Use Categories')\n",
    "plt.ylabel('Number of meter readings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common categories (has at least 5% of all values)\n",
    "rarenc = RareLabelEncoder(tol=0.05, variables=['primary_use'])\n",
    "rarenc.fit(Xe_train)\n",
    "rarenc.encoder_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group rare categories together in all 3 sets\n",
    "Xe_train = rarenc.transform(Xe_train)\n",
    "Xe_val = rarenc.transform(Xe_val)\n",
    "Xe_test = rarenc.transform(Xe_test)\n",
    "\n",
    "Xe_train['primary_use'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean target categorical encoding\n",
    "\n",
    "The 2 categorical features (`primary_use` and `country`) still need to be encoded numerically. I will be using mean-target categorical encoding instead of one-hot encoding for 2 reasons:\n",
    "1. To avoid expanding the feature set\n",
    "2. The different categories showed differrent patterns in energy usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the mean target of each primary use and country category\n",
    "meanenc = MeanEncoder(variables=['primary_use', 'country'])\n",
    "meanenc.fit(Xe_train, ye_train)\n",
    "meanenc.encoder_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode primary_use and country using the target mean in both train and validation sets\n",
    "Xe_train = meanenc.transform(Xe_train)\n",
    "Xe_val = meanenc.transform(Xe_val)\n",
    "Xe_test = meanenc.transform(Xe_test)\n",
    "\n",
    "Xe_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dir paths for encoders\n",
    "transformer_path = os.path.join('..', 'models', 'transformers')\n",
    "rarenc_path = os.path.join(transformer_path, 'rare_enc')\n",
    "meanenc_path = os.path.join(transformer_path, 'mean_enc')\n",
    "\n",
    "# Create dirs\n",
    "os.makedirs(rarenc_path, exist_ok=True)\n",
    "os.makedirs(meanenc_path, exist_ok=True)\n",
    "\n",
    "# Save encoders\n",
    "joblib.dump(rarenc, os.path.join(rarenc_path, 'rare_enc0.pkl'))\n",
    "joblib.dump(meanenc, os.path.join(meanenc_path, 'mean_enc0.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature elimination\n",
    "\n",
    "To start off the feature selection process, we will be looking for the following redundant features to remove:\n",
    "1. Duplicated features - pairs of features that share the same value for all observations\n",
    "2. Constant features - features that only have 1 unique value\n",
    "3. Quasi-constant features - features that have 1 unique value for MOST of their observations (low variance)\n",
    "    - I will be using a variance threshold of 1%\n",
    "4. Correlated features - pairs of features with high linear correlation\n",
    "    - I will be using a correlation threshold of 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicated feats\n",
    "udf.duplicated_feats(Xe_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant and quasi-constant feats\n",
    "udf.constant_feats(Xe_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlated feats\n",
    "udf.correlated_feats(Xe_train.corr(), threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicated, constant, or even quasi-constant features. However, there are 4 pairs of correlated features here, all of which have a high correlation constant (much higher than the 0.5 threshold). Let's take a closer look at the feature correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feat correlation\n",
    "corr = Xe_train.corr()\n",
    "corr.style.applymap(lambda c: 'color: red; background-color: yellow' if 0.5 < abs(c) < 1 else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, cmap=sns.color_palette('Reds', 8))\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop timestamp and 1 of 2 feats from each correlated pair in all 3 sets\n",
    "to_drop = ['timestamp', 'building_id', 'dew_temperature', 'month', 'dayofweek']\n",
    "Xe_train.drop(to_drop, axis=1, inplace=True)\n",
    "Xe_val.drop(to_drop, axis=1, inplace=True)\n",
    "Xe_test.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "Xe_train.shape, Xe_val.shape, Xe_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean vars\n",
    "del rarenc_path, meanenc_path, corr, to_drop\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the 4 pairs of corrrelated features, the feature that was dropped is either harder to deal with, harder to understand, or just not as well-suited as the other feature. Features dropped:\n",
    "- `Building_id` - has much higher cardinality than `site_id`, which makes `site_id` easier to encode\n",
    "    - Even though `site_id` and `building_id` are numeric, there is no order to the values because these are categorical variables\n",
    "- `Dew_temperature` - tracks `air_temperature` closely, but is not as concrete conceptually as `air_temperature`\n",
    "- `Month` - not as fine-tuned as `dayofyear` values, so the model may have a hard time differentiating different days of a month\n",
    "- `Dayofweek` - not as important to know what day of the week it is as it is to just know whether that day was a weekday or weekend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section V: Feature Selection - Electricity Meter\n",
    "\n",
    "After eliminating redundant features, there are 16 remaining. We will be looking at several feature selection methods to get an idea of which of the 16 features will be the most important in predicting energy consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling\n",
    "\n",
    "The remaining features are on completely different scales, with boolean features consisting of either 0 or 1 and a feature like `square_feet` containing values in the order of 10 to the 6th power. The values need to be on the same scale so that some of the models (especially linear models) do not misinterpret the data. We will be normalizing the values of every feature with the standard scaling method, where each feature will have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale all feats using the mean and stdev\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(Xe_train)\n",
    "\n",
    "# Apply the scaler to all 3 sets\n",
    "Xe_train_scaled = pd.DataFrame(scaler.transform(Xe_train), columns=Xe_train.columns)\n",
    "Xe_val_scaled = pd.DataFrame(scaler.transform(Xe_val), columns=Xe_val.columns)\n",
    "Xe_test_scaled = pd.DataFrame(scaler.transform(Xe_test), columns=Xe_test.columns)\n",
    "\n",
    "Xe_train_scaled.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dir for scaler\n",
    "scaler_path = os.path.join(transformer_path, 'scaler')\n",
    "os.makedirs(scaler_path, exist_ok=True)\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, os.path.join(scaler_path, 'scaler0.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track how many times each feature is selected\n",
    "\n",
    "Since we are looking at several methods of selecting features, let's create a table to track the running total of how many times each feature is selected. The idea is that a feature would be a better predictor the more it is selected, and any feature with a count of 0 is probably not contributing very much in the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Df to track selection count\n",
    "feat_sel = pd.DataFrame([0] * Xe_train.shape[1], index=Xe_train.columns, columns=['count'])\n",
    "feat_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation with target\n",
    "\n",
    "To start off, let's check the linear correlation of each feature with the target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge target var into the feats\n",
    "e_train = pd.merge(Xe_train, ye_train, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# Feat correlation with target var\n",
    "e_corr = e_train.corr()\n",
    "e_corr['meter_reading'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation\n",
    "e_corr['meter_reading'].sort_values()[:-1].plot.barh(figsize=(15, 5), title='Feature Correlation with Target Variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the features have a really low correlation with the target. It looks like `square_feet` and `country` would be the best predictors if we were to use a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add feats with a correlation coef magnitude of at least 0.4\n",
    "corr_feats = e_corr[e_corr['meter_reading'].abs() >= 0.4].index[:-1].tolist()\n",
    "feat_sel = udf.inc_feat_count(feat_sel, corr_feats)\n",
    "feat_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean vars\n",
    "del transformer_path, scaler_path, e_train, e_corr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso regularization\n",
    "\n",
    "Lasso (L1) regularization is able to reduce feature coefficients to 0. This removes the less informative features from the model. Using this selection method, the remaining features are the ones that are \"selected\". We will be doing this 2 different ways:\n",
    "1. Select from model - select features with high coefficients\n",
    "2. Recursive feature eliminaton - recursively remove the feature with the lowest coefficient until half of the features remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select feats using L1 regularization\n",
    "l1_feats = udf.feats_from_model(Xe_train_scaled, ye_train, SelectFromModel, Lasso(alpha=10))\n",
    "l1_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select feats recursively using L1 regularization\n",
    "rfe_l1_feats = udf.feats_from_model(Xe_train_scaled, ye_train, RFE, Lasso(alpha=10))\n",
    "rfe_l1_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increment the counts for selected feats\n",
    "feat_sel = udf.inc_feat_count(feat_sel, l1_feats + rfe_l1_feats)\n",
    "feat_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from the 3 features that have the highest correlation with the target - `square_feet`, `country`, and `primary_use` - the day and time are also providing a lot of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree importance\n",
    "\n",
    "We'll be repeating the above process with a decision tree model. As decision tree is a nonlinear model, it may provide completely different insights into which features are important in predicting energy consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select feats using decision tree\n",
    "tree_feats = udf.feats_from_model(Xe_train_scaled, ye_train, SelectFromModel, DecisionTreeRegressor())\n",
    "tree_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select feats recursively using decision tree\n",
    "rfe_tree_feats = udf.feats_from_model(Xe_train_scaled, ye_train, RFE, DecisionTreeRegressor())\n",
    "rfe_tree_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increment the counts for selected feats\n",
    "feat_sel = udf.inc_feat_count(feat_sel, tree_feats + rfe_tree_feats)\n",
    "feat_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the 3 features most correlated with the target show up, as well as day and time. But interestingly, we're also seeing `year_built` and `air_temperature` here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section VI: Featurization Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe of selected features for each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method names and their selected methods\n",
    "sel_feats = {\n",
    "    'target_corr': corr_feats,\n",
    "    'lasso_coef':  l1_feats, \n",
    "    'lasso_coef_recursive': rfe_l1_feats, \n",
    "    'tree_importance': tree_feats, \n",
    "    'tree_importance_recursive': rfe_tree_feats\n",
    "}\n",
    "\n",
    "# Fill shorter lists to match the length of the longest list\n",
    "longest = max([len(lst) for lst in sel_feats.values()])\n",
    "for key, val in sel_feats.items():\n",
    "    sel_feats[key] += [''] * (longest - len(val))\n",
    "    \n",
    "# Selected feats for each method\n",
    "sel_feats_df = pd.DataFrame(sel_feats).fillna('')\n",
    "sel_feats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean vars\n",
    "del corr_feats, l1_feats, rfe_l1_feats, tree_feats, rfe_tree_feats, sel_feats, longest, key, val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is strong evidence that `square_feet` and `country` will be the best predictors of energy consumption. Besides this, `primary_use` and day/time features will likely be good predictors as well. The following features were only selected once but may be informative nonetheless:\n",
    "- `site_id`\n",
    "- `air_temperature`\n",
    "- `missing_year`\n",
    "- `is_holiday`\n",
    "\n",
    "The 5 features that weren't selected at all didn't do well in both linear and tree-based models. They may end up being useful, but for now, these are the prime candidates to drop from the feature set:\n",
    "- `rel_humidity`\n",
    "- `sea_level_pressure`\n",
    "- `wind_direction_x`\n",
    "- `wind_direction_y`\n",
    "- `wind_speed`\n",
    "\n",
    "With this, we have a pretty good idea of which features will and will not be useful in predicting energy consumption. We won't know for sure until actually building the models, but this will serve as a good starting point for making the feature set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_path = os.path.join(output_dir, 'feats.pkl')\n",
    "sel_feats_df.to_pickle(feats_path)\n",
    "pd.read_pickle(feats_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:minds] *",
   "language": "python",
   "name": "conda-env-minds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
