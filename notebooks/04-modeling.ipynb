{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Energy Predictor - Modeling (Electricity)\n",
    "#### Hosted by: ASHRAE\n",
    "##### Source: https://www.kaggle.com/c/ashrae-energy-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section I: Dependencies and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import gc\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import src.utils as udf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "# Plot settings\n",
    "mpl.style.use('seaborn')\n",
    "mpl.rcParams['figure.figsize'] = (15, 3)\n",
    "mpl.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/03-feat-out'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data path\n",
    "data_path = os.path.join('..', 'data', '03-feat-out')\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11481619 entries, 0 to 18205341\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   site_id             uint8         \n",
      " 1   building_id         uint16        \n",
      " 2   timestamp           datetime64[ns]\n",
      " 3   meter_reading       float32       \n",
      " 4   air_temperature     float32       \n",
      " 5   dew_temperature     float32       \n",
      " 6   rel_humidity        float32       \n",
      " 7   sea_level_pressure  float32       \n",
      " 8   wind_speed          float32       \n",
      " 9   wind_direction_x    float32       \n",
      " 10  wind_direction_y    float32       \n",
      " 11  primary_use         object        \n",
      " 12  square_feet         uint32        \n",
      " 13  year_built          uint16        \n",
      " 14  missing_year        uint8         \n",
      " 15  country             object        \n",
      " 16  dayofyear           uint16        \n",
      " 17  month               uint8         \n",
      " 18  hour                uint8         \n",
      " 19  dayofweek           uint8         \n",
      " 20  is_weekend          uint8         \n",
      " 21  is_holiday          int8          \n",
      "dtypes: datetime64[ns](1), float32(8), int8(1), object(2), uint16(3), uint32(1), uint8(6)\n",
      "memory usage: 886.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Electricity meter data\n",
    "electricity = pd.read_pickle(os.path.join(data_path, 'electricity.pkl'))\n",
    "electricity.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3507966 entries, 70 to 18205292\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   site_id             uint8         \n",
      " 1   building_id         uint16        \n",
      " 2   timestamp           datetime64[ns]\n",
      " 3   meter_reading       float32       \n",
      " 4   air_temperature     float32       \n",
      " 5   dew_temperature     float32       \n",
      " 6   rel_humidity        float32       \n",
      " 7   sea_level_pressure  float32       \n",
      " 8   wind_speed          float32       \n",
      " 9   wind_direction_x    float32       \n",
      " 10  wind_direction_y    float32       \n",
      " 11  primary_use         object        \n",
      " 12  square_feet         uint32        \n",
      " 13  year_built          uint16        \n",
      " 14  missing_year        uint8         \n",
      " 15  country             object        \n",
      " 16  dayofyear           uint16        \n",
      " 17  month               uint8         \n",
      " 18  hour                uint8         \n",
      " 19  dayofweek           uint8         \n",
      " 20  is_weekend          uint8         \n",
      " 21  is_holiday          int8          \n",
      "dtypes: datetime64[ns](1), float32(8), int8(1), object(2), uint16(3), uint32(1), uint8(6)\n",
      "memory usage: 271.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Chilled water meter data\n",
    "chilledwater = pd.read_pickle(os.path.join(data_path, 'chilledwater.pkl'))\n",
    "chilledwater.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2296049 entries, 762 to 18205336\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   site_id             uint8         \n",
      " 1   building_id         uint16        \n",
      " 2   timestamp           datetime64[ns]\n",
      " 3   meter_reading       float32       \n",
      " 4   air_temperature     float32       \n",
      " 5   dew_temperature     float32       \n",
      " 6   rel_humidity        float32       \n",
      " 7   sea_level_pressure  float32       \n",
      " 8   wind_speed          float32       \n",
      " 9   wind_direction_x    float32       \n",
      " 10  wind_direction_y    float32       \n",
      " 11  primary_use         object        \n",
      " 12  square_feet         uint32        \n",
      " 13  year_built          uint16        \n",
      " 14  missing_year        uint8         \n",
      " 15  country             object        \n",
      " 16  dayofyear           uint16        \n",
      " 17  month               uint8         \n",
      " 18  hour                uint8         \n",
      " 19  dayofweek           uint8         \n",
      " 20  is_weekend          uint8         \n",
      " 21  is_holiday          int8          \n",
      "dtypes: datetime64[ns](1), float32(8), int8(1), object(2), uint16(3), uint32(1), uint8(6)\n",
      "memory usage: 177.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Steam meter data\n",
    "steam = pd.read_pickle(os.path.join(data_path, 'steam.pkl'))\n",
    "steam.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 919708 entries, 10 to 18205124\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   site_id             919708 non-null  uint8         \n",
      " 1   building_id         919708 non-null  uint16        \n",
      " 2   timestamp           919708 non-null  datetime64[ns]\n",
      " 3   meter_reading       919708 non-null  float32       \n",
      " 4   air_temperature     919708 non-null  float32       \n",
      " 5   dew_temperature     919708 non-null  float32       \n",
      " 6   rel_humidity        919708 non-null  float32       \n",
      " 7   sea_level_pressure  919708 non-null  float32       \n",
      " 8   wind_speed          919708 non-null  float32       \n",
      " 9   wind_direction_x    919708 non-null  float32       \n",
      " 10  wind_direction_y    919708 non-null  float32       \n",
      " 11  primary_use         919708 non-null  object        \n",
      " 12  square_feet         919708 non-null  uint32        \n",
      " 13  year_built          919708 non-null  uint16        \n",
      " 14  missing_year        919708 non-null  uint8         \n",
      " 15  country             919708 non-null  object        \n",
      " 16  dayofyear           919708 non-null  uint16        \n",
      " 17  month               919708 non-null  uint8         \n",
      " 18  hour                919708 non-null  uint8         \n",
      " 19  dayofweek           919708 non-null  uint8         \n",
      " 20  is_weekend          919708 non-null  uint8         \n",
      " 21  is_holiday          919708 non-null  int8          \n",
      "dtypes: datetime64[ns](1), float32(8), int8(1), object(2), uint16(3), uint32(1), uint8(6)\n",
      "memory usage: 71.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Hot water meter data\n",
    "hotwater = pd.read_pickle(os.path.join(data_path, 'hotwater.pkl'))\n",
    "hotwater.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_corr</th>\n",
       "      <th>lasso_coef</th>\n",
       "      <th>lasso_coef_recursive</th>\n",
       "      <th>tree_importance</th>\n",
       "      <th>tree_importance_recursive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>square_feet</td>\n",
       "      <td>primary_use</td>\n",
       "      <td>primary_use</td>\n",
       "      <td>square_feet</td>\n",
       "      <td>site_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>country</td>\n",
       "      <td>square_feet</td>\n",
       "      <td>square_feet</td>\n",
       "      <td>year_built</td>\n",
       "      <td>air_temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>country</td>\n",
       "      <td>missing_year</td>\n",
       "      <td>country</td>\n",
       "      <td>primary_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>is_weekend</td>\n",
       "      <td>country</td>\n",
       "      <td></td>\n",
       "      <td>square_feet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>dayofyear</td>\n",
       "      <td></td>\n",
       "      <td>year_built</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hour</td>\n",
       "      <td></td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>is_weekend</td>\n",
       "      <td></td>\n",
       "      <td>dayofyear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>is_holiday</td>\n",
       "      <td></td>\n",
       "      <td>hour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_corr   lasso_coef lasso_coef_recursive tree_importance  \\\n",
       "0  square_feet  primary_use          primary_use     square_feet   \n",
       "1      country  square_feet          square_feet      year_built   \n",
       "2                   country         missing_year         country   \n",
       "3                is_weekend              country                   \n",
       "4                                      dayofyear                   \n",
       "5                                           hour                   \n",
       "6                                     is_weekend                   \n",
       "7                                     is_holiday                   \n",
       "\n",
       "  tree_importance_recursive  \n",
       "0                   site_id  \n",
       "1           air_temperature  \n",
       "2               primary_use  \n",
       "3               square_feet  \n",
       "4                year_built  \n",
       "5                   country  \n",
       "6                 dayofyear  \n",
       "7                      hour  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = pd.read_pickle(os.path.join(data_path, 'feats.pkl'))\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean vars\n",
    "del data_path\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section II: Featurization - Electricity\n",
    "\n",
    "Once again, we will be working primarily with the electricity meter data as it contains the most readings and the process used here will be repeated for the other 3 meters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unused features\n",
    "\n",
    "We will be dropping the features we found to be unnecessary in the featurization notebook - `site_id`, `building_id`, `dew_temperature`, `timestamp`, `month`, `dayofweek`. `Site_id` was added here because we have the `country` feature which is a good proxy for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11481619 entries, 0 to 18205341\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   meter_reading       float32\n",
      " 1   air_temperature     float32\n",
      " 2   rel_humidity        float32\n",
      " 3   sea_level_pressure  float32\n",
      " 4   wind_direction_x    float32\n",
      " 5   wind_direction_y    float32\n",
      " 6   wind_speed          float32\n",
      " 7   primary_use         object \n",
      " 8   square_feet         uint32 \n",
      " 9   year_built          uint8  \n",
      " 10  missing_year        uint8  \n",
      " 11  country             object \n",
      " 12  dayofyear           uint16 \n",
      " 13  hour                uint8  \n",
      " 14  is_weekend          uint8  \n",
      " 15  is_holiday          uint8  \n",
      "dtypes: float32(7), object(2), uint16(1), uint32(1), uint8(5)\n",
      "memory usage: 689.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Drop features\n",
    "to_drop = ['site_id', 'building_id', 'dew_temperature', 'timestamp', 'month', 'dayofweek']\n",
    "electricity.drop(to_drop, axis=1, inplace=True)\n",
    "electricity.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split\n",
    "\n",
    "The same 60-20-20 data split will be done here. Variables will be suffixed with \"e\" to indicate that it is `electricity` meter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11481619, 15), (11481619,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split features and target\n",
    "Xe = electricity.drop('meter_reading', axis=1).copy()\n",
    "ye = electricity['meter_reading'].copy()\n",
    "Xe.shape, ye.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the target distribution\n",
    "ye.plot(kind='hist', bins=50, title='Target Distribution', xlim=(0, 1e4))\n",
    "plt.xlabel('Electricity meter reading')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw meter readings are highly right-skewed. We may be able to get more accurate predictions if we transform the target variable into a normal distribution to increase its linearity with the features. To do this, we will do a log transformation on the target variable and train our models using the log-transformed target. Of course, when making predictions, the output will be log-transformed values, so the predictions will have to be inverse-transformed to yield the true output.\n",
    "\n",
    "Note: the target variable contains meter readings of 0, so 1 will be added to all readings before taking the log (because log(0) is undefined) like this: `y_log_transformed = log(y + 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Log transform the target variable\n",
    "ye = np.log1p(ye)\n",
    "ye.plot(kind='hist', bins=50, title='Log-transformed Target Distribution', xlim=(0, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (6888971, 15) (6888971,)\n",
      "Validation set: (2296324, 15) (2296324,)\n",
      "Test set: (2296324, 15) (2296324,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>rel_humidity</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction_x</th>\n",
       "      <th>wind_direction_y</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>missing_year</th>\n",
       "      <th>country</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11668719</th>\n",
       "      <td>26.1</td>\n",
       "      <td>82.086754</td>\n",
       "      <td>1015.400024</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Office</td>\n",
       "      <td>26953</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15417488</th>\n",
       "      <td>18.9</td>\n",
       "      <td>78.094246</td>\n",
       "      <td>1020.099976</td>\n",
       "      <td>0.766044</td>\n",
       "      <td>-0.642788</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Education</td>\n",
       "      <td>66203</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>312</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4404673</th>\n",
       "      <td>4.4</td>\n",
       "      <td>50.354458</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>-0.766044</td>\n",
       "      <td>-0.642788</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Public services</td>\n",
       "      <td>400000</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>97</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          air_temperature  rel_humidity  sea_level_pressure  wind_direction_x  \\\n",
       "11668719             26.1     82.086754         1015.400024          0.866025   \n",
       "15417488             18.9     78.094246         1020.099976          0.766044   \n",
       "4404673               4.4     50.354458         1029.000000         -0.766044   \n",
       "\n",
       "          wind_direction_y  wind_speed      primary_use  square_feet  \\\n",
       "11668719          0.500000         3.1           Office        26953   \n",
       "15417488         -0.642788         1.5        Education        66203   \n",
       "4404673          -0.642788         4.6  Public services       400000   \n",
       "\n",
       "          year_built  missing_year country  dayofyear  hour  is_weekend  \\\n",
       "11668719         213             0      US        240     1           1   \n",
       "15417488         223             0      US        312    18           0   \n",
       "4404673          179             0      US         97     8           0   \n",
       "\n",
       "          is_holiday  \n",
       "11668719           0  \n",
       "15417488           0  \n",
       "4404673            0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/val/test split (60/20/20)\n",
    "Xe_train, Xe_test, ye_train, ye_test = train_test_split(Xe, ye, test_size=0.4, random_state=0)\n",
    "Xe_val, Xe_test, ye_val, ye_test = train_test_split(Xe_test, ye_test, test_size=0.5, random_state=0)\n",
    "\n",
    "print('Train set:', Xe_train.shape, ye_train.shape)\n",
    "print('Validation set:', Xe_val.shape, ye_val.shape)\n",
    "print('Test set:', Xe_test.shape, ye_test.shape)\n",
    "Xe_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12587"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del Xe, ye\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical feature encoding\n",
    "\n",
    "Next, we will perform the 2 types of categorical encoding as in the featurization notebook:\n",
    "1. Rare label categorical encoding - categorical labels that occur less than 5% in the data will be encoded as \"Rare\"\n",
    "    - This will be done for `primary_use`\n",
    "2. Mean target categorical encoding - categorical labels will be numerically encoded with the mean value of the target label for that particular label\n",
    "    - This will be done for `primary_use` and `country`\n",
    "    - Note: countries \"UK\" and \"IE\" were grouped into the label \"EU\"\n",
    "    \n",
    "The difference here is that the target label has been log-transformed, so the encoded values here will differ from the featurization notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'primary_use': Index(['Education', 'Office', 'Entertainment/public assembly',\n",
       "        'Public services', 'Lodging/residential'],\n",
       "       dtype='object')}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group all rare primary_use categories\n",
    "Xe_train, Xe_val, Xe_test, rare_dict = udf.rare_encoder(['primary_use'], Xe_train, Xe_test, val=Xe_val)\n",
    "rare_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train set #####\n",
      "Education                        2635696\n",
      "Office                           1310265\n",
      "Entertainment/public assembly     871248\n",
      "Public services                   788379\n",
      "Lodging/residential               678847\n",
      "Rare                              604536\n",
      "Name: primary_use, dtype: int64\n",
      "\n",
      "##### Validation set #####\n",
      "Education                        877922\n",
      "Office                           435865\n",
      "Entertainment/public assembly    291572\n",
      "Public services                  262875\n",
      "Lodging/residential              226541\n",
      "Rare                             201549\n",
      "Name: primary_use, dtype: int64\n",
      "\n",
      "##### Test set #####\n",
      "Education                        879687\n",
      "Office                           435391\n",
      "Entertainment/public assembly    290427\n",
      "Public services                  262464\n",
      "Lodging/residential              226333\n",
      "Rare                             202022\n",
      "Name: primary_use, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Value counts for `primary_use`\n",
    "print('##### Train set #####')\n",
    "print(Xe_train.primary_use.value_counts())\n",
    "print('\\n##### Validation set #####')\n",
    "print(Xe_val.primary_use.value_counts())\n",
    "print('\\n##### Test set #####')\n",
    "print(Xe_test.primary_use.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'primary_use': {'Education': 4.468423366546631,\n",
       "  'Entertainment/public assembly': 3.523334264755249,\n",
       "  'Lodging/residential': 3.9764797687530518,\n",
       "  'Office': 4.195037364959717,\n",
       "  'Public services': 3.760781764984131,\n",
       "  'Rare': 3.770461320877075},\n",
       " 'country': {'CA': 6.6370038986206055,\n",
       "  'EU': 3.4172074794769287,\n",
       "  'US': 4.179385185241699}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode categorical features using the target mean of each category\n",
    "Xe_train, Xe_val, Xe_test, mean_dict = udf.mean_encoder(['primary_use', 'country'], \n",
    "                                                        Xe_train, ye_train, Xe_test, X_val=Xe_val)\n",
    "mean_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train set: primary_use #####\n",
      "4.468423    2635696\n",
      "4.195037    1310265\n",
      "3.523334     871248\n",
      "3.760782     788379\n",
      "3.976480     678847\n",
      "3.770461     604536\n",
      "Name: primary_use, dtype: int64\n",
      "\n",
      "##### Train set: country #####\n",
      "4.179385    5885587\n",
      "3.417207     922469\n",
      "6.637004      80915\n",
      "Name: country, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Encoded value counts in train set\n",
    "print('##### Train set: primary_use #####')\n",
    "print(Xe_train.primary_use.value_counts())\n",
    "print('\\n##### Train set: country #####')\n",
    "print(Xe_train.country.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>rel_humidity</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction_x</th>\n",
       "      <th>wind_direction_y</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>missing_year</th>\n",
       "      <th>country</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.977865</td>\n",
       "      <td>0.741393</td>\n",
       "      <td>-0.120466</td>\n",
       "      <td>1.352629</td>\n",
       "      <td>0.853826</td>\n",
       "      <td>-0.197988</td>\n",
       "      <td>0.256614</td>\n",
       "      <td>-0.589092</td>\n",
       "      <td>1.827039</td>\n",
       "      <td>-1.108092</td>\n",
       "      <td>0.193303</td>\n",
       "      <td>0.495444</td>\n",
       "      <td>-1.517191</td>\n",
       "      <td>1.577058</td>\n",
       "      <td>-0.180158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.291863</td>\n",
       "      <td>0.562860</td>\n",
       "      <td>0.513359</td>\n",
       "      <td>1.204086</td>\n",
       "      <td>-0.880341</td>\n",
       "      <td>-0.886943</td>\n",
       "      <td>1.046239</td>\n",
       "      <td>-0.238802</td>\n",
       "      <td>2.298373</td>\n",
       "      <td>-1.108092</td>\n",
       "      <td>0.193303</td>\n",
       "      <td>1.180861</td>\n",
       "      <td>0.938746</td>\n",
       "      <td>-0.634092</td>\n",
       "      <td>-0.180158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.089669</td>\n",
       "      <td>-0.677575</td>\n",
       "      <td>1.713597</td>\n",
       "      <td>-1.072159</td>\n",
       "      <td>-0.880341</td>\n",
       "      <td>0.447907</td>\n",
       "      <td>-0.997653</td>\n",
       "      <td>2.740196</td>\n",
       "      <td>0.224504</td>\n",
       "      <td>-1.108092</td>\n",
       "      <td>0.193303</td>\n",
       "      <td>-0.865871</td>\n",
       "      <td>-0.505923</td>\n",
       "      <td>-0.634092</td>\n",
       "      <td>-0.180158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.299280</td>\n",
       "      <td>0.175473</td>\n",
       "      <td>1.201131</td>\n",
       "      <td>0.065963</td>\n",
       "      <td>0.095082</td>\n",
       "      <td>-1.532838</td>\n",
       "      <td>-1.683476</td>\n",
       "      <td>4.201882</td>\n",
       "      <td>-0.152563</td>\n",
       "      <td>0.902452</td>\n",
       "      <td>0.193303</td>\n",
       "      <td>-1.522729</td>\n",
       "      <td>-1.661658</td>\n",
       "      <td>-0.634092</td>\n",
       "      <td>-0.180158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.737140</td>\n",
       "      <td>-0.663548</td>\n",
       "      <td>1.956347</td>\n",
       "      <td>-0.192028</td>\n",
       "      <td>1.589516</td>\n",
       "      <td>0.921563</td>\n",
       "      <td>-0.374649</td>\n",
       "      <td>0.087578</td>\n",
       "      <td>-0.482496</td>\n",
       "      <td>-1.108092</td>\n",
       "      <td>-1.819603</td>\n",
       "      <td>1.380774</td>\n",
       "      <td>-0.072522</td>\n",
       "      <td>-0.634092</td>\n",
       "      <td>-0.180158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   air_temperature  rel_humidity  sea_level_pressure  wind_direction_x  \\\n",
       "0         0.977865      0.741393           -0.120466          1.352629   \n",
       "1         0.291863      0.562860            0.513359          1.204086   \n",
       "2        -1.089669     -0.677575            1.713597         -1.072159   \n",
       "3        -1.299280      0.175473            1.201131          0.065963   \n",
       "4        -0.737140     -0.663548            1.956347         -0.192028   \n",
       "\n",
       "   wind_direction_y  wind_speed  primary_use  square_feet  year_built  \\\n",
       "0          0.853826   -0.197988     0.256614    -0.589092    1.827039   \n",
       "1         -0.880341   -0.886943     1.046239    -0.238802    2.298373   \n",
       "2         -0.880341    0.447907    -0.997653     2.740196    0.224504   \n",
       "3          0.095082   -1.532838    -1.683476     4.201882   -0.152563   \n",
       "4          1.589516    0.921563    -0.374649     0.087578   -0.482496   \n",
       "\n",
       "   missing_year   country  dayofyear      hour  is_weekend  is_holiday  \n",
       "0     -1.108092  0.193303   0.495444 -1.517191    1.577058   -0.180158  \n",
       "1     -1.108092  0.193303   1.180861  0.938746   -0.634092   -0.180158  \n",
       "2     -1.108092  0.193303  -0.865871 -0.505923   -0.634092   -0.180158  \n",
       "3      0.902452  0.193303  -1.522729 -1.661658   -0.634092   -0.180158  \n",
       "4     -1.108092 -1.819603   1.380774 -0.072522   -0.634092   -0.180158  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale features using their mean and standard deviation\n",
    "Xe_train_scaled, Xe_val_scaled, Xe_test_scaled = udf.scale_feats(Xe_train, Xe_test, val=Xe_val)\n",
    "Xe_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del Xe_train, Xe_val, Xe_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature sets\n",
    "\n",
    "Building on the featurization notebook, we will be creating several feature sets for model training to try see if we can get better predictions:\n",
    "1. All features (15) - full feature set\n",
    "2. Custom features (10) - drop the 5 features that were selected 0 times in the featurization notebook\n",
    "    - `rel_humidity`, `sea_level_pressure`, `wind_direction_x`, `wind_direction_y`, `wind_speed`\n",
    "3. Lasso RFE features (8) - features selected from the lasso RFE method\n",
    "4. Tree RFE features (7) - features selected from the decision tree RFE method, except for `site_id`, which was just dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_corr</th>\n",
       "      <th>lasso_coef</th>\n",
       "      <th>lasso_coef_recursive</th>\n",
       "      <th>tree_importance</th>\n",
       "      <th>tree_importance_recursive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>square_feet</td>\n",
       "      <td>primary_use</td>\n",
       "      <td>primary_use</td>\n",
       "      <td>square_feet</td>\n",
       "      <td>site_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>country</td>\n",
       "      <td>square_feet</td>\n",
       "      <td>square_feet</td>\n",
       "      <td>year_built</td>\n",
       "      <td>air_temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>country</td>\n",
       "      <td>missing_year</td>\n",
       "      <td>country</td>\n",
       "      <td>primary_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>is_weekend</td>\n",
       "      <td>country</td>\n",
       "      <td></td>\n",
       "      <td>square_feet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>dayofyear</td>\n",
       "      <td></td>\n",
       "      <td>year_built</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hour</td>\n",
       "      <td></td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>is_weekend</td>\n",
       "      <td></td>\n",
       "      <td>dayofyear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>is_holiday</td>\n",
       "      <td></td>\n",
       "      <td>hour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_corr   lasso_coef lasso_coef_recursive tree_importance  \\\n",
       "0  square_feet  primary_use          primary_use     square_feet   \n",
       "1      country  square_feet          square_feet      year_built   \n",
       "2                   country         missing_year         country   \n",
       "3                is_weekend              country                   \n",
       "4                                      dayofyear                   \n",
       "5                                           hour                   \n",
       "6                                     is_weekend                   \n",
       "7                                     is_holiday                   \n",
       "\n",
       "  tree_importance_recursive  \n",
       "0                   site_id  \n",
       "1           air_temperature  \n",
       "2               primary_use  \n",
       "3               square_feet  \n",
       "4                year_built  \n",
       "5                   country  \n",
       "6                 dayofyear  \n",
       "7                      hour  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected features from featurization notebook\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['air_temperature',\n",
       " 'rel_humidity',\n",
       " 'sea_level_pressure',\n",
       " 'wind_direction_x',\n",
       " 'wind_direction_y',\n",
       " 'wind_speed',\n",
       " 'primary_use',\n",
       " 'square_feet',\n",
       " 'year_built',\n",
       " 'missing_year',\n",
       " 'country',\n",
       " 'dayofyear',\n",
       " 'hour',\n",
       " 'is_weekend',\n",
       " 'is_holiday']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full feature set\n",
    "all_feats = Xe_train_scaled.columns.tolist()\n",
    "print(len(all_feats))\n",
    "all_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['air_temperature',\n",
       " 'primary_use',\n",
       " 'square_feet',\n",
       " 'year_built',\n",
       " 'missing_year',\n",
       " 'country',\n",
       " 'dayofyear',\n",
       " 'hour',\n",
       " 'is_weekend',\n",
       " 'is_holiday']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom feature set\n",
    "custom_drop = ['rel_humidity', 'sea_level_pressure', 'wind_direction_x', 'wind_direction_y', 'wind_speed']\n",
    "custom_feats = Xe_train_scaled.drop(custom_drop, axis=1).columns.tolist()\n",
    "\n",
    "print(len(custom_feats))\n",
    "custom_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['primary_use',\n",
       " 'square_feet',\n",
       " 'missing_year',\n",
       " 'country',\n",
       " 'dayofyear',\n",
       " 'hour',\n",
       " 'is_weekend',\n",
       " 'is_holiday']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso RFE feature set\n",
    "lasso_feats = feats['lasso_coef_recursive'].tolist()\n",
    "print(len(lasso_feats))\n",
    "lasso_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['air_temperature',\n",
       " 'primary_use',\n",
       " 'square_feet',\n",
       " 'year_built',\n",
       " 'country',\n",
       " 'dayofyear',\n",
       " 'hour']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree RFE feature set\n",
    "tree_feats = feats['tree_importance_recursive'].tolist()[1:]\n",
    "print(len(tree_feats))\n",
    "tree_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del feats, custom_drop\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section III: Modeling - Electricity\n",
    "\n",
    "With the 4 feature sets we just created, we will be training 3 different models - a linear model and 2 tree-based models:\n",
    "1. `Lasso regression` (linear regression with L1 regularization) - this will be the baseline model for prediction performance\n",
    "    - As we did use lasso regression to create one of the feature sets, that feature set is optimized for lasso regression, so this model may do quite well\n",
    "2. LightGBM - a parallelizable gradient boosting machines (GBM) implementation that grows trees leaf-wise, which can reduce loss more than the commonly used depth-wise implementation *\n",
    "    - Another one of the feature sets was created with decision tree, so that's why we are using tree-based models\n",
    "3. XGBoost - another parallelizable GBM implementation that has a reputation of winning Kaggle competitions involving structured data\n",
    "    - Although not as fast as LightGBM, I suspect this algorithm will produce the best predictions\n",
    "    \n",
    "For each of the 3 models above, we will be tuning the model hyperparameters and training it on each of the 4 feature sets to select the model with the highest scores. The metric we are using to evaluate model performance is the `root mean squared error`. This is the most commonly used metric for evaluating regression models, and for good reason: it is easy to compute and understand, much like the `mean absolute error`, but has the added benefit of penalizing larger errors more so that the optimization process can be more robust to outliers.\n",
    "\n",
    "##### \\* Note: Read more about LightGBM and XGBoost [here](https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/). Pranjal provides a great comparison between the 2 algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso regression\n",
    "\n",
    "Again, this will be the baseline model for performance. This will give us an idea of the performance we can expect with the data. With only 1 hyperparamer to tune, a simple for loop would do the trick. But we are going to take advantage of Scikit-learn's grid search for the detailed results it provides. The only thing we are tuning here is the `alpha` parameter, which controls the degree of L1 regularization in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  24 | elapsed:   35.1s remaining:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   39.3s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>-1.116370</td>\n",
       "      <td>-1.116607</td>\n",
       "      <td>-1.115951</td>\n",
       "      <td>-1.117037</td>\n",
       "      <td>-1.116491</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>-1.116380</td>\n",
       "      <td>-1.116616</td>\n",
       "      <td>-1.115960</td>\n",
       "      <td>-1.117044</td>\n",
       "      <td>-1.116500</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>-1.117120</td>\n",
       "      <td>-1.117382</td>\n",
       "      <td>-1.116698</td>\n",
       "      <td>-1.117792</td>\n",
       "      <td>-1.117248</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>-1.139569</td>\n",
       "      <td>-1.139799</td>\n",
       "      <td>-1.139120</td>\n",
       "      <td>-1.140224</td>\n",
       "      <td>-1.139678</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>-1.485414</td>\n",
       "      <td>-1.485675</td>\n",
       "      <td>-1.485209</td>\n",
       "      <td>-1.484830</td>\n",
       "      <td>-1.485282</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0000</th>\n",
       "      <td>-1.485414</td>\n",
       "      <td>-1.485675</td>\n",
       "      <td>-1.485209</td>\n",
       "      <td>-1.484830</td>\n",
       "      <td>-1.485282</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             split0_test_score  split1_test_score  split2_test_score  \\\n",
       "param_alpha                                                            \n",
       "0.0001               -1.116370          -1.116607          -1.115951   \n",
       "0.0010               -1.116380          -1.116616          -1.115960   \n",
       "0.0100               -1.117120          -1.117382          -1.116698   \n",
       "0.1000               -1.139569          -1.139799          -1.139120   \n",
       "1.0000               -1.485414          -1.485675          -1.485209   \n",
       "10.0000              -1.485414          -1.485675          -1.485209   \n",
       "\n",
       "             split3_test_score  mean_test_score  std_test_score  \\\n",
       "param_alpha                                                       \n",
       "0.0001               -1.117037        -1.116491        0.000393   \n",
       "0.0010               -1.117044        -1.116500        0.000392   \n",
       "0.0100               -1.117792        -1.117248        0.000398   \n",
       "0.1000               -1.140224        -1.139678        0.000399   \n",
       "1.0000               -1.484830        -1.485282        0.000309   \n",
       "10.0000              -1.484830        -1.485282        0.000309   \n",
       "\n",
       "             rank_test_score  \n",
       "param_alpha                   \n",
       "0.0001                     1  \n",
       "0.0010                     2  \n",
       "0.0100                     3  \n",
       "0.1000                     4  \n",
       "1.0000                     5  \n",
       "10.0000                    5  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression with full feature set (15)\n",
    "params = {'alpha': [10 ** e for e in range(-4, 2)]}\n",
    "lasso15 = GridSearchCV(Lasso(random_state=0), params, cv=4, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=-1)\n",
    "lasso15.fit(Xe_train_scaled, ye_train)\n",
    "pd.DataFrame(lasso15.cv_results_).set_index('param_alpha').iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:   15.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>-1.119237</td>\n",
       "      <td>-1.119506</td>\n",
       "      <td>-1.118950</td>\n",
       "      <td>-1.119851</td>\n",
       "      <td>-1.119386</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>-1.119239</td>\n",
       "      <td>-1.119511</td>\n",
       "      <td>-1.118952</td>\n",
       "      <td>-1.119860</td>\n",
       "      <td>-1.119390</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>-1.119598</td>\n",
       "      <td>-1.119892</td>\n",
       "      <td>-1.119296</td>\n",
       "      <td>-1.120267</td>\n",
       "      <td>-1.119763</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>-1.139775</td>\n",
       "      <td>-1.139996</td>\n",
       "      <td>-1.139284</td>\n",
       "      <td>-1.140418</td>\n",
       "      <td>-1.139868</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             split0_test_score  split1_test_score  split2_test_score  \\\n",
       "param_alpha                                                            \n",
       "0.0001               -1.119237          -1.119506          -1.118950   \n",
       "0.0010               -1.119239          -1.119511          -1.118952   \n",
       "0.0100               -1.119598          -1.119892          -1.119296   \n",
       "0.1000               -1.139775          -1.139996          -1.139284   \n",
       "\n",
       "             split3_test_score  mean_test_score  std_test_score  \\\n",
       "param_alpha                                                       \n",
       "0.0001               -1.119851        -1.119386        0.000333   \n",
       "0.0010               -1.119860        -1.119390        0.000335   \n",
       "0.0100               -1.120267        -1.119763        0.000359   \n",
       "0.1000               -1.140418        -1.139868        0.000409   \n",
       "\n",
       "             rank_test_score  \n",
       "param_alpha                   \n",
       "0.0001                     1  \n",
       "0.0010                     2  \n",
       "0.0100                     3  \n",
       "0.1000                     4  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression with custom feature set (10)\n",
    "params = {'alpha': [10 ** e for e in range(-4, 0)]}\n",
    "lasso10 = GridSearchCV(Lasso(random_state=0), params, cv=4, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=-1)\n",
    "lasso10.fit(Xe_train_scaled[custom_feats], ye_train)\n",
    "pd.DataFrame(lasso10.cv_results_).set_index('param_alpha').iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:   12.3s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>-1.128990</td>\n",
       "      <td>-1.129433</td>\n",
       "      <td>-1.128609</td>\n",
       "      <td>-1.129648</td>\n",
       "      <td>-1.129170</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>-1.128992</td>\n",
       "      <td>-1.129437</td>\n",
       "      <td>-1.128610</td>\n",
       "      <td>-1.129655</td>\n",
       "      <td>-1.129174</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>-1.129291</td>\n",
       "      <td>-1.129730</td>\n",
       "      <td>-1.128896</td>\n",
       "      <td>-1.129977</td>\n",
       "      <td>-1.129473</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>-1.144999</td>\n",
       "      <td>-1.145229</td>\n",
       "      <td>-1.144494</td>\n",
       "      <td>-1.145633</td>\n",
       "      <td>-1.145089</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             split0_test_score  split1_test_score  split2_test_score  \\\n",
       "param_alpha                                                            \n",
       "0.0001               -1.128990          -1.129433          -1.128609   \n",
       "0.0010               -1.128992          -1.129437          -1.128610   \n",
       "0.0100               -1.129291          -1.129730          -1.128896   \n",
       "0.1000               -1.144999          -1.145229          -1.144494   \n",
       "\n",
       "             split3_test_score  mean_test_score  std_test_score  \\\n",
       "param_alpha                                                       \n",
       "0.0001               -1.129648        -1.129170        0.000401   \n",
       "0.0010               -1.129655        -1.129174        0.000404   \n",
       "0.0100               -1.129977        -1.129473        0.000414   \n",
       "0.1000               -1.145633        -1.145089        0.000412   \n",
       "\n",
       "             rank_test_score  \n",
       "param_alpha                   \n",
       "0.0001                     1  \n",
       "0.0010                     2  \n",
       "0.0100                     3  \n",
       "0.1000                     4  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression with lasso RFE feature set (8)\n",
    "lasso8 = GridSearchCV(Lasso(random_state=0), params, cv=4, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=-1)\n",
    "lasso8.fit(Xe_train_scaled[lasso_feats], ye_train)\n",
    "pd.DataFrame(lasso8.cv_results_).set_index('param_alpha').iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:   11.2s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>-1.122640</td>\n",
       "      <td>-1.122912</td>\n",
       "      <td>-1.122351</td>\n",
       "      <td>-1.123326</td>\n",
       "      <td>-1.122807</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>-1.122641</td>\n",
       "      <td>-1.122915</td>\n",
       "      <td>-1.122353</td>\n",
       "      <td>-1.123333</td>\n",
       "      <td>-1.122810</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>-1.122875</td>\n",
       "      <td>-1.123168</td>\n",
       "      <td>-1.122577</td>\n",
       "      <td>-1.123608</td>\n",
       "      <td>-1.123057</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>-1.139775</td>\n",
       "      <td>-1.139996</td>\n",
       "      <td>-1.139284</td>\n",
       "      <td>-1.140418</td>\n",
       "      <td>-1.139868</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             split0_test_score  split1_test_score  split2_test_score  \\\n",
       "param_alpha                                                            \n",
       "0.0001               -1.122640          -1.122912          -1.122351   \n",
       "0.0010               -1.122641          -1.122915          -1.122353   \n",
       "0.0100               -1.122875          -1.123168          -1.122577   \n",
       "0.1000               -1.139775          -1.139996          -1.139284   \n",
       "\n",
       "             split3_test_score  mean_test_score  std_test_score  \\\n",
       "param_alpha                                                       \n",
       "0.0001               -1.123326        -1.122807        0.000359   \n",
       "0.0010               -1.123333        -1.122810        0.000361   \n",
       "0.0100               -1.123608        -1.123057        0.000381   \n",
       "0.1000               -1.140418        -1.139868        0.000409   \n",
       "\n",
       "             rank_test_score  \n",
       "param_alpha                   \n",
       "0.0001                     1  \n",
       "0.0010                     2  \n",
       "0.0100                     3  \n",
       "0.1000                     4  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression with decision tree RFE feature set (7)\n",
    "lasso7 = GridSearchCV(Lasso(random_state=0), params, cv=4, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=-1)\n",
    "lasso7.fit(Xe_train_scaled[tree_feats], ye_train)\n",
    "pd.DataFrame(lasso7.cv_results_).set_index('param_alpha').iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 4 feature sets, the full feature set produced the lowest error with an `alpha` value of `0.0001`. We can see that the error decreases as `alpha` decreases, but going from an `alpha` value of `0.001` to `0.0001` did not decrease the error by much, so it's unnecessary to go any smaller for `alpha`.\n",
    "\n",
    "Even though there is little difference in error between the 4 feature sets, it's clear that using less features increases the error. But interestingly, the decision tree set (with 7 features) did slightly better than the lasso set (with 8 features). This suggests 2 things:\n",
    "1. The 3 features present in both the custom set and lasso set, but absent from the tree set - `missing_year`, `is_weekend`, and `is_holiday` - are not providing much information to the model. This is because of the minimal difference in error with or without these features.\n",
    "2. Either (or both) the features present in the tree set, but absent from the lasso set - `air_temperature` and `year_built` - are important features because the model did worse without them.\n",
    "\n",
    "The top 2 choices here are:\n",
    "1. Full set (15 features) - This would be the better option if the goal is to minimize prediction error\n",
    "2. Decision tree set (7 features) - This would be the better option if the goal was to keep the model simple (minimize complexity) for better explainability without losing too much prediction performance\n",
    "\n",
    "Since the goal here is to minimize the prediction error, we will be going with the full feature set. But first, let's check if the difference in prediction error between these two sets is similar when makinng predictions on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Feature Set\n",
      "-------------------------\n",
      "Training RMSE: 1.1228058261290472\n",
      "Validation RMSE: 1.1240332865490208\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>square_feet</td>\n",
       "      <td>0.816805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>primary_use</td>\n",
       "      <td>0.289410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>country</td>\n",
       "      <td>0.200245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>year_built</td>\n",
       "      <td>0.149502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hour</td>\n",
       "      <td>0.057963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_temperature</td>\n",
       "      <td>0.002877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dayofyear</td>\n",
       "      <td>-0.010735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feat      coef\n",
       "2      square_feet  0.816805\n",
       "1      primary_use  0.289410\n",
       "4          country  0.200245\n",
       "3       year_built  0.149502\n",
       "6             hour  0.057963\n",
       "0  air_temperature  0.002877\n",
       "5        dayofyear -0.010735"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression with tree set (7)\n",
    "lasso7 = Lasso(alpha=1e-4, random_state=0).fit(Xe_train_scaled[tree_feats], ye_train)\n",
    "\n",
    "# RMSE for predictions on train and validation sets\n",
    "print('Decision Tree Feature Set')\n",
    "print('-------------------------')\n",
    "print('Training RMSE:', np.sqrt(mean_squared_error(ye_train, lasso7.predict(Xe_train_scaled[tree_feats]))))\n",
    "print('Validation RMSE:', np.sqrt(mean_squared_error(ye_val, lasso7.predict(Xe_val_scaled[tree_feats]))))\n",
    "print('-------------------------')\n",
    "\n",
    "# Feature coefficients\n",
    "pd.DataFrame(zip(tree_feats, lasso7.coef_), columns=['feat', 'coef']).sort_values('coef', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Feature Set\n",
      "----------------\n",
      "Training RMSE: 1.1164884259890666\n",
      "Validation RMSE: 1.1178666417409446\n",
      "----------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>square_feet</td>\n",
       "      <td>0.818479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>primary_use</td>\n",
       "      <td>0.293400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>country</td>\n",
       "      <td>0.179818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>year_built</td>\n",
       "      <td>0.146047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hour</td>\n",
       "      <td>0.044884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>missing_year</td>\n",
       "      <td>0.039700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dayofyear</td>\n",
       "      <td>0.011316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wind_direction_y</td>\n",
       "      <td>-0.005384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wind_speed</td>\n",
       "      <td>-0.019623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wind_direction_x</td>\n",
       "      <td>-0.021407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is_holiday</td>\n",
       "      <td>-0.025455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sea_level_pressure</td>\n",
       "      <td>-0.027101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_temperature</td>\n",
       "      <td>-0.036747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>is_weekend</td>\n",
       "      <td>-0.074217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rel_humidity</td>\n",
       "      <td>-0.085652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feat      coef\n",
       "7          square_feet  0.818479\n",
       "6          primary_use  0.293400\n",
       "10             country  0.179818\n",
       "8           year_built  0.146047\n",
       "12                hour  0.044884\n",
       "9         missing_year  0.039700\n",
       "11           dayofyear  0.011316\n",
       "4     wind_direction_y -0.005384\n",
       "5           wind_speed -0.019623\n",
       "3     wind_direction_x -0.021407\n",
       "14          is_holiday -0.025455\n",
       "2   sea_level_pressure -0.027101\n",
       "0      air_temperature -0.036747\n",
       "13          is_weekend -0.074217\n",
       "1         rel_humidity -0.085652"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression with full feature set (15)\n",
    "lasso = Lasso(alpha=1e-4, random_state=0).fit(Xe_train_scaled, ye_train)\n",
    "\n",
    "# RMSE for predictions on train and validation sets\n",
    "print('Full Feature Set')\n",
    "print('----------------')\n",
    "print('Training RMSE:', np.sqrt(mean_squared_error(ye_train, lasso.predict(Xe_train_scaled))))\n",
    "print('Validation RMSE:', np.sqrt(mean_squared_error(ye_val, lasso.predict(Xe_val_scaled))))\n",
    "print('----------------')\n",
    "\n",
    "# Feature coefficients\n",
    "coefs = pd.DataFrame(zip(Xe_train_scaled.columns, lasso.coef_), columns=['feat', 'coef'])\\\n",
    "          .sort_values('coef', ascending=False)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "994"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del lasso8, lasso10, lasso15, params, coefs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction error of the validation set confirms that training the model on the full feature set does a little better than using a reduced set, with the following root mean squared error (RMSE) scores:\n",
    "- Full feature set: 1.1165 (train) and 1.1179 (validation)\n",
    "- Decision tree RFE feature set: 1.1228 (train) and 1.1240 (validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM\n",
    "\n",
    "Now that we have a baseline model, let's see if we can do better with a gradient boosting model. With LightGBM, there are quite a bit of hyperparameters to tune. And with the cross-validation folds and number of options for each parameter, the number of trials can get exponentially high, so a parameter grid search is not feasible here.\n",
    "\n",
    "Instead, we will use `Optuna` to optimize LightGBM's parameters. `Optuna` takes a Bayesian approach to hyperparameter tuning, learning from previous trials to optimize each parameter. This is much more efficient than a grid search, which does a brute force search through every parameter combination.\n",
    "\n",
    "To use `Optuna`, we must define the objective function for the parameter optimization process. This objective function will be used on every trial to evaluate the model's prediction performance using that trial's parameters. On every trial of the `Optuna` study, the function will do the following:\n",
    "1. Save the study object - to save progress in case it is interrupted\n",
    "2. Define the parameters to tune and distribution of values to search for each parameter - `Optuna` uses a distribution of values, instead of a list of explicit values\n",
    "    - This allows us to get more fine-grained with the parameter values\n",
    "3. Create a LightGBM `Dataset` object for the data - the LightGBM model has its own data object so we must convert the data to said object in order to train the model\n",
    "4. Train model - using both the training and validation sets for validation\n",
    "5. Evaluate model on the validation set - predictions are made on the validation set and evaluated using the root mean squared error (RMSE)\n",
    "    - Negative predictions are replaced with 0 because there can't be negative energy consumption\n",
    "5. Return evaluation metric to minimize (model loss) - in this case, we are trying to minimize the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for Optuna study\n",
    "lgb_path = '../models/electricity/lgb/'\n",
    "udf.mkdir(lgb_path)\n",
    "\n",
    "\n",
    "def objective_lgb(trial):\n",
    "    \n",
    "    \"\"\" Objective function for Optuna study to optimize model hyperparameters \"\"\"\n",
    "    \n",
    "    # Save study\n",
    "    print(dt.datetime.now(), ' | Finished trials:', len(study_lgb.trials))\n",
    "    joblib.dump(study_lgb, lgb_path + 'study_lgb.pkl')\n",
    "    \n",
    "    # LightGBM parameters to tune\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-4, 1e1),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-4, 1e1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 100),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 2048),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 5000),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.5, 1.0),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.5, 1.0),\n",
    "        'num_iterations': 1000,\n",
    "        'early_stopping_round': 10,\n",
    "        'metric': 'rmse',\n",
    "        'num_threads': -1,\n",
    "        'seed': 0\n",
    "    }\n",
    "    \n",
    "    # LightGBM dataset objects\n",
    "    dtrain = lgb.Dataset(Xe_train_scaled, label=ye_train)\n",
    "    dval = lgb.Dataset(Xe_val_scaled, label=ye_val)\n",
    "    \n",
    "    # Train model\n",
    "    lgbm = lgb.train(params, dtrain, \n",
    "                     valid_sets=[dtrain, dval], \n",
    "                     valid_names=['train', 'valid'], \n",
    "                     verbose_eval=False)\n",
    "    \n",
    "    # Make and evaluate predictions on validation set\n",
    "    pred = lgbm.predict(Xe_val_scaled)\n",
    "    pred[pred < 0] = 0 # replace negative predictions with 0\n",
    "    loss = np.sqrt(mean_squared_error(ye_val, pred)) # RMSE\n",
    "\n",
    "#     # Cross validation on train set (no validation set)\n",
    "#     cv = lgb.cv(params, dtrain, folds=KFold(10, shuffle=True, random_state=0), verbose_eval=False)\n",
    "#     loss = cv['rmse-mean'][-1]\n",
    "    \n",
    "    # RMSE\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the objective function defined, we can now run the trials to optimize our parameters. Since we are evaluating the model using the RMSE, the goal is to minimize this metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start time\n",
    "# start_lgb = dt.datetime.now()\n",
    "# print('Start:', start_lgb)\n",
    "\n",
    "# # Enable logging\n",
    "# optuna.logging.enable_default_handler()\n",
    "\n",
    "# # Run trials\n",
    "# study_lgb = optuna.create_study(direction='minimize')\n",
    "# study_lgb.optimize(objective_lgb, n_trials=100)\n",
    "# joblib.dump(study_lgb, lgb_path + 'study_lgb.pkl') # Save study after last trial\n",
    "\n",
    "# # End time and total run time\n",
    "# end_lgb = dt.datetime.now()\n",
    "# print('End:', end_lgb)\n",
    "# print('Run time:', end_lgb - start_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start time\n",
    "# start_lgb = dt.datetime.now()\n",
    "# print('Start:', start_lgb)\n",
    "\n",
    "# # Enable logging\n",
    "# optuna.logging.enable_default_handler()\n",
    "\n",
    "# # Continue trials\n",
    "# study_lgb = joblib.load(lgb_path + 'study_lgb.pkl')\n",
    "# study_lgb.optimize(objective_lgb, n_trials=50)\n",
    "# joblib.dump(study_lgb, lgb_path + 'study_lgb.pkl') # Save study after last trial\n",
    "\n",
    "# # End time and total run time\n",
    "# end_lgb = dt.datetime.now()\n",
    "# print('End:', end_lgb)\n",
    "# print('Run time:', end_lgb - start_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trials: 101\n",
      "Best trial: 0.23179190098693012\n",
      "Best parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.08318870089692557,\n",
       " 'lambda_l1': 0.0074992163884415545,\n",
       " 'lambda_l2': 2.9505901993515122,\n",
       " 'max_depth': 92,\n",
       " 'num_leaves': 1929,\n",
       " 'min_data_in_leaf': 13,\n",
       " 'bagging_fraction': 0.7334916237773891,\n",
       " 'feature_fraction': 0.8102168078812939}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Study results\n",
    "study_lgb = joblib.load(lgb_path + 'study_lgb.pkl')\n",
    "print('Finished trials:', len(study_lgb.trials))\n",
    "print('Best trial:', study_lgb.best_trial.value)\n",
    "print('Best parameters:')\n",
    "params_lgb = dict(study_lgb.best_trial.params)\n",
    "params_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters yielded from the best trial are the optimized parameters and will be the final setting to train our LightGBM model. One caveat is that the Optuna study was run with a LightGBM model that builds 1,000 estimators (`num_iterations` = 1000) so the parameters were optimized to this value, more specifically the `learning_rate`, which is inversely proportional to `num_iterations`.\n",
    "\n",
    "We will be increasing `num_iterations` to 10,000 (10x the original value) to try to improve the gradient descent process. To adjust the `learning_rate` accordingly, we will divide it by 10 (the same factor `num_iterations` was increased by). \n",
    "\n",
    "Let's train a LightGBM model using the optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tri/miniconda3/envs/minds/lib/python3.8/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/tri/miniconda3/envs/minds/lib/python3.8/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1880\n",
      "[LightGBM] [Info] Number of data points in the train set: 6888971, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.106192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/electricity/lgb/lgbm.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LightGBM datasets\n",
    "edtrain = lgb.Dataset(Xe_train_scaled, label=ye_train)\n",
    "edval = lgb.Dataset(Xe_val_scaled, label=ye_val)\n",
    "\n",
    "# Parameters\n",
    "params_lgb['learning_rate'] /= 10 # adjust learning rate for the increase in iterations\n",
    "params_lgb['num_iterations'] = 10000\n",
    "params_lgb['early_stopping_round'] = 10\n",
    "params_lgb['metric'] = 'rmse'\n",
    "params_lgb['num_threads'] = -1\n",
    "params_lgb['seed'] = 0\n",
    "\n",
    "# Train data\n",
    "lgbm = lgb.train(params_lgb, edtrain, valid_sets=[edtrain, edval], verbose_eval=False)\n",
    "joblib.dump(lgbm, lgb_path + 'lgbm.pkl') # save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.1995306516062774\n",
      "Validation RMSE: 0.23088982559839394\n",
      "Test RMSE: 0.23073209469105768\n"
     ]
    }
   ],
   "source": [
    "# Train set RMSE\n",
    "pred_train = lgbm.predict(Xe_train_scaled) # make predictions\n",
    "pred_train[pred_train < 0] = 0 # replace negative predictions with 0\n",
    "rmse_train = np.sqrt(mean_squared_error(ye_train, pred_train)) # RMSE\n",
    "print('Train RMSE:', rmse_train)\n",
    "\n",
    "# Validation set RMSE\n",
    "pred_val = lgbm.predict(Xe_val_scaled) # make predictions\n",
    "pred_val[pred_val < 0] = 0 # replace negative predictions with 0\n",
    "rmse_val = np.sqrt(mean_squared_error(ye_val, pred_val)) # RMSE\n",
    "print('Validation RMSE:', rmse_val)\n",
    "\n",
    "# Test set RMSE\n",
    "pred_test = lgbm.predict(Xe_test_scaled) # make predictions\n",
    "pred_test[pred_test < 0] = 0 # replace negative predictions with 0\n",
    "rmse_test = np.sqrt(mean_squared_error(ye_test, pred_test)) # RMSE\n",
    "print('Test RMSE:', rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del edtrain, edval, pred_train, rmse_train, pred_val, rmse_val, pred_test, rmse_test, lgb_path, start_lgb, end_lgb\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finished trials: 101\n",
    "Best trial: 0.23179190098693012\n",
    "Best parameters:\n",
    "{'learning_rate': 0.08318870089692557,\n",
    " 'lambda_l1': 0.0074992163884415545,\n",
    " 'lambda_l2': 2.9505901993515122,\n",
    " 'max_depth': 92,\n",
    " 'num_leaves': 1929,\n",
    " 'min_data_in_leaf': 13,\n",
    " 'bagging_fraction': 0.7334916237773891,\n",
    " 'feature_fraction': 0.8102168078812939}\n",
    "\n",
    "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104431 seconds.\n",
    "You can set `force_row_wise=true` to remove the overhead.\n",
    "And if memory is not enough, you can set `force_col_wise=true`.\n",
    "[LightGBM] [Info] Total Bins 1880\n",
    "[LightGBM] [Info] Number of data points in the train set: 6888971, number of used features: 15\n",
    "[LightGBM] [Info] Start training from score 4.106192\n",
    "\n",
    "Train RMSE: 0.1995306516062774\n",
    "Validation RMSE: 0.23088982559839394\n",
    "Test RMSE: 0.23073209469105768"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "XGBoost is another implementation of gradiant boosting that is optimized with the features in the image below.\n",
    "\n",
    "![XGBoost](src/imgs/xgb.png)\n",
    "\n",
    "Source: https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d\n",
    "\n",
    "As with LightGBM, we will be using `Optuna` to optimize XGBoost's parameters, and similar parameters at that. Again, we must define an objective function for the Optuna study to call on every trial. The objective function will do the following:\n",
    "1. Save the study object\n",
    "2. Define the parameters to tune and distribution of values to search for each parameter\n",
    "3. Create an XGBoost `DMatrix` object for the data\n",
    "4. Train model\n",
    "5. Evaluate model on the validation set using the RMSE\n",
    "    - Negative predictions are replaced with 0 before evaluation\n",
    "6. Return the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for Optuna study\n",
    "xgb_path = '../models/electricity/xgb/'\n",
    "udf.mkdir(xgb_path)\n",
    "\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    \n",
    "    \"\"\" Objective function for Optuna study to optimize model hyperparameters \"\"\"\n",
    "    \n",
    "    # Save study\n",
    "    print(dt.datetime.now(), '| Finished trials:', len(study_xgb.trials))\n",
    "    print()\n",
    "    joblib.dump(study_xgb, xgb_path + 'study_xgb.pkl')\n",
    "    \n",
    "    # XGBoost parameters to tune\n",
    "    params = {\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 2e-1),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e1),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-4, 1e1),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 200),\n",
    "        'max_leaves': trial.suggest_int('max_leaves', 2, 4096),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        'eval_metric': 'rmse',\n",
    "        'seed': 0\n",
    "    }\n",
    "    \n",
    "    # XGBoost dmatrix objects\n",
    "    dtrain = xgb.DMatrix(Xe_val_scaled, label=ye_val)\n",
    "    dval = xgb.DMatrix(Xe_test_scaled, label=ye_test)\n",
    "    \n",
    "    # Train model\n",
    "    xg = xgb.train(params, dtrain, \n",
    "                   evals=[(dtrain, 'train'), (dval, 'valid')],\n",
    "                   num_boost_round=100, \n",
    "                   early_stopping_rounds=10,\n",
    "                   verbose_eval=False)\n",
    "    \n",
    "    # Make and evaluate predictions on validation set\n",
    "    pred = xg.predict(dval)\n",
    "    pred[pred < 0] = 0 # replace negative predictions with 0\n",
    "    loss = np.sqrt(mean_squared_error(ye_test, pred)) # RMSE\n",
    "\n",
    "#     # Cross validation on train set (no validation set)\n",
    "#     cv = xgb.cv(params, dtrain, folds=KFold(10, shuffle=True, random_state=0), verbose_eval=False)\n",
    "#     loss = cv['rmse-mean'][-1]\n",
    "    \n",
    "    # RMSE\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start time\n",
    "# start_xgb = dt.datetime.now()\n",
    "# print('Start:', start_xgb)\n",
    "\n",
    "# # Run trials\n",
    "# study_xgb = optuna.create_study(direction='minimize')\n",
    "# study_xgb.optimize(objective_xgb, n_trials=100)\n",
    "# joblib.dump(study_xgb, xgb_path + 'study_xgb.pkl') # Save study after last trial\n",
    "\n",
    "# # End time and total run time\n",
    "# end_xgb = dt.datetime.now()\n",
    "# print('End:', end_xgb)\n",
    "# print('Run time:', end_xgb - start_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2021-01-14 14:11:19.631388\n",
      "2021-01-14 14:11:19.650167 | Finished trials: 95\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-01-14 14:34:41,537] Trial 94 finished with value: 0.1715300977230072 and parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.1533402225402267, 'alpha': 0.00019917861014242014, 'lambda': 1.1972363798842338, 'gamma': 0.0018107265529473087, 'max_depth': 39, 'max_leaves': 795, 'subsample': 0.9304129866341228, 'colsample_bytree': 0.9989000734678424}. Best is trial 88 with value: 0.16957750916481018.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14 14:34:41.591784 | Finished trials: 96\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-01-14 15:02:32,257] Trial 95 finished with value: 0.17265385389328003 and parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.09182084537307542, 'alpha': 0.00044144230927467586, 'lambda': 4.449487615510002, 'gamma': 0.00017617278495483244, 'max_depth': 63, 'max_leaves': 626, 'subsample': 0.8812040029521067, 'colsample_bytree': 0.9245996220784722}. Best is trial 88 with value: 0.16957750916481018.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14 15:02:32.271293 | Finished trials: 97\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-01-14 15:41:46,520] Trial 96 finished with value: 0.17049871385097504 and parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.12031834811738326, 'alpha': 0.00028400469686020466, 'lambda': 1.6219608495117108, 'gamma': 0.0003554055327946864, 'max_depth': 52, 'max_leaves': 1122, 'subsample': 0.903171232862659, 'colsample_bytree': 0.9684595210379997}. Best is trial 88 with value: 0.16957750916481018.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14 15:41:46.553130 | Finished trials: 98\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-01-14 16:26:09,409] Trial 97 finished with value: 0.17035287618637085 and parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.12111439684310885, 'alpha': 0.00010403362565381818, 'lambda': 0.9018804290487774, 'gamma': 0.0006928286605959651, 'max_depth': 53, 'max_leaves': 982, 'subsample': 0.923017482172553, 'colsample_bytree': 0.9997475493605211}. Best is trial 88 with value: 0.16957750916481018.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14 16:26:09.444097 | Finished trials: 99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-01-14 17:26:15,113] Trial 98 finished with value: 0.1739557385444641 and parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.19971458978206794, 'alpha': 0.0010281475314162802, 'lambda': 1.5743240737692605, 'gamma': 0.0004397800647038333, 'max_depth': 74, 'max_leaves': 930, 'subsample': 0.9549442630360018, 'colsample_bytree': 0.9822048071011065}. Best is trial 88 with value: 0.16957750916481018.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14 17:26:15.193747 | Finished trials: 100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-01-14 17:43:54,316] Trial 99 finished with value: 0.17423996329307556 and parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.053960587650421846, 'alpha': 0.000556121290239216, 'lambda': 2.1356058645118465, 'gamma': 0.00087409824828435, 'max_depth': 37, 'max_leaves': 1255, 'subsample': 0.9808713551018198, 'colsample_bytree': 0.9665814617525953}. Best is trial 88 with value: 0.16957750916481018.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14 17:43:54.323831 | Finished trials: 101\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-01-14 18:18:24,165] Trial 100 finished with value: 0.1719323992729187 and parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.09587679054999948, 'alpha': 0.00015308713047560254, 'lambda': 3.4926807130459037, 'gamma': 0.0003186731787019137, 'max_depth': 80, 'max_leaves': 1405, 'subsample': 0.8941761068336549, 'colsample_bytree': 0.9392034109389809}. Best is trial 88 with value: 0.16957750916481018.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14 18:18:24.183991 | Finished trials: 102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-01-14 19:07:19,669] Trial 101 finished with value: 0.17125293612480164 and parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.1277068142020639, 'alpha': 0.00032711811836960843, 'lambda': 1.0482352021710821, 'gamma': 0.0005679383243019158, 'max_depth': 56, 'max_leaves': 671, 'subsample': 0.8521861590529589, 'colsample_bytree': 0.9786291063711575}. Best is trial 88 with value: 0.16957750916481018.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14 19:07:19.808147 | Finished trials: 103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-01-14 19:47:35,299] Trial 102 finished with value: 0.1693050116300583 and parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.09897522425910911, 'alpha': 0.0007631264300296365, 'lambda': 2.4504122928666554, 'gamma': 0.001191775797167784, 'max_depth': 63, 'max_leaves': 1086, 'subsample': 0.9443322952938715, 'colsample_bytree': 0.9518408116816858}. Best is trial 102 with value: 0.1693050116300583.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14 19:47:35.324425 | Finished trials: 104\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-01-14 20:31:34,627] Trial 103 finished with value: 0.1696968525648117 and parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.09799406535565086, 'alpha': 0.0007210224934710539, 'lambda': 2.793557311099988, 'gamma': 0.0013813201154939494, 'max_depth': 63, 'max_leaves': 750, 'subsample': 0.941919296077924, 'colsample_bytree': 0.9551562915800498}. Best is trial 102 with value: 0.1693050116300583.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14 20:31:34.666706 | Finished trials: 105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-01-14 21:04:29,242] Trial 104 finished with value: 0.17243477702140808 and parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.09583246932333232, 'alpha': 0.001490006936058583, 'lambda': 7.300178759188074, 'gamma': 0.0015751298833397707, 'max_depth': 63, 'max_leaves': 1038, 'subsample': 0.9412149313031377, 'colsample_bytree': 0.9056075514745967}. Best is trial 102 with value: 0.1693050116300583.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14 21:04:29.277078 | Finished trials: 106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-01-14 21:28:08,659] Trial 105 finished with value: 0.17222410440444946 and parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.058759242441350695, 'alpha': 0.0007475459139512703, 'lambda': 2.489247058264496, 'gamma': 0.002332833929094313, 'max_depth': 86, 'max_leaves': 932, 'subsample': 0.9737547962738097, 'colsample_bytree': 0.95375668496011}. Best is trial 102 with value: 0.1693050116300583.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14 21:28:08.686715 | Finished trials: 107\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-01-14 22:25:39,294] Trial 106 finished with value: 0.1750892549753189 and parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.158760156810594, 'alpha': 0.00041417129258659044, 'lambda': 1.1333873878758576, 'gamma': 0.0033879683143398977, 'max_depth': 72, 'max_leaves': 785, 'subsample': 0.9483272147410655, 'colsample_bytree': 0.9277140480786281}. Best is trial 102 with value: 0.1693050116300583.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14 22:25:39.361951 | Finished trials: 108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-01-14 22:53:38,230] Trial 107 finished with value: 0.17043939232826233 and parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.07707308304792086, 'alpha': 0.00020837450669252566, 'lambda': 3.0615890986089758, 'gamma': 0.0010950966063897625, 'max_depth': 43, 'max_leaves': 730, 'subsample': 0.9334654284887309, 'colsample_bytree': 0.9883394942793433}. Best is trial 102 with value: 0.1693050116300583.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14 22:53:38.250478 | Finished trials: 109\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-01-14 23:12:07,647] Trial 108 finished with value: 0.17215386033058167 and parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.14427324572128167, 'alpha': 0.0012022311161534877, 'lambda': 2.0390089172575316, 'gamma': 0.000795012382313119, 'max_depth': 31, 'max_leaves': 1198, 'subsample': 0.8709067703640782, 'colsample_bytree': 0.9502897034533823}. Best is trial 102 with value: 0.1693050116300583.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14 23:12:07.655062 | Finished trials: 110\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-01-14 23:56:31,831] Trial 109 finished with value: 0.1747255027294159 and parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.18012557454103145, 'alpha': 0.0021006008944627376, 'lambda': 4.902694679294649, 'gamma': 0.0005092949251948125, 'max_depth': 65, 'max_leaves': 600, 'subsample': 0.9245891688444929, 'colsample_bytree': 0.9992498512814884}. Best is trial 102 with value: 0.1693050116300583.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14 23:56:31.882374 | Finished trials: 111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-01-15 00:46:20,804] Trial 110 finished with value: 0.16978587210178375 and parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.09820515574671844, 'alpha': 0.000767765618863153, 'lambda': 0.9268417077436988, 'gamma': 0.001273089135952361, 'max_depth': 76, 'max_leaves': 916, 'subsample': 0.9827793122487057, 'colsample_bytree': 0.9681461535557897}. Best is trial 102 with value: 0.1693050116300583.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End: 2021-01-15 00:46:20.936815\n",
      "Run time: 10:35:01.305427\n"
     ]
    }
   ],
   "source": [
    "# # Start time\n",
    "# start_xgb = dt.datetime.now()\n",
    "# print('Start:', start_xgb)\n",
    "\n",
    "# # Continue trials\n",
    "# study_xgb = joblib.load(xgb_path + 'study_xgb.pkl')\n",
    "# study_xgb.optimize(objective_xgb, n_trials=50)\n",
    "# joblib.dump(study_xgb, xgb_path + 'study_xgb.pkl') # Save study after last trial\n",
    "\n",
    "# # End time and total run time\n",
    "# end_xgb = dt.datetime.now()\n",
    "# print('End:', end_xgb)\n",
    "# print('Run time:', end_xgb - start_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trials: 111\n",
      "Best trial: 0.1693050116300583\n",
      "Best parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'grow_policy': 'lossguide',\n",
       " 'learning_rate': 0.09897522425910911,\n",
       " 'alpha': 0.0007631264300296365,\n",
       " 'lambda': 2.4504122928666554,\n",
       " 'gamma': 0.001191775797167784,\n",
       " 'max_depth': 63,\n",
       " 'max_leaves': 1086,\n",
       " 'subsample': 0.9443322952938715,\n",
       " 'colsample_bytree': 0.9518408116816858}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Study results\n",
    "study_xgb = joblib.load(xgb_path + 'study_xgb.pkl')\n",
    "print('Finished trials:', len(study_xgb.trials))\n",
    "print('Best trial:', study_xgb.best_trial.value)\n",
    "print('Best parameters:')\n",
    "params_xgb = dict(study_xgb.best_trial.params)\n",
    "params_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/electricity/xgb/xgbm.pkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost dmatrices\n",
    "edtrain = xgb.DMatrix(Xe_train_scaled, label=ye_train)\n",
    "edval = xgb.DMatrix(Xe_val_scaled, label=ye_val)\n",
    "edtest = xgb.DMatrix(Xe_test_scaled, label=ye_test)\n",
    "\n",
    "# Parameters\n",
    "params_xgb['eval_metric'] = 'rmse'\n",
    "params_xgb['seed'] = 0\n",
    "\n",
    "# Train data\n",
    "xg = xgb.train(params_xgb, edtrain, \n",
    "               evals=[(edtrain, 'train'), (edval, 'valid')], \n",
    "               num_boost_round=100,\n",
    "               early_stopping_rounds=10,\n",
    "               verbose_eval=False)\n",
    "joblib.dump(xg, xgb_path + 'xgbm.pkl') # save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.2477201\n",
      "Validation RMSE: 0.42980975\n",
      "Test RMSE: 0.43017015\n"
     ]
    }
   ],
   "source": [
    "# Train set RMSE\n",
    "pred_train = xg.predict(edtrain)  # make predictions\n",
    "pred_train[pred_train < 0] = 0 # replace negative predictions with 0\n",
    "rmse_train = np.sqrt(mean_squared_error(ye_train, pred_train)) # RMSE\n",
    "print('Train RMSE:', rmse_train)\n",
    "\n",
    "# Validation set RMSE\n",
    "pred_val = xg.predict(edval)  # make predictions\n",
    "pred_val[pred_val < 0] = 0 # replace negative predictions with 0\n",
    "rmse_val = np.sqrt(mean_squared_error(ye_val, pred_val)) # RMSE\n",
    "print('Validation RMSE:', rmse_val)\n",
    "\n",
    "# Test set RMSE\n",
    "pred_test = xg.predict(edtest)  # make predictions\n",
    "pred_test[pred_test < 0] = 0 # replace negative predictions with 0\n",
    "rmse_test = np.sqrt(mean_squared_error(ye_test, pred_test)) # RMSE\n",
    "print('Test RMSE:', rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del edtrain, edval, edtest, pred_train, rmse_train, pred_val, rmse_val, pred_test, rmse_test, xgb_path, start_xgb, end_xgb\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finished trials: 111\n",
    "Best trial: 0.1693050116300583\n",
    "Best parameters:\n",
    "{'grow_policy': 'lossguide',\n",
    " 'learning_rate': 0.09897522425910911,\n",
    " 'alpha': 0.0007631264300296365,\n",
    " 'lambda': 2.4504122928666554,\n",
    " 'gamma': 0.001191775797167784,\n",
    " 'max_depth': 63,\n",
    " 'max_leaves': 1086,\n",
    " 'subsample': 0.9443322952938715,\n",
    " 'colsample_bytree': 0.9518408116816858}\n",
    " \n",
    "Train RMSE: 0.2477201\n",
    "Validation RMSE: 0.42980975\n",
    "Test RMSE: 0.43017015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section IV: Electricity Modeling Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
