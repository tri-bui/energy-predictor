{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Energy Predictor - Modeling (Electricity Meters)\n",
    "#### Hosted by: ASHRAE\n",
    "##### Source: https://www.kaggle.com/c/ashrae-energy-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section I: Dependencies and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import gc\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import src.utils as udf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "# Plot settings\n",
    "mpl.style.use('seaborn')\n",
    "mpl.rcParams['figure.figsize'] = (15, 3)\n",
    "mpl.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/03-feat-out'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data path\n",
    "data_path = os.path.join('..', 'data', '03-feat-out')\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11481619 entries, 0 to 18205341\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   site_id             uint8         \n",
      " 1   building_id         uint16        \n",
      " 2   timestamp           datetime64[ns]\n",
      " 3   meter_reading       float32       \n",
      " 4   air_temperature     float32       \n",
      " 5   dew_temperature     float32       \n",
      " 6   rel_humidity        float32       \n",
      " 7   sea_level_pressure  float32       \n",
      " 8   wind_speed          float32       \n",
      " 9   wind_direction_x    float32       \n",
      " 10  wind_direction_y    float32       \n",
      " 11  primary_use         object        \n",
      " 12  square_feet         uint32        \n",
      " 13  year_built          uint16        \n",
      " 14  missing_year        uint8         \n",
      " 15  country             object        \n",
      " 16  dayofyear           uint16        \n",
      " 17  month               uint8         \n",
      " 18  hour                uint8         \n",
      " 19  dayofweek           uint8         \n",
      " 20  is_weekend          uint8         \n",
      " 21  is_holiday          int8          \n",
      "dtypes: datetime64[ns](1), float32(8), int8(1), object(2), uint16(3), uint32(1), uint8(6)\n",
      "memory usage: 886.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Electricity meter data\n",
    "electricity = pd.read_pickle(os.path.join(data_path, 'electricity.pkl'))\n",
    "electricity.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3507966 entries, 70 to 18205292\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   site_id             uint8         \n",
      " 1   building_id         uint16        \n",
      " 2   timestamp           datetime64[ns]\n",
      " 3   meter_reading       float32       \n",
      " 4   air_temperature     float32       \n",
      " 5   dew_temperature     float32       \n",
      " 6   rel_humidity        float32       \n",
      " 7   sea_level_pressure  float32       \n",
      " 8   wind_speed          float32       \n",
      " 9   wind_direction_x    float32       \n",
      " 10  wind_direction_y    float32       \n",
      " 11  primary_use         object        \n",
      " 12  square_feet         uint32        \n",
      " 13  year_built          uint16        \n",
      " 14  missing_year        uint8         \n",
      " 15  country             object        \n",
      " 16  dayofyear           uint16        \n",
      " 17  month               uint8         \n",
      " 18  hour                uint8         \n",
      " 19  dayofweek           uint8         \n",
      " 20  is_weekend          uint8         \n",
      " 21  is_holiday          int8          \n",
      "dtypes: datetime64[ns](1), float32(8), int8(1), object(2), uint16(3), uint32(1), uint8(6)\n",
      "memory usage: 271.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Chilled water meter data\n",
    "chilledwater = pd.read_pickle(os.path.join(data_path, 'chilledwater.pkl'))\n",
    "chilledwater.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2296049 entries, 762 to 18205336\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   site_id             uint8         \n",
      " 1   building_id         uint16        \n",
      " 2   timestamp           datetime64[ns]\n",
      " 3   meter_reading       float32       \n",
      " 4   air_temperature     float32       \n",
      " 5   dew_temperature     float32       \n",
      " 6   rel_humidity        float32       \n",
      " 7   sea_level_pressure  float32       \n",
      " 8   wind_speed          float32       \n",
      " 9   wind_direction_x    float32       \n",
      " 10  wind_direction_y    float32       \n",
      " 11  primary_use         object        \n",
      " 12  square_feet         uint32        \n",
      " 13  year_built          uint16        \n",
      " 14  missing_year        uint8         \n",
      " 15  country             object        \n",
      " 16  dayofyear           uint16        \n",
      " 17  month               uint8         \n",
      " 18  hour                uint8         \n",
      " 19  dayofweek           uint8         \n",
      " 20  is_weekend          uint8         \n",
      " 21  is_holiday          int8          \n",
      "dtypes: datetime64[ns](1), float32(8), int8(1), object(2), uint16(3), uint32(1), uint8(6)\n",
      "memory usage: 177.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Steam meter data\n",
    "steam = pd.read_pickle(os.path.join(data_path, 'steam.pkl'))\n",
    "steam.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 919708 entries, 10 to 18205124\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   site_id             919708 non-null  uint8         \n",
      " 1   building_id         919708 non-null  uint16        \n",
      " 2   timestamp           919708 non-null  datetime64[ns]\n",
      " 3   meter_reading       919708 non-null  float32       \n",
      " 4   air_temperature     919708 non-null  float32       \n",
      " 5   dew_temperature     919708 non-null  float32       \n",
      " 6   rel_humidity        919708 non-null  float32       \n",
      " 7   sea_level_pressure  919708 non-null  float32       \n",
      " 8   wind_speed          919708 non-null  float32       \n",
      " 9   wind_direction_x    919708 non-null  float32       \n",
      " 10  wind_direction_y    919708 non-null  float32       \n",
      " 11  primary_use         919708 non-null  object        \n",
      " 12  square_feet         919708 non-null  uint32        \n",
      " 13  year_built          919708 non-null  uint16        \n",
      " 14  missing_year        919708 non-null  uint8         \n",
      " 15  country             919708 non-null  object        \n",
      " 16  dayofyear           919708 non-null  uint16        \n",
      " 17  month               919708 non-null  uint8         \n",
      " 18  hour                919708 non-null  uint8         \n",
      " 19  dayofweek           919708 non-null  uint8         \n",
      " 20  is_weekend          919708 non-null  uint8         \n",
      " 21  is_holiday          919708 non-null  int8          \n",
      "dtypes: datetime64[ns](1), float32(8), int8(1), object(2), uint16(3), uint32(1), uint8(6)\n",
      "memory usage: 71.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Hot water meter data\n",
    "hotwater = pd.read_pickle(os.path.join(data_path, 'hotwater.pkl'))\n",
    "hotwater.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_corr</th>\n",
       "      <th>lasso_coef</th>\n",
       "      <th>lasso_coef_recursive</th>\n",
       "      <th>tree_importance</th>\n",
       "      <th>tree_importance_recursive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>square_feet</td>\n",
       "      <td>primary_use</td>\n",
       "      <td>primary_use</td>\n",
       "      <td>square_feet</td>\n",
       "      <td>site_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>country</td>\n",
       "      <td>square_feet</td>\n",
       "      <td>square_feet</td>\n",
       "      <td>year_built</td>\n",
       "      <td>air_temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>country</td>\n",
       "      <td>missing_year</td>\n",
       "      <td>country</td>\n",
       "      <td>primary_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>is_weekend</td>\n",
       "      <td>country</td>\n",
       "      <td></td>\n",
       "      <td>square_feet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>dayofyear</td>\n",
       "      <td></td>\n",
       "      <td>year_built</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hour</td>\n",
       "      <td></td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>is_weekend</td>\n",
       "      <td></td>\n",
       "      <td>dayofyear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>is_holiday</td>\n",
       "      <td></td>\n",
       "      <td>hour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_corr   lasso_coef lasso_coef_recursive tree_importance  \\\n",
       "0  square_feet  primary_use          primary_use     square_feet   \n",
       "1      country  square_feet          square_feet      year_built   \n",
       "2                   country         missing_year         country   \n",
       "3                is_weekend              country                   \n",
       "4                                      dayofyear                   \n",
       "5                                           hour                   \n",
       "6                                     is_weekend                   \n",
       "7                                     is_holiday                   \n",
       "\n",
       "  tree_importance_recursive  \n",
       "0                   site_id  \n",
       "1           air_temperature  \n",
       "2               primary_use  \n",
       "3               square_feet  \n",
       "4                year_built  \n",
       "5                   country  \n",
       "6                 dayofyear  \n",
       "7                      hour  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected feats table\n",
    "feats = pd.read_pickle(os.path.join(data_path, 'feats.pkl'))\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean vars\n",
    "del data_path\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section II: Featurization - Electricity\n",
    "\n",
    "Once again, we will be working primarily with the electricity meter data as it contains the most readings and the process used here will be repeated for the other 3 meters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unused features\n",
    "\n",
    "We will be dropping the features we found to be unnecessary in the featurization notebook - `site_id`, `building_id`, `dew_temperature`, `timestamp`, `month`, `dayofweek`. `Site_id` was added here because we have the `country` feature which is a good proxy for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>rel_humidity</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction_x</th>\n",
       "      <th>wind_direction_y</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>missing_year</th>\n",
       "      <th>country</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.603682</td>\n",
       "      <td>19.4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1019.400024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Parking</td>\n",
       "      <td>387638</td>\n",
       "      <td>1997</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.364478</td>\n",
       "      <td>19.4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1019.400024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Office</td>\n",
       "      <td>33370</td>\n",
       "      <td>1982</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.303600</td>\n",
       "      <td>3.8</td>\n",
       "      <td>90.549408</td>\n",
       "      <td>1020.900024</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>Education</td>\n",
       "      <td>50623</td>\n",
       "      <td>1960</td>\n",
       "      <td>1</td>\n",
       "      <td>EU</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meter_reading  air_temperature  rel_humidity  sea_level_pressure  \\\n",
       "0      12.603682             19.4    100.000000         1019.400024   \n",
       "1      15.364478             19.4    100.000000         1019.400024   \n",
       "2      23.303600              3.8     90.549408         1020.900024   \n",
       "\n",
       "   wind_speed  wind_direction_x  wind_direction_y primary_use  square_feet  \\\n",
       "0         0.0               0.0          0.000000     Parking       387638   \n",
       "1         0.0               0.0          0.000000      Office        33370   \n",
       "2         3.1              -0.5         -0.866025   Education        50623   \n",
       "\n",
       "   year_built  missing_year country  dayofyear  hour  is_weekend  is_holiday  \n",
       "0        1997             0      US          1     0           0           1  \n",
       "1        1982             0      US          1     0           0           1  \n",
       "2        1960             1      EU          1     0           0           1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop feats\n",
    "to_drop = ['site_id', 'building_id', 'dew_temperature', 'timestamp', 'month', 'dayofweek']\n",
    "electricity.drop(to_drop, axis=1, inplace=True)\n",
    "electricity.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split\n",
    "\n",
    "The same 70-12-18 data split will be done here. Variables will be suffixed with \"e\" to indicate that it is `electricity` meter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11481619, 15), (11481619,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split feats and target\n",
    "Xe = electricity.drop('meter_reading', axis=1).copy()\n",
    "ye = electricity['meter_reading'].copy()\n",
    "Xe.shape, ye.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target distribution\n",
    "ye.plot(kind='hist', bins=200, title='Target Distribution', xlim=(0, 3e3))\n",
    "plt.xlabel('Electricity meter reading')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw meter readings are highly right-skewed. We may be able to get more accurate predictions if we transform the target variable into a normal distribution to increase its linearity with the features. To do this, we will do a log transformation on the target variable and train our models using the log-transformed target. Of course, when making predictions, the output will be log-transformed values, so the predictions will have to be inverse-transformed to yield the true output.\n",
    "\n",
    "Note: the target variable contains meter readings of 0, so 1 will be added to all readings before taking the log (because log(0) is undefined) like this: `y_log_transformed = log(y + 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Log transform the target var\n",
    "ye_log = np.log1p(ye)\n",
    "ye_log.plot.hist(bins=50, title='Log-transformed Target Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (8037133, 15) (8037133,)\n",
      "Validation set: (1377794, 15) (1377794,)\n",
      "Test set: (2066692, 15) (2066692,)\n"
     ]
    }
   ],
   "source": [
    "# Train/val/test split (70/12/18)\n",
    "Xe_train, Xe_test, ye_train, ye_test = train_test_split(Xe, ye_log, test_size=0.3, random_state=30)\n",
    "Xe_val, Xe_test, ye_val, ye_test = train_test_split(Xe_test, ye_test, test_size=0.6, random_state=30)\n",
    "\n",
    "print('Train set:', Xe_train.shape, ye_train.shape)\n",
    "print('Validation set:', Xe_val.shape, ye_val.shape)\n",
    "print('Test set:', Xe_test.shape, ye_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24477"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean vars\n",
    "del Xe, ye, ye_log\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical feature encoding\n",
    "\n",
    "Next, we will perform the 2 types of categorical encoding as in the featurization notebook:\n",
    "1. Rare label categorical encoding - categorical labels that occur less than 5% in the data will be encoded as \"Rare\"\n",
    "    - This will be done for `primary_use`\n",
    "2. Mean target categorical encoding - categorical labels will be numerically encoded with the mean value of the target label for that particular label\n",
    "    - This will be done for `primary_use` and `country`\n",
    "    - Note: countries \"UK\" and \"IE\" were grouped into the label \"EU\"\n",
    "    \n",
    "The difference here is that the target label has been log-transformed, so the encoded values here will differ from the featurization notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'primary_use': Index(['Education', 'Office', 'Entertainment/public assembly',\n",
       "        'Public services', 'Lodging/residential'],\n",
       "       dtype='object')}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group all rare primary use categories\n",
    "Xe_train, Xe_val, Xe_test, rare_dict = udf.rare_encoder(['primary_use'], Xe_train, Xe_test, val=Xe_val)\n",
    "rare_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train set #####\n",
      "Education                        3076745\n",
      "Office                           1527749\n",
      "Entertainment/public assembly    1016074\n",
      "Public services                   919271\n",
      "Lodging/residential               791749\n",
      "Rare                              705545\n",
      "Name: primary_use, dtype: int64\n",
      "\n",
      "##### Validation set #####\n",
      "Education                        526501\n",
      "Office                           261779\n",
      "Entertainment/public assembly    174535\n",
      "Public services                  158071\n",
      "Lodging/residential              135833\n",
      "Rare                             121075\n",
      "Name: primary_use, dtype: int64\n",
      "\n",
      "##### Test set #####\n",
      "Education                        790059\n",
      "Office                           391993\n",
      "Entertainment/public assembly    262638\n",
      "Public services                  236376\n",
      "Lodging/residential              204139\n",
      "Rare                             181487\n",
      "Name: primary_use, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Primary use counts\n",
    "print('##### Train set #####')\n",
    "print(Xe_train['primary_use'].value_counts())\n",
    "print('\\n##### Validation set #####')\n",
    "print(Xe_val['primary_use'].value_counts())\n",
    "print('\\n##### Test set #####')\n",
    "print(Xe_test['primary_use'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'primary_use': {'Education': 4.467979431152344,\n",
       "  'Entertainment/public assembly': 3.522857666015625,\n",
       "  'Lodging/residential': 3.975877046585083,\n",
       "  'Office': 4.195546627044678,\n",
       "  'Public services': 3.761206865310669,\n",
       "  'Rare': 3.770613193511963},\n",
       " 'country': {'CA': 6.633710861206055,\n",
       "  'EU': 3.41705322265625,\n",
       "  'US': 4.179178237915039}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode categorical feats using the mean target of each category\n",
    "Xe_train, Xe_val, Xe_test, mean_dict = udf.mean_encoder(['primary_use', 'country'], \n",
    "                                                        Xe_train, ye_train, Xe_test, X_val=Xe_val)\n",
    "mean_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train set: primary_use #####\n",
      "4.467979    3076745\n",
      "4.195547    1527749\n",
      "3.522858    1016074\n",
      "3.761207     919271\n",
      "3.975877     791749\n",
      "3.770613     705545\n",
      "Name: primary_use, dtype: int64\n",
      "\n",
      "##### Train set: country #####\n",
      "4.179178    6867059\n",
      "3.417053    1075257\n",
      "6.633711      94817\n",
      "Name: country, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Encoded val counts in train set\n",
    "print('##### Train set: primary_use #####')\n",
    "print(Xe_train['primary_use'].value_counts())\n",
    "print('\\n##### Train set: country #####')\n",
    "print(Xe_train['country'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>rel_humidity</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction_x</th>\n",
       "      <th>wind_direction_y</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>missing_year</th>\n",
       "      <th>country</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.023356</td>\n",
       "      <td>-0.728482</td>\n",
       "      <td>0.931492</td>\n",
       "      <td>-1.532234</td>\n",
       "      <td>0.065809</td>\n",
       "      <td>0.09452</td>\n",
       "      <td>0.258197</td>\n",
       "      <td>-0.589271</td>\n",
       "      <td>0.177163</td>\n",
       "      <td>0.902634</td>\n",
       "      <td>0.19275</td>\n",
       "      <td>0.761807</td>\n",
       "      <td>0.794293</td>\n",
       "      <td>1.577957</td>\n",
       "      <td>-0.180435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.815406</td>\n",
       "      <td>-2.340778</td>\n",
       "      <td>-0.322773</td>\n",
       "      <td>-1.532234</td>\n",
       "      <td>0.065809</td>\n",
       "      <td>0.09452</td>\n",
       "      <td>-1.685188</td>\n",
       "      <td>-0.676851</td>\n",
       "      <td>-2.273199</td>\n",
       "      <td>-1.107869</td>\n",
       "      <td>0.19275</td>\n",
       "      <td>-1.171445</td>\n",
       "      <td>0.071957</td>\n",
       "      <td>1.577957</td>\n",
       "      <td>-0.180435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.567442</td>\n",
       "      <td>-0.927504</td>\n",
       "      <td>0.472939</td>\n",
       "      <td>-1.532234</td>\n",
       "      <td>0.065809</td>\n",
       "      <td>0.09452</td>\n",
       "      <td>-0.996602</td>\n",
       "      <td>-0.745909</td>\n",
       "      <td>-0.246938</td>\n",
       "      <td>0.902634</td>\n",
       "      <td>0.19275</td>\n",
       "      <td>-1.676185</td>\n",
       "      <td>-1.661652</td>\n",
       "      <td>-0.633731</td>\n",
       "      <td>-0.180435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   air_temperature  rel_humidity  sea_level_pressure  wind_speed  \\\n",
       "0        -0.023356     -0.728482            0.931492   -1.532234   \n",
       "1         0.815406     -2.340778           -0.322773   -1.532234   \n",
       "2        -1.567442     -0.927504            0.472939   -1.532234   \n",
       "\n",
       "   wind_direction_x  wind_direction_y  primary_use  square_feet  year_built  \\\n",
       "0          0.065809           0.09452     0.258197    -0.589271    0.177163   \n",
       "1          0.065809           0.09452    -1.685188    -0.676851   -2.273199   \n",
       "2          0.065809           0.09452    -0.996602    -0.745909   -0.246938   \n",
       "\n",
       "   missing_year  country  dayofyear      hour  is_weekend  is_holiday  \n",
       "0      0.902634  0.19275   0.761807  0.794293    1.577957   -0.180435  \n",
       "1     -1.107869  0.19275  -1.171445  0.071957    1.577957   -0.180435  \n",
       "2      0.902634  0.19275  -1.676185 -1.661652   -0.633731   -0.180435  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale feats using their mean and stdev\n",
    "Xe_train_scaled, Xe_val_scaled, Xe_test_scaled = udf.scale_feats(Xe_train, Xe_test, val=Xe_val)\n",
    "Xe_train_scaled.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean vars\n",
    "del Xe_train, Xe_val, Xe_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature sets\n",
    "\n",
    "Building on the featurization notebook, we will be creating several feature sets for model training to try see if we can get better predictions:\n",
    "1. All features (15) - full feature set\n",
    "2. Custom features (10) - drop the 5 features that were selected 0 times in the featurization notebook\n",
    "    - `rel_humidity`, `sea_level_pressure`, `wind_direction_x`, `wind_direction_y`, `wind_speed`\n",
    "3. Lasso RFE features (8) - features selected from the lasso RFE method\n",
    "4. Tree RFE features (7) - features selected from the decision tree RFE method, except for `site_id`, which was just dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_corr</th>\n",
       "      <th>lasso_coef</th>\n",
       "      <th>lasso_coef_recursive</th>\n",
       "      <th>tree_importance</th>\n",
       "      <th>tree_importance_recursive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>square_feet</td>\n",
       "      <td>primary_use</td>\n",
       "      <td>primary_use</td>\n",
       "      <td>square_feet</td>\n",
       "      <td>site_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>country</td>\n",
       "      <td>square_feet</td>\n",
       "      <td>square_feet</td>\n",
       "      <td>year_built</td>\n",
       "      <td>air_temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>country</td>\n",
       "      <td>missing_year</td>\n",
       "      <td>country</td>\n",
       "      <td>primary_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>is_weekend</td>\n",
       "      <td>country</td>\n",
       "      <td></td>\n",
       "      <td>square_feet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>dayofyear</td>\n",
       "      <td></td>\n",
       "      <td>year_built</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hour</td>\n",
       "      <td></td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>is_weekend</td>\n",
       "      <td></td>\n",
       "      <td>dayofyear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>is_holiday</td>\n",
       "      <td></td>\n",
       "      <td>hour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_corr   lasso_coef lasso_coef_recursive tree_importance  \\\n",
       "0  square_feet  primary_use          primary_use     square_feet   \n",
       "1      country  square_feet          square_feet      year_built   \n",
       "2                   country         missing_year         country   \n",
       "3                is_weekend              country                   \n",
       "4                                      dayofyear                   \n",
       "5                                           hour                   \n",
       "6                                     is_weekend                   \n",
       "7                                     is_holiday                   \n",
       "\n",
       "  tree_importance_recursive  \n",
       "0                   site_id  \n",
       "1           air_temperature  \n",
       "2               primary_use  \n",
       "3               square_feet  \n",
       "4                year_built  \n",
       "5                   country  \n",
       "6                 dayofyear  \n",
       "7                      hour  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected feats from notebook 03\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['air_temperature',\n",
       " 'rel_humidity',\n",
       " 'sea_level_pressure',\n",
       " 'wind_speed',\n",
       " 'wind_direction_x',\n",
       " 'wind_direction_y',\n",
       " 'primary_use',\n",
       " 'square_feet',\n",
       " 'year_built',\n",
       " 'missing_year',\n",
       " 'country',\n",
       " 'dayofyear',\n",
       " 'hour',\n",
       " 'is_weekend',\n",
       " 'is_holiday']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full feat set\n",
    "all_feats = Xe_train_scaled.columns.tolist()\n",
    "print(len(all_feats))\n",
    "all_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['air_temperature',\n",
       " 'primary_use',\n",
       " 'square_feet',\n",
       " 'year_built',\n",
       " 'missing_year',\n",
       " 'country',\n",
       " 'dayofyear',\n",
       " 'hour',\n",
       " 'is_weekend',\n",
       " 'is_holiday']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom feat set\n",
    "custom_drop = ['rel_humidity', 'sea_level_pressure', 'wind_direction_x', 'wind_direction_y', 'wind_speed']\n",
    "custom_feats = Xe_train_scaled.drop(custom_drop, axis=1).columns.tolist()\n",
    "\n",
    "print(len(custom_feats))\n",
    "custom_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['primary_use',\n",
       " 'square_feet',\n",
       " 'missing_year',\n",
       " 'country',\n",
       " 'dayofyear',\n",
       " 'hour',\n",
       " 'is_weekend',\n",
       " 'is_holiday']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso RFE feat set\n",
    "lasso_feats = feats['lasso_coef_recursive'].tolist()\n",
    "print(len(lasso_feats))\n",
    "lasso_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['air_temperature',\n",
       " 'primary_use',\n",
       " 'square_feet',\n",
       " 'year_built',\n",
       " 'country',\n",
       " 'dayofyear',\n",
       " 'hour']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree RFE feat set\n",
    "tree_feats = feats['tree_importance_recursive'].tolist()[1:]\n",
    "print(len(tree_feats))\n",
    "tree_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean vars\n",
    "del feats, custom_drop\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section III: Modeling - Electricity\n",
    "\n",
    "With the 4 feature sets we just created, we will be training 3 different models - a linear model and 2 tree-based models:\n",
    "1. `Lasso regression` (linear regression with L1 regularization) - this will be the baseline model for prediction performance\n",
    "    - As we did use lasso regression to create one of the feature sets, that feature set is optimized for lasso regression, so this model may do quite well\n",
    "2. LightGBM - a parallelizable gradient boosting machines (GBM) implementation that grows trees leaf-wise, which can reduce loss more than the commonly used depth-wise implementation *\n",
    "    - Another one of the feature sets was created with decision tree, so that's why we are using tree-based models\n",
    "3. XGBoost - another parallelizable GBM implementation that has a reputation of winning Kaggle competitions involving structured data\n",
    "    - Although not as fast as LightGBM, I suspect this algorithm will produce the best predictions\n",
    "    \n",
    "For each of the 3 models above, we will be tuning the model hyperparameters and training it on each of the 4 feature sets to select the model with the highest scores. The metric we are using to evaluate model performance is the `root mean squared error`. This is the most commonly used metric for evaluating regression models, and for good reason: it is easy to compute and understand, much like the `mean absolute error`, but has the added benefit of penalizing larger errors more so that the optimization process can be more robust to outliers.\n",
    "\n",
    "##### \\* Note: Read more about LightGBM and XGBoost [here](https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/). Pranjal provides a great comparison between the 2 algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso regression\n",
    "\n",
    "Again, this will be the baseline model for performance. This will give us an idea of the performance we can expect with the data. With only 1 hyperparamer to tune, a simple for loop would do the trick. But we are going to take advantage of Scikit-learn's grid search for the detailed results it provides. The only thing we are tuning here is the `alpha` parameter, which controls the degree of L1 regularization in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>-1.117169</td>\n",
       "      <td>-1.117163</td>\n",
       "      <td>-1.117316</td>\n",
       "      <td>-1.116869</td>\n",
       "      <td>-1.117129</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>-1.117176</td>\n",
       "      <td>-1.117173</td>\n",
       "      <td>-1.117325</td>\n",
       "      <td>-1.116878</td>\n",
       "      <td>-1.117138</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>-1.117904</td>\n",
       "      <td>-1.117940</td>\n",
       "      <td>-1.118070</td>\n",
       "      <td>-1.117633</td>\n",
       "      <td>-1.117887</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>-1.140061</td>\n",
       "      <td>-1.140273</td>\n",
       "      <td>-1.140695</td>\n",
       "      <td>-1.140054</td>\n",
       "      <td>-1.140271</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>-1.485491</td>\n",
       "      <td>-1.485756</td>\n",
       "      <td>-1.485862</td>\n",
       "      <td>-1.485268</td>\n",
       "      <td>-1.485594</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0000</th>\n",
       "      <td>-1.485491</td>\n",
       "      <td>-1.485756</td>\n",
       "      <td>-1.485862</td>\n",
       "      <td>-1.485268</td>\n",
       "      <td>-1.485594</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             split0_test_score  split1_test_score  split2_test_score  \\\n",
       "param_alpha                                                            \n",
       "0.0001               -1.117169          -1.117163          -1.117316   \n",
       "0.0010               -1.117176          -1.117173          -1.117325   \n",
       "0.0100               -1.117904          -1.117940          -1.118070   \n",
       "0.1000               -1.140061          -1.140273          -1.140695   \n",
       "1.0000               -1.485491          -1.485756          -1.485862   \n",
       "10.0000              -1.485491          -1.485756          -1.485862   \n",
       "\n",
       "             split3_test_score  mean_test_score  std_test_score  \\\n",
       "param_alpha                                                       \n",
       "0.0001               -1.116869        -1.117129        0.000162   \n",
       "0.0010               -1.116878        -1.117138        0.000162   \n",
       "0.0100               -1.117633        -1.117887        0.000159   \n",
       "0.1000               -1.140054        -1.140271        0.000260   \n",
       "1.0000               -1.485268        -1.485594        0.000232   \n",
       "10.0000              -1.485268        -1.485594        0.000232   \n",
       "\n",
       "             rank_test_score  \n",
       "param_alpha                   \n",
       "0.0001                     1  \n",
       "0.0010                     2  \n",
       "0.0100                     3  \n",
       "0.1000                     4  \n",
       "1.0000                     5  \n",
       "10.0000                    5  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression with full feat set (15)\n",
    "params = {'alpha': [10 ** p for p in range(-4, 2)]}\n",
    "lasso15 = GridSearchCV(Lasso(random_state=4), params, cv=4, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=-1)\n",
    "lasso15.fit(Xe_train_scaled, ye_train)\n",
    "pd.DataFrame(lasso15.cv_results_).set_index('param_alpha').iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>-1.120109</td>\n",
       "      <td>-1.119981</td>\n",
       "      <td>-1.120203</td>\n",
       "      <td>-1.119689</td>\n",
       "      <td>-1.119995</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>-1.120108</td>\n",
       "      <td>-1.119985</td>\n",
       "      <td>-1.120209</td>\n",
       "      <td>-1.119696</td>\n",
       "      <td>-1.120000</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>-1.120438</td>\n",
       "      <td>-1.120369</td>\n",
       "      <td>-1.120593</td>\n",
       "      <td>-1.120090</td>\n",
       "      <td>-1.120372</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>-1.140209</td>\n",
       "      <td>-1.140452</td>\n",
       "      <td>-1.140839</td>\n",
       "      <td>-1.140212</td>\n",
       "      <td>-1.140428</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             split0_test_score  split1_test_score  split2_test_score  \\\n",
       "param_alpha                                                            \n",
       "0.0001               -1.120109          -1.119981          -1.120203   \n",
       "0.0010               -1.120108          -1.119985          -1.120209   \n",
       "0.0100               -1.120438          -1.120369          -1.120593   \n",
       "0.1000               -1.140209          -1.140452          -1.140839   \n",
       "\n",
       "             split3_test_score  mean_test_score  std_test_score  \\\n",
       "param_alpha                                                       \n",
       "0.0001               -1.119689        -1.119995        0.000194   \n",
       "0.0010               -1.119696        -1.120000        0.000192   \n",
       "0.0100               -1.120090        -1.120372        0.000182   \n",
       "0.1000               -1.140212        -1.140428        0.000257   \n",
       "\n",
       "             rank_test_score  \n",
       "param_alpha                   \n",
       "0.0001                     1  \n",
       "0.0010                     2  \n",
       "0.0100                     3  \n",
       "0.1000                     4  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression with custom feat set (10)\n",
    "params = {'alpha': [10 ** e for e in range(-4, 0)]}\n",
    "lasso10 = GridSearchCV(Lasso(random_state=4), params, cv=4, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=-1)\n",
    "lasso10.fit(Xe_train_scaled[custom_feats], ye_train)\n",
    "pd.DataFrame(lasso10.cv_results_).set_index('param_alpha').iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:   34.7s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>-1.129856</td>\n",
       "      <td>-1.129722</td>\n",
       "      <td>-1.130270</td>\n",
       "      <td>-1.129480</td>\n",
       "      <td>-1.129832</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>-1.129855</td>\n",
       "      <td>-1.129728</td>\n",
       "      <td>-1.130272</td>\n",
       "      <td>-1.129486</td>\n",
       "      <td>-1.129835</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>-1.130119</td>\n",
       "      <td>-1.130046</td>\n",
       "      <td>-1.130570</td>\n",
       "      <td>-1.129806</td>\n",
       "      <td>-1.130135</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>-1.145471</td>\n",
       "      <td>-1.145717</td>\n",
       "      <td>-1.146136</td>\n",
       "      <td>-1.145477</td>\n",
       "      <td>-1.145700</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             split0_test_score  split1_test_score  split2_test_score  \\\n",
       "param_alpha                                                            \n",
       "0.0001               -1.129856          -1.129722          -1.130270   \n",
       "0.0010               -1.129855          -1.129728          -1.130272   \n",
       "0.0100               -1.130119          -1.130046          -1.130570   \n",
       "0.1000               -1.145471          -1.145717          -1.146136   \n",
       "\n",
       "             split3_test_score  mean_test_score  std_test_score  \\\n",
       "param_alpha                                                       \n",
       "0.0001               -1.129480        -1.129832        0.000287   \n",
       "0.0010               -1.129486        -1.129835        0.000285   \n",
       "0.0100               -1.129806        -1.130135        0.000277   \n",
       "0.1000               -1.145477        -1.145700        0.000270   \n",
       "\n",
       "             rank_test_score  \n",
       "param_alpha                   \n",
       "0.0001                     1  \n",
       "0.0010                     2  \n",
       "0.0100                     3  \n",
       "0.1000                     4  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression with lasso RFE feat set (8)\n",
    "lasso8 = GridSearchCV(Lasso(random_state=4), params, cv=4, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=-1)\n",
    "lasso8.fit(Xe_train_scaled[lasso_feats], ye_train)\n",
    "pd.DataFrame(lasso8.cv_results_).set_index('param_alpha').iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:   40.7s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>-1.123522</td>\n",
       "      <td>-1.123356</td>\n",
       "      <td>-1.123536</td>\n",
       "      <td>-1.123050</td>\n",
       "      <td>-1.123366</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>-1.123520</td>\n",
       "      <td>-1.123358</td>\n",
       "      <td>-1.123540</td>\n",
       "      <td>-1.123056</td>\n",
       "      <td>-1.123369</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>-1.123724</td>\n",
       "      <td>-1.123609</td>\n",
       "      <td>-1.123801</td>\n",
       "      <td>-1.123333</td>\n",
       "      <td>-1.123617</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>-1.140209</td>\n",
       "      <td>-1.140452</td>\n",
       "      <td>-1.140839</td>\n",
       "      <td>-1.140212</td>\n",
       "      <td>-1.140428</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             split0_test_score  split1_test_score  split2_test_score  \\\n",
       "param_alpha                                                            \n",
       "0.0001               -1.123522          -1.123356          -1.123536   \n",
       "0.0010               -1.123520          -1.123358          -1.123540   \n",
       "0.0100               -1.123724          -1.123609          -1.123801   \n",
       "0.1000               -1.140209          -1.140452          -1.140839   \n",
       "\n",
       "             split3_test_score  mean_test_score  std_test_score  \\\n",
       "param_alpha                                                       \n",
       "0.0001               -1.123050        -1.123366        0.000196   \n",
       "0.0010               -1.123056        -1.123369        0.000194   \n",
       "0.0100               -1.123333        -1.123617        0.000178   \n",
       "0.1000               -1.140212        -1.140428        0.000257   \n",
       "\n",
       "             rank_test_score  \n",
       "param_alpha                   \n",
       "0.0001                     1  \n",
       "0.0010                     2  \n",
       "0.0100                     3  \n",
       "0.1000                     4  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression with decision tree RFE feat set (7)\n",
    "lasso7 = GridSearchCV(Lasso(random_state=4), params, cv=4, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=-1)\n",
    "lasso7.fit(Xe_train_scaled[tree_feats], ye_train)\n",
    "pd.DataFrame(lasso7.cv_results_).set_index('param_alpha').iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 4 feature sets, the full feature set produced the lowest error with an `alpha` value of `0.0001`. We can see that the error decreases as `alpha` decreases, but going from an `alpha` value of `0.001` to `0.0001` did not decrease the error by much, so it's unnecessary to go any smaller for `alpha`.\n",
    "\n",
    "Even though there is little difference in error between the 4 feature sets, it's clear that using less features increases the error. But interestingly, the decision tree set (with 7 features) did slightly better than the lasso set (with 8 features). This suggests 2 things:\n",
    "1. The 3 features present in both the custom set and lasso set, but absent from the tree set - `missing_year`, `is_weekend`, and `is_holiday` - are not providing much information to the model. This is because of the minimal difference in error with or without these features.\n",
    "2. Either (or both) the features present in the tree set, but absent from the lasso set - `air_temperature` and `year_built` - are important features because the model did worse without them.\n",
    "\n",
    "The top 2 choices here are:\n",
    "1. Full set (15 features) - This would be the better option if the goal is to minimize prediction error\n",
    "2. Decision tree set (7 features) - This would be the better option if the goal was to keep the model simple (minimize complexity) for better explainability without losing too much prediction performance\n",
    "\n",
    "Since the goal here is to minimize the prediction error, we will be going with the full feature set. But first, let's check if the difference in prediction error between these two sets is similar when makinng predictions on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Feature Set\n",
      "-------------------------\n",
      "Training RMSE: 1.1233637030044468\n",
      "Validation RMSE: 1.123159063262605\n",
      "Test RMSE: 1.1225384159334848\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>square_feet</td>\n",
       "      <td>0.816397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>primary_use</td>\n",
       "      <td>0.289574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>country</td>\n",
       "      <td>0.200506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>year_built</td>\n",
       "      <td>0.149960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hour</td>\n",
       "      <td>0.058108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_temperature</td>\n",
       "      <td>0.003007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dayofyear</td>\n",
       "      <td>-0.010668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feat      coef\n",
       "2      square_feet  0.816397\n",
       "1      primary_use  0.289574\n",
       "4          country  0.200506\n",
       "3       year_built  0.149960\n",
       "6             hour  0.058108\n",
       "0  air_temperature  0.003007\n",
       "5        dayofyear -0.010668"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression with tree set (7)\n",
    "lasso7 = Lasso(alpha=1e-4, random_state=4).fit(Xe_train_scaled[tree_feats], ye_train)\n",
    "\n",
    "# RMSE for preds on train and val sets\n",
    "print('Decision Tree Feature Set')\n",
    "print('-------------------------')\n",
    "print('Training RMSE:', np.sqrt(mean_squared_error(ye_train, lasso7.predict(Xe_train_scaled[tree_feats]))))\n",
    "print('Validation RMSE:', np.sqrt(mean_squared_error(ye_val, lasso7.predict(Xe_val_scaled[tree_feats]))))\n",
    "print('Test RMSE:', np.sqrt(mean_squared_error(ye_test, lasso7.predict(Xe_test_scaled[tree_feats]))))\n",
    "print('-------------------------')\n",
    "\n",
    "# Feat coefs\n",
    "pd.DataFrame(zip(tree_feats, lasso7.coef_), columns=['feat', 'coef']).sort_values('coef', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Feature Set\n",
      "----------------\n",
      "Training RMSE: 1.1171254394161136\n",
      "Validation RMSE: 1.116764639445934\n",
      "Test RMSE: 1.1162570687364561\n",
      "----------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>square_feet</td>\n",
       "      <td>0.817981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>primary_use</td>\n",
       "      <td>0.293554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>country</td>\n",
       "      <td>0.180226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>year_built</td>\n",
       "      <td>0.146542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hour</td>\n",
       "      <td>0.045132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>missing_year</td>\n",
       "      <td>0.039533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dayofyear</td>\n",
       "      <td>0.011212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wind_direction_y</td>\n",
       "      <td>-0.005778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wind_speed</td>\n",
       "      <td>-0.019801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wind_direction_x</td>\n",
       "      <td>-0.021721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is_holiday</td>\n",
       "      <td>-0.025109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sea_level_pressure</td>\n",
       "      <td>-0.026945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_temperature</td>\n",
       "      <td>-0.036403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>is_weekend</td>\n",
       "      <td>-0.073683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rel_humidity</td>\n",
       "      <td>-0.085049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feat      coef\n",
       "7          square_feet  0.817981\n",
       "6          primary_use  0.293554\n",
       "10             country  0.180226\n",
       "8           year_built  0.146542\n",
       "12                hour  0.045132\n",
       "9         missing_year  0.039533\n",
       "11           dayofyear  0.011212\n",
       "5     wind_direction_y -0.005778\n",
       "3           wind_speed -0.019801\n",
       "4     wind_direction_x -0.021721\n",
       "14          is_holiday -0.025109\n",
       "2   sea_level_pressure -0.026945\n",
       "0      air_temperature -0.036403\n",
       "13          is_weekend -0.073683\n",
       "1         rel_humidity -0.085049"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression with full feat set (15)\n",
    "lasso = Lasso(alpha=1e-4, random_state=0).fit(Xe_train_scaled, ye_train)\n",
    "\n",
    "# RMSE for preds on train and val sets\n",
    "print('Full Feature Set')\n",
    "print('----------------')\n",
    "print('Training RMSE:', np.sqrt(mean_squared_error(ye_train, lasso.predict(Xe_train_scaled))))\n",
    "print('Validation RMSE:', np.sqrt(mean_squared_error(ye_val, lasso.predict(Xe_val_scaled))))\n",
    "print('Test RMSE:', np.sqrt(mean_squared_error(ye_test, lasso.predict(Xe_test_scaled))))\n",
    "print('----------------')\n",
    "\n",
    "# Feat coefs\n",
    "coefs = pd.DataFrame(zip(Xe_train_scaled.columns, lasso.coef_), columns=['feat', 'coef'])\\\n",
    "          .sort_values('coef', ascending=False)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean vars\n",
    "del lasso8, lasso10, lasso15, params, coefs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction error of the validation set confirms that training the model on the full feature set does a little better than using a reduced set, with the following root mean squared error (RMSE) scores:\n",
    "- Full feature set: 1.1165 (train) and 1.1179 (validation)\n",
    "- Decision tree RFE feature set: 1.1228 (train) and 1.1240 (validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM\n",
    "\n",
    "Now that we have a baseline model, let's see if we can do better with a gradient boosting model. With LightGBM, there are quite a bit of hyperparameters to tune. And with the cross-validation folds and number of options for each parameter, the number of trials can get exponentially high, so a parameter grid search is not feasible here.\n",
    "\n",
    "Instead, we will use `Optuna` to optimize LightGBM's parameters. `Optuna` takes a Bayesian approach to hyperparameter tuning, learning from previous trials to optimize each parameter. This is much more efficient than a grid search, which does a brute force search through every parameter combination.\n",
    "\n",
    "To use `Optuna`, we must define the objective function for the parameter optimization process. This objective function will be used on every trial to evaluate the model's prediction performance using that trial's parameters. On every trial of the `Optuna` study, the function will do the following:\n",
    "1. Save the study object - to save progress in case it is interrupted\n",
    "2. Define the parameters to tune and distribution of values to search for each parameter - `Optuna` uses a distribution of values, instead of a list of explicit values\n",
    "    - This allows us to get more fine-grained with the parameter values\n",
    "3. Create a LightGBM `Dataset` object for the data - the LightGBM model has its own data object so we must convert the data to said object in order to train the model\n",
    "4. Train model - using both the training and validation sets for validation\n",
    "5. Evaluate model on the validation set - predictions are made on the validation set and evaluated using the root mean squared error (RMSE)\n",
    "    - Negative predictions are replaced with 0 because there can't be negative energy consumption\n",
    "5. Return evaluation metric to minimize (model loss) - in this case, we are trying to minimize the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna study path\n",
    "lgb_path = os.path.join('..', 'models', 'electricity', 'lgb')\n",
    "os.makedirs(lgb_path, exist_ok=True)\n",
    "\n",
    "\n",
    "def objective_lgb(trial):\n",
    "    \n",
    "    \"\"\" Objective function for Optuna study to optimize model hyperparameters \"\"\"\n",
    "    \n",
    "    # Save study\n",
    "    print(dt.datetime.now(), ' | Finished trials:', len(study_lgb.trials))\n",
    "    joblib.dump(study_lgb, os.path.join(lgb_path, 'study_lgb.pkl'))\n",
    "    \n",
    "    # LightGBM params\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-4, 1e1),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-4, 1e1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 100),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 2000),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 5000),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.5, 1.0),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.5, 1.0),\n",
    "        'num_iterations': 1000,\n",
    "        'early_stopping_round': 10,\n",
    "        'metric': 'rmse',\n",
    "        'num_threads': -1,\n",
    "        'seed': 0\n",
    "    }\n",
    "    \n",
    "    # LightGBM datasets\n",
    "    dtrain = lgb.Dataset(Xe_train_scaled, label=ye_train)\n",
    "    dval = lgb.Dataset(Xe_val_scaled, label=ye_val)\n",
    "    \n",
    "    # Train model\n",
    "    lgbm = lgb.train(params, dtrain, valid_sets=[dtrain, dval], valid_names=['train', 'valid'], verbose_eval=False)\n",
    "    \n",
    "    # Make and evaluate predictions on validation set\n",
    "    pred = lgbm.predict(Xe_val_scaled)\n",
    "    pred[pred < 0] = 0 # replace negative predictions with 0\n",
    "    loss = np.sqrt(mean_squared_error(ye_val, pred)) # RMSE\n",
    "\n",
    "#     # Cross val on train set\n",
    "#     cv = lgb.cv(params, dtrain, folds=KFold(10, shuffle=True, random_state=0), verbose_eval=False)\n",
    "#     loss = cv['rmse-mean'][-1]\n",
    "    \n",
    "    # RMSE\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the objective function defined, we can now run the trials to optimize our parameters. Since we are evaluating the model using the RMSE, the goal is to minimize this metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start time\n",
    "# start_lgb = dt.datetime.now()\n",
    "# print('Start:', start_lgb)\n",
    "\n",
    "# # Enable logging\n",
    "# optuna.logging.enable_default_handler()\n",
    "\n",
    "# # Run trials\n",
    "# study_lgb = optuna.create_study(direction='minimize')\n",
    "# study_lgb.optimize(objective_lgb, n_trials=100)\n",
    "# joblib.dump(study_lgb, os.path.join(lgb_path, 'study_lgb.pkl')) # Save study after last trial\n",
    "\n",
    "# # End and total run time\n",
    "# end_lgb = dt.datetime.now()\n",
    "# print('End:', end_lgb)\n",
    "# print('Run time:', end_lgb - start_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start time\n",
    "# start_lgb = dt.datetime.now()\n",
    "# print('Start:', start_lgb)\n",
    "\n",
    "# # Enable logging\n",
    "# optuna.logging.enable_default_handler()\n",
    "\n",
    "# # Continue trials\n",
    "# study_lgb = joblib.load(os.path.join(lgb_path, 'study_lgb.pkl'))\n",
    "# study_lgb.optimize(objective_lgb, n_trials=50)\n",
    "# joblib.dump(study_lgb, os.path.join(lgb_path, 'study_lgb.pkl')) # Save study after last trial\n",
    "\n",
    "# # End and total run time\n",
    "# end_lgb = dt.datetime.now()\n",
    "# print('End:', end_lgb)\n",
    "# print('Run time:', end_lgb - start_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trials: 101\n",
      "Best trial: 0.23179190098693012\n",
      "Best parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.08318870089692557,\n",
       " 'lambda_l1': 0.0074992163884415545,\n",
       " 'lambda_l2': 2.9505901993515122,\n",
       " 'max_depth': 92,\n",
       " 'num_leaves': 1929,\n",
       " 'min_data_in_leaf': 13,\n",
       " 'bagging_fraction': 0.7334916237773891,\n",
       " 'feature_fraction': 0.8102168078812939}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Study results\n",
    "study_lgb = joblib.load(os.path.join(lgb_path, 'study_lgb.pkl'))\n",
    "print('Finished trials:', len(study_lgb.trials))\n",
    "print('Best trial:', study_lgb.best_trial.value)\n",
    "print('Best parameters:')\n",
    "params_lgb = dict(study_lgb.best_trial.params)\n",
    "params_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters yielded from the best trial are the optimized parameters and will be the final setting to train our LightGBM model. One caveat is that the Optuna study was run with a LightGBM model that builds 1,000 estimators (`num_iterations` = 1000) so the parameters were optimized to this value, more specifically the `learning_rate`, which is inversely proportional to `num_iterations`.\n",
    "\n",
    "We will be increasing `num_iterations` to 10,000 (10x the original value) to try to improve the gradient descent process. To adjust the `learning_rate` accordingly, we will divide it by 10 (the same factor `num_iterations` was increased by). \n",
    "\n",
    "Let's train a LightGBM model using the optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tribui/miniconda3/envs/minds/lib/python3.7/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.276137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1877\n",
      "[LightGBM] [Info] Number of data points in the train set: 8037133, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.106173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/electricity/lgb/lgbm.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LightGBM datasets\n",
    "edtrain = lgb.Dataset(Xe_train_scaled, label=ye_train)\n",
    "edval = lgb.Dataset(Xe_val_scaled, label=ye_val)\n",
    "\n",
    "# Parameters\n",
    "params_lgb['num_iterations'] = 1000\n",
    "params_lgb['num_iterations'] *= 10\n",
    "params_lgb['learning_rate'] /= 10 # adjust learning rate for the increase in iterations\n",
    "params_lgb['early_stopping_round'] = 10\n",
    "params_lgb['metric'] = 'rmse'\n",
    "params_lgb['num_threads'] = -1\n",
    "params_lgb['seed'] = 0\n",
    "\n",
    "# Train data\n",
    "lgbm = lgb.train(params_lgb, edtrain, valid_sets=[edtrain, edval], verbose_eval=False)\n",
    "joblib.dump(lgbm, os.path.join(lgb_path, 'lgbm.pkl')) # save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.2767524332412216\n",
      "Validation RMSE: 0.2824860563945859\n",
      "Test RMSE: 0.2817529661480336\n"
     ]
    }
   ],
   "source": [
    "# Train set RMSE\n",
    "pred_train = lgbm.predict(Xe_train_scaled) # make preds\n",
    "pred_train[pred_train < 0] = 0 # replace negative preds with 0\n",
    "rmse_train = np.sqrt(mean_squared_error(ye_train, pred_train)) # RMSE\n",
    "print('Train RMSE:', rmse_train)\n",
    "\n",
    "# Val set RMSE\n",
    "pred_val = lgbm.predict(Xe_val_scaled) # make preds\n",
    "pred_val[pred_val < 0] = 0 # replace negative preds with 0\n",
    "rmse_val = np.sqrt(mean_squared_error(ye_val, pred_val)) # RMSE\n",
    "print('Validation RMSE:', rmse_val)\n",
    "\n",
    "# Test set RMSE\n",
    "pred_test = lgbm.predict(Xe_test_scaled) # make preds\n",
    "pred_test[pred_test < 0] = 0 # replace negative preds with 0\n",
    "rmse_test = np.sqrt(mean_squared_error(ye_test, pred_test)) # RMSE\n",
    "print('Test RMSE:', rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean vars\n",
    "# del start_lgb, end_lgb\n",
    "del lgb_path, edtrain, edval, pred_train, rmse_train, pred_val, rmse_val, pred_test, rmse_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "XGBoost is another implementation of gradiant boosting that is optimized with the features in the image below.\n",
    "\n",
    "![XGBoost](src/imgs/xgb.png)\n",
    "\n",
    "Source: https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d\n",
    "\n",
    "As with LightGBM, we will be using `Optuna` to optimize XGBoost's parameters, and similar parameters at that. Again, we must define an objective function for the Optuna study to call on every trial. The objective function will do the following:\n",
    "1. Save the study object\n",
    "2. Define the parameters to tune and distribution of values to search for each parameter\n",
    "3. Create an XGBoost `DMatrix` object for the data\n",
    "4. Train model\n",
    "5. Evaluate model on the validation set using the RMSE\n",
    "    - Negative predictions are replaced with 0 before evaluation\n",
    "6. Return the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna study path\n",
    "xgb_path = os.path.join('..', 'models', 'electricity', 'xgb')\n",
    "os.makedirs(xgb_path, exist_ok=True)\n",
    "\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    \n",
    "    \"\"\" Objective function for Optuna study to optimize model hyperparameters \"\"\"\n",
    "    \n",
    "    # Save study\n",
    "    print(dt.datetime.now(), '| Finished trials:', len(study_xgb.trials))\n",
    "    print()\n",
    "    joblib.dump(study_xgb, os.path.join(xgb_path, 'study_xgb.pkl'))\n",
    "    \n",
    "    # XGBoost params\n",
    "    params = {\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 2e-1),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e1),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-4, 1e1),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 200),\n",
    "        'max_leaves': trial.suggest_int('max_leaves', 2, 4096),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        'eval_metric': 'rmse',\n",
    "        'seed': 0\n",
    "    }\n",
    "    \n",
    "    # XGBoost dmatrices\n",
    "    dtrain = xgb.DMatrix(Xe_val_scaled, label=ye_val)\n",
    "    dval = xgb.DMatrix(Xe_test_scaled, label=ye_test)\n",
    "    \n",
    "    # Train model\n",
    "    xg = xgb.train(params, dtrain, \n",
    "                   evals=[(dtrain, 'train'), (dval, 'valid')],\n",
    "                   num_boost_round=100, \n",
    "                   early_stopping_rounds=10,\n",
    "                   verbose_eval=False)\n",
    "    \n",
    "    # Make and eval preds on val set\n",
    "    pred = xg.predict(dval)\n",
    "    pred[pred < 0] = 0 # replace negative predictions with 0\n",
    "    loss = np.sqrt(mean_squared_error(ye_test, pred)) # RMSE\n",
    "\n",
    "#     # Cross val on train set\n",
    "#     cv = xgb.cv(params, dtrain, folds=KFold(10, shuffle=True, random_state=0), verbose_eval=False)\n",
    "#     loss = cv['rmse-mean'][-1]\n",
    "    \n",
    "    # RMSE\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start time\n",
    "# start_xgb = dt.datetime.now()\n",
    "# print('Start:', start_xgb)\n",
    "\n",
    "# # Run trials\n",
    "# study_xgb = optuna.create_study(direction='minimize')\n",
    "# study_xgb.optimize(objective_xgb, n_trials=100)\n",
    "# joblib.dump(study_xgb, os.path.join(xgb_path, 'study_xgb.pkl')) # Save study after last trial\n",
    "\n",
    "# # End and total run time\n",
    "# end_xgb = dt.datetime.now()\n",
    "# print('End:', end_xgb)\n",
    "# print('Run time:', end_xgb - start_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start time\n",
    "# start_xgb = dt.datetime.now()\n",
    "# print('Start:', start_xgb)\n",
    "\n",
    "# # Continue trials\n",
    "# study_xgb = joblib.load(os.path.join(xgb_path, 'study_xgb.pkl'))\n",
    "# study_xgb.optimize(objective_xgb, n_trials=50)\n",
    "# joblib.dump(study_xgb, os.path.join(xgb_path, 'study_xgb.pkl')) # Save study after last trial\n",
    "\n",
    "# # End and total run time\n",
    "# end_xgb = dt.datetime.now()\n",
    "# print('End:', end_xgb)\n",
    "# print('Run time:', end_xgb - start_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trials: 111\n",
      "Best trial: 0.1693050116300583\n",
      "Best parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'grow_policy': 'lossguide',\n",
       " 'learning_rate': 0.09897522425910911,\n",
       " 'alpha': 0.0007631264300296365,\n",
       " 'lambda': 2.4504122928666554,\n",
       " 'gamma': 0.001191775797167784,\n",
       " 'max_depth': 63,\n",
       " 'max_leaves': 1086,\n",
       " 'subsample': 0.9443322952938715,\n",
       " 'colsample_bytree': 0.9518408116816858}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Study results\n",
    "study_xgb = joblib.load(os.path.join(xgb_path, 'study_xgb.pkl'))\n",
    "print('Finished trials:', len(study_xgb.trials))\n",
    "print('Best trial:', study_xgb.best_trial.value)\n",
    "print('Best parameters:')\n",
    "params_xgb = dict(study_xgb.best_trial.params)\n",
    "params_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:12:19] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/gbm/gbtree.cc:139: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/electricity/xgb/xgbm.pkl']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost dmatrices\n",
    "edtrain = xgb.DMatrix(Xe_train_scaled, label=ye_train)\n",
    "edval = xgb.DMatrix(Xe_val_scaled, label=ye_val)\n",
    "edtest = xgb.DMatrix(Xe_test_scaled, label=ye_test)\n",
    "\n",
    "# Params\n",
    "params_xgb['eval_metric'] = 'rmse'\n",
    "params_xgb['seed'] = 0\n",
    "\n",
    "# Train data\n",
    "xg = xgb.train(params_xgb, edtrain, \n",
    "               evals=[(edtrain, 'train'), (edval, 'valid')], \n",
    "               num_boost_round=100,\n",
    "               early_stopping_rounds=10,\n",
    "               verbose_eval=False)\n",
    "joblib.dump(xg, os.path.join(xgb_path, 'xgbm.pkl')) # save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.26175472\n",
      "Validation RMSE: 0.43477845\n",
      "Test RMSE: 0.4348392\n"
     ]
    }
   ],
   "source": [
    "# Train set RMSE\n",
    "pred_train = xg.predict(edtrain)  # make preds\n",
    "pred_train[pred_train < 0] = 0 # replace negative preds with 0\n",
    "rmse_train = np.sqrt(mean_squared_error(ye_train, pred_train)) # RMSE\n",
    "print('Train RMSE:', rmse_train)\n",
    "\n",
    "# Val set RMSE\n",
    "pred_val = xg.predict(edval)  # make preds\n",
    "pred_val[pred_val < 0] = 0 # replace negative preds with 0\n",
    "rmse_val = np.sqrt(mean_squared_error(ye_val, pred_val)) # RMSE\n",
    "print('Validation RMSE:', rmse_val)\n",
    "\n",
    "# Test set RMSE\n",
    "pred_test = xg.predict(edtest)  # make preds\n",
    "pred_test[pred_test < 0] = 0 # replace negative preds with 0\n",
    "rmse_test = np.sqrt(mean_squared_error(ye_test, pred_test)) # RMSE\n",
    "print('Test RMSE:', rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean vars\n",
    "# del start_xgb, end_xgb\n",
    "del xgb_path, edtrain, edval, edtest, pred_train, rmse_train, pred_val, rmse_val, pred_test, rmse_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section IV: Electricity Modeling Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE scores were calculated on the log-transformed target and are as follows:\n",
    "1. Lasso regression:\n",
    "    - Training RMSE: 1.1171254394161136\n",
    "    - Validation RMSE: 1.116764639445934\n",
    "    - Test RMSE: 1.1162570687364561\n",
    "2. LightGBM\n",
    "    - Train RMSE: 0.2767524332412216\n",
    "    - Validation RMSE: 0.2824860563945859\n",
    "    - Test RMSE: 0.2817529661480336\n",
    "3. XGBoost\n",
    "    - Train RMSE: 0.26175472\n",
    "    - Validation RMSE: 0.43477845\n",
    "    - Test RMSE: 0.4348392\n",
    "        \n",
    "Out of the 3 models, the LightGBM model performed the best. It yielded the lowest error on the validation and test sets, and also trained a lot faster than the XGBoost model despite going for 100 times the number of iterations. The hyperparameters for the optimized LightGBM model are:\n",
    "- `num_iterations` : 10000\n",
    "- `learning_rate` : 0.008318870089692557\n",
    "- `lambda_l1` : 0.0074992163884415545\n",
    "- `lambda_l2` : 2.9505901993515122\n",
    "- `max_depth` : 92\n",
    "- `num_leaves` : 1929\n",
    "- `min_data_in_leaf` : 13\n",
    "- `bagging_fraction` : 0.7334916237773891\n",
    "- `feature_fraction` : 0.8102168078812939\n",
    "\n",
    "Note: These results are only for the electricity meter readings. LightGBM will be the choice model for electricity meters moving forward, but this may not be the case for the other 3 meter types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
