{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Energy Predictor - Modeling (Electricity)\n",
    "#### Hosted by: ASHRAE\n",
    "##### Source: https://www.kaggle.com/c/ashrae-energy-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section I: Dependencies and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import gc\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "import src.utils as udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "# Plot settings\n",
    "sns.set(rc={'figure.figsize': (15, 3),\n",
    "            'font.size': 15})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path\n",
    "data_path = '../data/from_feat/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11481619 entries, 0 to 18205341\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   site_id             uint8         \n",
      " 1   building_id         uint16        \n",
      " 2   timestamp           datetime64[ns]\n",
      " 3   meter_reading       float32       \n",
      " 4   air_temperature     float32       \n",
      " 5   dew_temperature     float32       \n",
      " 6   rel_humidity        float32       \n",
      " 7   sea_level_pressure  float32       \n",
      " 8   wind_direction_x    float32       \n",
      " 9   wind_direction_y    float32       \n",
      " 10  wind_speed          float32       \n",
      " 11  primary_use         object        \n",
      " 12  square_feet         uint32        \n",
      " 13  year_built          uint8         \n",
      " 14  missing_year        uint8         \n",
      " 15  country             object        \n",
      " 16  dayofyear           uint16        \n",
      " 17  month               uint8         \n",
      " 18  hour                uint8         \n",
      " 19  dayofweek           uint8         \n",
      " 20  is_weekend          uint8         \n",
      " 21  is_holiday          uint8         \n",
      "dtypes: datetime64[ns](1), float32(8), object(2), uint16(2), uint32(1), uint8(8)\n",
      "memory usage: 876.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Electricity meter data\n",
    "electricity = pd.read_pickle(data_path + 'electricity.pkl')\n",
    "electricity.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3507966, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>rel_humidity</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction_x</th>\n",
       "      <th>wind_direction_y</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>missing_year</th>\n",
       "      <th>country</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2</td>\n",
       "      <td>163</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4.571900</td>\n",
       "      <td>7.2</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>39.616142</td>\n",
       "      <td>1017.299988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Education</td>\n",
       "      <td>72102</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>209.886002</td>\n",
       "      <td>7.2</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>39.616142</td>\n",
       "      <td>1017.299988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lodging/residential</td>\n",
       "      <td>553210</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>51.556999</td>\n",
       "      <td>7.2</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>39.616142</td>\n",
       "      <td>1017.299988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Education</td>\n",
       "      <td>183460</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    site_id  building_id  timestamp  meter_reading  air_temperature  \\\n",
       "70        2          163 2016-01-01       4.571900              7.2   \n",
       "75        2          166 2016-01-01     209.886002              7.2   \n",
       "80        2          168 2016-01-01      51.556999              7.2   \n",
       "\n",
       "    dew_temperature  rel_humidity  sea_level_pressure  wind_direction_x  \\\n",
       "70             -5.6     39.616142         1017.299988               0.0   \n",
       "75             -5.6     39.616142         1017.299988               0.0   \n",
       "80             -5.6     39.616142         1017.299988               0.0   \n",
       "\n",
       "    wind_direction_y  wind_speed          primary_use  square_feet  \\\n",
       "70               0.0         0.0            Education        72102   \n",
       "75               0.0         0.0  Lodging/residential       553210   \n",
       "80               0.0         0.0            Education       183460   \n",
       "\n",
       "    year_built  missing_year country  dayofyear  month  hour  dayofweek  \\\n",
       "70         178             0      US          1      1     0          4   \n",
       "75         217             0      US          1      1     0          4   \n",
       "80         213             0      US          1      1     0          4   \n",
       "\n",
       "    is_weekend  is_holiday  \n",
       "70           0           1  \n",
       "75           0           1  \n",
       "80           0           1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chilled water meter data\n",
    "chilledwater = pd.read_pickle(data_path + 'chilledwater.pkl')\n",
    "print(chilledwater.shape)\n",
    "chilledwater.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2296049, 22)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Steam meter data\n",
    "steam = pd.read_pickle(data_path + 'steam.pkl')\n",
    "steam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(919708, 22)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hot water meter data\n",
    "hotwater = pd.read_pickle(data_path + 'hotwater.pkl')\n",
    "hotwater.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_corr</th>\n",
       "      <th>lasso_coef</th>\n",
       "      <th>lasso_coef_recursive</th>\n",
       "      <th>tree_importance</th>\n",
       "      <th>tree_importance_recursive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>square_feet</td>\n",
       "      <td>primary_use</td>\n",
       "      <td>primary_use</td>\n",
       "      <td>square_feet</td>\n",
       "      <td>site_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>country</td>\n",
       "      <td>square_feet</td>\n",
       "      <td>square_feet</td>\n",
       "      <td>year_built</td>\n",
       "      <td>air_temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>country</td>\n",
       "      <td>missing_year</td>\n",
       "      <td>country</td>\n",
       "      <td>primary_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>is_weekend</td>\n",
       "      <td>country</td>\n",
       "      <td></td>\n",
       "      <td>square_feet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>dayofyear</td>\n",
       "      <td></td>\n",
       "      <td>year_built</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hour</td>\n",
       "      <td></td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>is_weekend</td>\n",
       "      <td></td>\n",
       "      <td>dayofyear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>is_holiday</td>\n",
       "      <td></td>\n",
       "      <td>hour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_corr   lasso_coef lasso_coef_recursive tree_importance  \\\n",
       "0  square_feet  primary_use          primary_use     square_feet   \n",
       "1      country  square_feet          square_feet      year_built   \n",
       "2                   country         missing_year         country   \n",
       "3                is_weekend              country                   \n",
       "4                                      dayofyear                   \n",
       "5                                           hour                   \n",
       "6                                     is_weekend                   \n",
       "7                                     is_holiday                   \n",
       "\n",
       "  tree_importance_recursive  \n",
       "0                   site_id  \n",
       "1           air_temperature  \n",
       "2               primary_use  \n",
       "3               square_feet  \n",
       "4                year_built  \n",
       "5                   country  \n",
       "6                 dayofyear  \n",
       "7                      hour  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = pd.read_pickle(data_path + 'feats.pkl')\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data_path\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section II: Featurization - Electricity\n",
    "\n",
    "Once again, we will be working primarily with the electricity meter data as it contains the most readings and the process used here will be repeated for the other 3 meters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unused features\n",
    "\n",
    "We will be dropping the features we found to be unnecessary in the featurization notebook - `site_id`, `building_id`, `dew_temperature`, `timestamp`, `month`, `dayofweek`. `Site_id` was added here because we have the `country` feature which is a good proxy for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11481619 entries, 0 to 18205341\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   meter_reading       float32\n",
      " 1   air_temperature     float32\n",
      " 2   rel_humidity        float32\n",
      " 3   sea_level_pressure  float32\n",
      " 4   wind_direction_x    float32\n",
      " 5   wind_direction_y    float32\n",
      " 6   wind_speed          float32\n",
      " 7   primary_use         object \n",
      " 8   square_feet         uint32 \n",
      " 9   year_built          uint8  \n",
      " 10  missing_year        uint8  \n",
      " 11  country             object \n",
      " 12  dayofyear           uint16 \n",
      " 13  hour                uint8  \n",
      " 14  is_weekend          uint8  \n",
      " 15  is_holiday          uint8  \n",
      "dtypes: float32(7), object(2), uint16(1), uint32(1), uint8(5)\n",
      "memory usage: 689.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Drop features\n",
    "to_drop = ['site_id', 'building_id', 'dew_temperature', 'timestamp', 'month', 'dayofweek']\n",
    "electricity.drop(to_drop, axis=1, inplace=True)\n",
    "electricity.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split\n",
    "\n",
    "The same 60-20-20 data split will be done here. Variables will be suffixed with \"e\" to indicate that it is `electricity` meter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11481619, 15), (11481619,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split features and target\n",
    "Xe = electricity.drop('meter_reading', axis=1).copy()\n",
    "ye = electricity['meter_reading'].copy()\n",
    "Xe.shape, ye.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4AAAADhCAYAAACZdNs1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlpUlEQVR4nO3de1TUdf7H8dcA461BCQL1p2sX8q7purVKa5hU3kBJQldz1d9qmm79NNtCxHvejdVcTc/q+is1LDERBC+Zkq4GeasWbTPZLbxlSF5RQWHm+/vD0/yiFEadb4zO83GOp5nvzPfzeY+9j3Ne8/leLIZhGAIAAAAA3PF8KrsAAAAAAMAvgwAIAAAAAF6CAAgAAAAAXoIACAAAAABeggAIAAAAAF6CAAgAAAAAXoIACABwu6lTpyo6OlrR0dFq0aKFOnfu7HxeXFxs2ryFhYUaMGDANV+bP3++2rVr56wjMjJSL7/8svLy8pzviY6O1vnz529q/B/vn5KSoueff/6G61+wYIG2bNkiSZo3b55SU1NveAwAAMrjV9kFAADuPOPGjXM+joiIUGJiolq2bGn6vOfOndP+/fuv+3q3bt00YcIE5/PU1FQNHDhQ69evl81mU1pa2i2NX9H+Fdm1a5cefPBBSdLIkSNvaSwAAK6FAAgA+MVcunRJkyZN0uHDh3X27FndddddSkxM1AMPPKD+/furVq1a+vrrr9W3b1+Fh4crISFB586dU3BwsAzDUI8ePRQTE6NPP/1UiYmJKioqko+Pj1588UV17NhRY8aMUXFxsaKjo5WSkiJfX99y63n66ae1bt06paenq2/fvmrcuLGys7Nlt9s1evRonTlzRpLUoUMHvfTSSz8bv1WrVnriiSd08OBBJSYmKjY2VtnZ2ZKkgoICDR48WCdPnlS9evU0ZcoUBQcHq3///urXr5+6dOkiSc7np06d0oEDBzR79mz5+vpq69atatiwoQYPHqy9e/dq9uzZKioqktVq1UsvvaTw8HClpKToww8/lI+Pjw4fPqxq1app1qxZCg0NNfd/JADgtuXRh4BeuHBBUVFROnbsWLnv+/rrr9W/f3/16NFDgwcP1rlz536hCgEAN+If//iHatasqVWrVumDDz5QixYtlJSU5Hy9Zs2a2rBhg/r376+4uDhFRkYqIyND48aN0+effy7p6ircmDFjNHv2bK1du1YLFy7UpEmT9O2332rGjBmqVq2a0tLSKgx/P2jcuLEOHTpUZltycrLq16+vtWvXKikpSYcPH1ZhYeHPxi8pKVHHjh31wQcf/GyF85tvvtGECROUnp6uRo0aadq0aeXW0a9fP7Vo0UJxcXF66qmnnNvPnDmjESNGaOzYsUpPT9esWbP06quv6ujRo5KkPXv2aPz48crIyFCrVq20ePFilz43AMA7eWwA/Oc//6m+ffuWOTfjWgzD0PDhwzVkyBCtW7dOTZs25csPADxUly5d1LNnT61YsUJTp07V7t27denSJefrDz/8sKSrIS8nJ0e9evWSJIWGhqpdu3aSpM8//1wFBQV64YUXFB0draFDh8piseirr766qZosFouqVatWZttjjz2mzZs3a8iQIVq1apX+/Oc/y9/f/5r7/1DzTz366KO69957JUmxsbHKysq6qfpycnLUoEEDtWrVSpLUsGFDtWnTRrt375YkNW/eXHXq1JEkNWvWjB9BAQDl8thDQJOTkzVx4kTFxcU5t6WmpmrZsmVyOBxq3ry5Jk6cqNzcXNWoUUPh4eGSpGHDhpV7Aj8AoPKsXLlSycnJ6tevn7p3766AgIAyR3nUqFFDkpyrd4ZhOF/7YZvdbldoaKhWr17tfC0/P1+BgYHKz8+/4Zr279+vZ555psy2hx56SFu3blV2drY++eQT9erVS0uWLFFAQMDP9v+h5p/68Qqkw+GQn9//f+X++HOVlJSUW5/dbpfFYimzzTAMlZaWymq1lgmvFoulzNgAAPyUx64ATps2rcyvqrm5uUpOTtZ7772ntLQ0BQUFaenSpTpy5IjuueceJSQkqGfPnpo4ceJ1v4wBAJVr586d6tmzp3r16qX7779fmZmZstvtP3ufzWZTmzZtlJKSIkk6evSosrOzZbFY1Lp1ax0+fFh79uyRJH355Zfq3Lmz8vPz5efnJ7vd7nIIWr16tY4dO6auXbuW2Z6YmKiFCxfqySef1NixY/Xggw8qNzf3hsbftWuXvv32W0nSe++95/yhMjAwUAcOHJAk/fvf/y6zcunr66vS0tIy47Ru3Vpff/21cnJyJF39PtyzZ49++9vfuvQZAQD4MY9dAfypXbt26fDhw+rdu7ekq7+YNmvWTPXr19fu3bv1zjvvqGXLlnrjjTc0c+ZMzZw5s5IrBgD81KBBgzRhwgS9//77kq6Gm5+ef/eDWbNmaezYsVq5cqVq166t+vXrq1q1agoMDNRf//pXzZ49W5cvX5ZhGJo9e7bq168vu92uhx56SJGRkUpKStLdd99dZswNGzZo3759slgscjgcuv/++7V8+XJVrVq1zPsGDhyo+Ph4RUVFqUqVKmrcuLEiIyPl6+tbZvzyNGrUSAkJCfr+++/1wAMP6LXXXpMkDR8+XPHx8dq+fbseeOCBMj92RkREaM6cOWVWBQMDAzVv3jxNmTJFxcXFslgsmjFjhu6//3599tlnrv/lAwAgyWJ4+LEiERERWr58ubZu3aqjR486Ly1+8eJF2e12ffHFF5oxY4bWrVsn6eqvqSNGjNCGDRsqs2wAwC1atGiROnXqpNDQUBUWFqpHjx5asmSJ8zYJAADgxt02K4Bt27bV//7v/2r48OEKDAzUpEmT1KBBAw0ZMkSnT5/WwYMH1aRJE2VmZqp58+aVXS4A4Bbdd999GjVqlHx8fGS32zVkyBDCHwAAt+i2WQGsX7++Vq9e7bwITNOmTTV9+nRVrVpV//znPzVlyhQVFRWpTp06mj17toKCgiq7dAAAAADwKB4fAAEAAAAA7uGxVwEFAAAAALgXARAAAAAAvAQBEAAAAAC8hMdeBfTMmYtyODg9EZ4lKMimU6cuVHYZwDXRn/BU9CY8Fb0JT+XjY9Hdd99lytgeGwAdDoMACI9EX8KT0Z/wVPQmPBW9CW/DIaAAAAAA4CUIgAAAAADgJQiAAAAAAOAlCIAAAAAA4CUIgAAAAADgJTz2KqBBQTa3jFN8uVSF54vcMhYAAAAA3M48NgAOnrpZJ8/cenBL/0u0Ct1QDwAAAADc7jgEFAAAAAC8BAEQAAAAALwEARAAAAAAvAQBEAAAAAC8BAEQAAAAALwEARAAAAAAvAQBEAAAAAC8BAEQAAAAALwEARAAAAAAvAQBEAAAAAC8BAEQAAAAALwEARAAAAAAvAQBEAAAAAC8BAEQAAAAALwEARAAAAAAvAQBEAAAAAC8BAEQAAAAALwEARAAAAAAvISpATAtLU2RkZGKjIzUrFmzzJwKAAAAAFAB0wJgUVGRpk2bphUrVigtLU179+5VVlaWWdMBAAAAACpgWgC02+1yOBwqKipSaWmpSktLVbVqVbOmAwAAAABUwM+sgW02m0aOHKmuXbuqevXqeuSRR9SmTRuzpgMAAAAAVMC0AHjw4EGtWbNGH330kfz9/fXKK69o6dKleu6558ya8rqCg/1/8Tlx56Kf4MnoT3gqehOeit6EtzEtAO7cuVNhYWEKCgqSJMXExGjlypWVEgALCgp/8TlxZwoO9qef4LHoT3gqehOeit6Ep/LxsSgoyGbO2KaMKqlJkybKysrSpUuXZBiGMjMz1bJlS7OmAwAAAABUwLQVwPbt2+tf//qXYmJiZLVa1bJlSw0dOtSs6QAAAAAAFTAtAErS0KFDCX0AAAAA4CFMvRE8AAAAAMBzEAABAAAAwEsQAAEAAADASxAAAQAAAMBLEAABAAAAwEsQAAEAAADASxAAAQAAAMBLEAABAAAAwEsQAAEAAADASxAAAQAAAMBLEAABAAAAwEsQAAEAAADASxAAAQAAAMBLEAABAAAAwEsQAAEAAADASxAAAQAAAMBLEAABAAAAwEsQAAEAAADAS7gUAFesWKELFy6YXQsAAAAAwEQuBcCvvvpKnTt31tixY7V//36zawIAAAAAmMDPlTdNnTpVFy5cUHp6uiZPnizDMNS3b191795dVatWNbtGAAAAAIAbuHwOoM1mU5cuXRQVFaWzZ89q5cqV6tKlizIzM82sDwAAAADgJi6tAGZnZ2vVqlXKzs5W586d9eabb6pJkyY6cuSInn32WUVERJhdJwAAAADgFrkUACdPnqxnn31WU6ZMkb+/v3N7gwYN1Lt3b9OKAwAAAAC4j0uHgK5bt04BAQHy9/dXQUGB3n77bTkcDknSiBEjrrtfZmamYmJi1LVrV02dOtU9FQMAAAAAbopLAXDKlCnatm3b1R18fLRv3z5Nnz693H2OHj2qiRMnauHChVq3bp3+9a9/afv27bdcMAAAAADg5rh0COhnn32mjIwMSVJQUJDmzZun6Ojocvf58MMP1a1bN9WpU0eSNHfuXK4YCgAAAACVyKUVwJKSEl25csX5vLS0tMJ9Dh8+LLvdrmHDhik6OlorV65UrVq1br5SAAAAAMAtcWkF8PHHH9fgwYMVHR0ti8WijIwMdejQodx97Ha79u7dqxUrVqhGjRoaPny41q5dq5iYGLcUfiOCg/0rfhPgIvoJnoz+hKeiN+Gp6E14G5cCYFxcnJKSkrR161b5+fnpqaeeUp8+fcrd55577lFYWJgCAwMlSU8++aRycnIqJQAWFBT+4nPizhQc7E8/wWPRn/BU9CY8Fb0JT+XjY1FQkM2UsV0KgL6+vhowYIAGDBjg8sAdO3bU6NGjdf78ed11113asWOHnnjiiZsuFAAAAABwa1wKgFu2bNH06dN17tw5GYbh3P7pp59ed59WrVrpueee07PPPquSkhL97ne/0zPPPHPrFQMAAAAAbopLAfD1119XfHy8mjVrJovF4vLgsbGxio2NveniAAAAAADu41IArFmzpjp16mR2LQAAAAAAE7l0G4hWrVpxE3cAAAAAuM25tAK4fft2vfPOO7JarbJarTIMQxaLpdxzAAEAAAAAnsWlAPj222+bXAYAAAAAwGwuHQJar1497d+/X8nJyQoMDNRnn32mevXqmV0bAAAAAMCNXAqAixcv1rvvvqtNmzapuLhYCxYs0Jtvvml2bQAAAAAAN3IpAK5fv15LlixR9erVdffddys5OVkZGRlm1wYAAAAAcCOXAqCfn5+qVKnifF6zZk35+bl0+iAAAAAAwEO4lOLq1q2rbdu2yWKx6MqVK1q6dCnnAAIAAADAbcalADh+/HjFxcXpq6++UuvWrdWqVSslJiaaXRsAAAAAwI1cCoC1a9fWsmXLVFRUJLvdLpvNZnZdAAAAAAA3cykAvvXWW9fc/sc//tGtxQAAAAAAzONSADx06JDz8ZUrV7Rnzx6FhYWZVhQAAAAAwP1cCoAzZswo8zw/P19jx441pSAAAAAAgDlcug3ET9WuXVvHjx93dy0AAAAAABPd8DmAhmHowIEDCgoKMq0oAAAAAID73fA5gNLV+wLGxcWZUhAAAAAAwBw3dQ4gAAAAAOD241IA7N+/vywWy3VfX758udsKAgAAAACYw6UA2KJFC/3nP/9R7969ZbValZaWptLSUkVGRppdHwAAAADATVwKgJ9++qlWrlwpX19fSdJjjz2m3r17q3PnzqYWBwAAAABwH5duA3H69GldvnzZ+fzixYsqLi42rSgAAAAAgPu5tAIYFRWl3//+93rqqadkGIY2btyoAQMGmF0bAAAAAMCNXAqAI0eOVLNmzfTJJ5+oatWqeu211/Tb3/7W7NoAAAAAAG7k0iGgklS7dm01bNhQL730kqxWq8sTzJo1S/Hx8TdVHAAAAADAfVwKgGvWrNGYMWP097//XYWFhfrTn/6k5OTkCvfLzs7W2rVrb7lIAAAAAMCtcykAvvPOO1q1apVsNpuCgoKUkpKiZcuWlbvP2bNnNXfuXA0bNswthQIAAAAAbo1LAdDHx0c2m835vG7dus5bQlzPhAkTNGrUKNWsWfPWKgQAAAAAuIVLF4EJCAjQl19+KYvFIklat26datWqdd33r169WnXr1lVYWJhSUlLcU+ktCA72r+wScAehn+DJ6E94KnoTnorehLdxKQAmJCRo5MiROnLkiNq3b6+qVatq4cKF133/hg0bVFBQoOjoaJ07d06XLl3S9OnTlZCQ4LbCb0RBQWGlzIs7T3CwP/0Ej0V/wlPRm/BU9CY8lY+PRUFBtorfeBNcCoDFxcVKS0tTXl6e7Ha77r///nKvBPrWW285H6ekpGj37t2VFv4AAAAAAFe5dA7gK6+8Il9fX4WGhqpRo0Y3dBsIAAAAAIBncGkFsHHjxkpPT9dvfvMb1ahRw7k9ICCgwn1jYmIUExNz0wUCAAAAANzDpQC4detWbdq0qcw2i8WiL7/80pSiAAAAAADu51IA3L9/v9l1AAAAAABMVu45gOPHj3c+Pn36tOnFAAAAAADMU24APHDggPPx4MGDTS8GAAAAAGCecgOgYRjXfAwAAAAAuP24dBsI6epFXwAAAAAAt69yLwLjcDh07tw5GYYhu93ufPwDV24DAQAAAADwDOUGwEOHDqldu3bO0Ne2bVvna9wGAgAAAABuL+UGwIMHD/5SdQAAAAAATObyOYAAAAAAgNsbARAAAAAAvAQBEAAAAAC8BAEQAAAAALwEARAAAAAAvAQBEAAAAAC8BAEQAAAAALwEARAAAAAAvAQBEAAAAAC8BAEQAAAAALwEARAAAAAAvAQBEAAAAAC8BAEQAAAAALwEARAAAAAAvAQBEAAAAAC8hJ+Zgy9YsEAbN26UJHXo0EFxcXFmTgcAAAAAKIdpK4BZWVnauXOn1q5dq9TUVH3xxRf68MMPzZoOAAAAAFAB01YAg4ODFR8frypVqkiSQkND9e2335o1HQAAAACgAqYFwIYNGzof5+XlaePGjXr33XfNmg4AAAAAUAFTzwGUpNzcXD3//POKi4vTfffdZ/Z01xQc7F8p8+LORD/Bk9Gf8FT0JjwVvQlvY2oA3Ldvn0aMGKGEhARFRkaaOVW5CgoKK21u3FmCg/3pJ3gs+hOeit6Ep6I34al8fCwKCrKZMrZpAfDEiRN64YUXNHfuXIWFhZk1DQAAAADARaYFwKVLl+ry5cuaOXOmc1ufPn3Ut29fs6YEAAAAAJTDtAA4btw4jRs3zqzhAQAAAAA3yLT7AAIAAAAAPAsBEAAAAAC8BAEQAAAAALwEARAAAAAAvAQBEAAAAAC8BAEQAAAAALwEARAAAAAAvAQBEAAAAAC8BAEQAAAAALwEARAAAAAAvIRfZRdgtisldgUH+7ttvOLLpSo8X+S28QAAAADgl3LHB8AqVl91/3Oa28ZL/0u0Ct02GgAAAAD8cjgEFAAAAAC8BAEQAAAAALwEARAAAAAAvAQBEAAAAAC8BAEQAAAAALwEARAAAAAAvAQBEAAAAAC8BAEQAAAAALzEHX8jeHe7UmJXcLC/W8YqvlyqwvNFbhkLAAAAACpCALxBVay+6v7nNLeMlf6XaBW6ZSQAAAAAqBiHgAIAAACAlzA1AKanp6tbt27q1KmTkpKSzJwKAAAAAFAB0w4Bzc/P19y5c5WSkqIqVaqoT58+atu2rR588EGzprztuPN8QolzCgEAAACUz7QAmJWVpXbt2ikgIECS1LlzZ23atEkvvviiWVPedtx5PqEkrZkZxQVqAAAAAFyXaQHw5MmTCg4Odj4PCQlRTk6Oy/sH1armtlpC7q7utrHcPZ47x6pi9dXgqZvdMtai0U+4dXXy8uVSXbhQ7LbxKpOPj6WySwCui/6Ep6I34anoTXgiM/vSYhiGYcbAixYt0uXLl/XSSy9JkpKTk3XgwAG99tprZkwHAAAAAKiAaReBqVOnjgoKCpzPCwoKFBISYtZ0AAAAAIAKmBYAH330UWVnZ+v06dMqKirS5s2bFR4ebtZ0AAAAAIAKmHYOYO3atTVq1CgNGDBAJSUlio2N1UMPPWTWdAAAAACACph2DiAAAAAAwLOYeiN4AAAAAIDnIAACAAAAgJcgAAIAAACAlyAAAgAAAICXIAACAAAAgJfwqACYnp6ubt26qVOnTkpKSqrscuAlFixYoMjISEVGRmr27NmSpKysLHXv3l2dOnXS3Llzne/98ssvFRMTo86dO2vs2LEqLS2VJH377bfq16+funTpouHDh+vixYuV8llw55o1a5bi4+Ml0Z/wDJmZmYqJiVHXrl01depUSfQmPEdaWprzu33WrFmS6E9UrgsXLigqKkrHjh2T5L5+PH/+vIYOHaquXbuqX79+KigoqLgYw0N89913RseOHY0zZ84YFy9eNLp3727k5uZWdlm4w3388cfG73//e+Py5cvGlStXjAEDBhjp6elGhw4djCNHjhglJSXGoEGDjG3bthmGYRiRkZHGZ599ZhiGYYwZM8ZISkoyDMMwhg4damRkZBiGYRgLFiwwZs+eXSmfB3emrKwso23btsbo0aONoqIi+hOV7siRI0b79u2NEydOGFeuXDH69u1rbNu2jd6ER7h06ZLxyCOPGKdOnTJKSkqM2NhYY+vWrfQnKs3nn39uREVFGc2bNzeOHj3q1u/yyZMnG3/7298MwzCMtWvXGiNHjqywHo9ZAczKylK7du0UEBCgGjVqqHPnztq0aVNll4U7XHBwsOLj41WlShVZrVaFhoYqLy9P9957r371q1/Jz89P3bt316ZNm3T8+HEVFxerdevWkqSYmBht2rRJJSUl2rNnjzp37lxmO+AOZ8+e1dy5czVs2DBJUk5ODv2JSvfhhx+qW7duqlOnjqxWq+bOnavq1avTm/AIdrtdDodDRUVFKi0tVWlpqWw2G/2JSpOcnKyJEycqJCREknu/y7dt26bu3btLkqKiovSPf/xDJSUl5dbjZ9LnvGEnT55UcHCw83lISIhycnIqsSJ4g4YNGzof5+XlaePGjfrDH/7ws17Mz8//WY8GBwcrPz9fZ86ckc1mk5+fX5ntgDtMmDBBo0aN0okTJyRd+99K+hO/tMOHD8tqtWrYsGE6ceKEHn/8cTVs2JDehEew2WwaOXKkunbtqurVq+uRRx7h305UqmnTppV57s5+/PE+fn5+stlsOn36tGrXrn3dejxmBdDhcMhisTifG4ZR5jlgptzcXA0aNEhxcXH61a9+dc1evF6PXqtX6V24w+rVq1W3bl2FhYU5t12vD+lP/JLsdruys7M1ffp0rVq1Sjk5OTp69Ci9CY9w8OBBrVmzRh999JF27NghHx8f5eXl0Z/wGGZ+lxuGIR+f8iOex6wA1qlTR3v37nU+LygocC6TAmbat2+fRowYoYSEBEVGRmr37t1lTqD9oRfr1KlTZvv333+vkJAQBQYGqrCwUHa7Xb6+vvQu3GbDhg0qKChQdHS0zp07p0uXLun48ePy9fV1vof+RGW45557FBYWpsDAQEnSk08+qU2bNtGb8Ag7d+5UWFiYgoKCJF09XG7p0qX0JzzGT/vuVvoxJCRE33//verUqaPS0lJdvHhRAQEB5c7vMSuAjz76qLKzs3X69GkVFRVp8+bNCg8Pr+yycIc7ceKEXnjhBSUmJioyMlKS1KpVK33zzTc6fPiw7Ha7MjIyFB4ernr16qlq1arat2+fpKtXGAsPD5fVatXDDz+sDRs2SJJSU1PpXbjFW2+9pYyMDKWlpWnEiBGKiIjQ3//+d/oTla5jx47auXOnzp8/L7vdrh07dqhLly70JjxCkyZNlJWVpUuXLskwDGVmZvLdDo/izn7s0KGDUlNTJV394fjhhx+W1Wotd36LYRiGeR/vxqSnp+tvf/ubSkpKFBsbqyFDhlR2SbjDTZ06VWvWrFGDBg2c2/r06aP77rtPM2bM0OXLl9WhQweNGTNGFotFBw8e1Lhx43ThwgU1b95cM2bMUJUqVXT8+HHFx8fr1KlTqlu3rubMmaNatWpV4ifDnSYlJUW7d+/WzJkzlZ2dTX+i0r3//vt6++23VVJSot/97ncaN26cdu3aRW/CIyxevFgpKSmyWq1q2bKlJk6cqE8//ZT+RKWKiIjQ8uXLVb9+fbd9l589e1bx8fE6evSo/P39lZiYqPr165dbh0cFQAAAAACAeTzmEFAAAAAAgLkIgAAAAADgJQiAAAAAAOAlCIAAAAAA4CUIgAAAAADgJQiAAIBraty4sbp3767o6Ogyf44dO6Zdu3YpKirqpsdevXq1kpKSrvnau+++q8WLF5e7/5AhQ/Tvf/9bkjRo0CCdPn36pmu5Gdu2bdO8efN+0Tld9etf/1rHjh3T/v37NWLEiMouBwDgYfwquwAAgOdatmyZAgMDf7b9+PHjtzTuvn371LBhw2u+1rdv3wr3X7JkifPxxx9/fEu13Iz9+/fr3Llzv/i8N6Jly5b661//WtllAAA8DAEQAHBLrly5osTERO3Zs0d2u13NmjXTuHHjZLPZ9M0332jChAk6ffq0fHx8NHz4cFmtVmVmZurjjz9WtWrVdPr0aX3++ec6efKkGjdurHvvvVdnzpzRhAkTrrl/t27dFBERoXnz5mnlypWSpIEDB2r8+PGKi4tTZmamfHx8VFRUpIiICK1fv75MiJ0/f76OHDmi/Px8FRQUqHnz5mrbtq1SU1N17Ngxvfrqq87VzUWLFmnz5s1yOByqV6+eJk6cqO+++07vvfee7Ha7/P39NWrUKK1evVrvvvuuHA6HAgICNH78eIWGhio+Pl5nz57V0aNH9fjjj+vVV1911rFr1y5NmzZNNWrU0MWLF7VmzRrt3LlTixYtUklJiapVq6bRo0fr17/+tb7//ntNmDBBp06dUkFBgerVq6c33nhDQUFB2rt3r6ZMmSKLxaKWLVvK4XA4x58yZYoyMjIUHx8vm82mr776St99950aN26sWbNm6a677tL27duVmJgoHx8fNW3aVFlZWVq5cmWFNxIGANyeCIAAgOsaOHCgfHz+/2yB+vXr68033yzznsWLF8vX11cpKSmyWCyaM2eOEhMTNWnSJL388suKjY1Vv379dOLECfXv31+pqamKiIhQw4YN1a9fP82fP1/Hjx9XRkaG/Pz8NH/+fOfY19o/PDzc+fqMGTOUkpLiXKmsVauWduzYoQ4dOmj9+vUKCwu75grmvn37lJaWJqvVqvDwcN1zzz1KSkrSli1b9PrrrysqKkqpqak6dOiQVq9eLT8/P61atUrjxo3TkiVL1KdPH505c0ajRo3S7t27lZqaqqSkJFWvXl07d+7Uiy++qI0bN0qSiouLtX79+mv+/ebm5mrLli2qV6+e8vLyNHfuXC1fvlx33323cnNz9cc//lGbN2/W+vXr1bp1aw0dOlSGYWjo0KFKS0vTH/7wB40cOVKJiYkKCwtTRkaGkpOTrznXgQMHtHz5clksFvXu3VubNm1SRESE4uLitGzZMjVp0kRr167V2rVrXW8QAMBthwAIALiu6x0C+mPbtm1TYWGhsrKyJEklJSUKCgrS2bNndfDgQfXq1UuSVLduXW3ZsuWaY7Ru3Vp+fmW/km5k/x/069dPycnJ6tChg1atWqW4uLhrvu/RRx+Vv7+/JCkkJESPPfaYJKlBgwY6e/asJOmjjz7S/v379cwzz0iSHA6HioqKrvn5Dx8+rD59+ji3nT9/3jnOb37zm+vWW7duXdWrV0/S1UNZT548qf/+7/92vm6xWHTkyBENHDhQe/fu1VtvvaW8vDzl5uaqVatWOnTokPz8/BQWFiZJioqK0oQJE64512OPPaYqVapIkho1aqRz585p7969Cg0NVZMmTSRJPXv21NSpU69bLwDg9kcABADcEofDoYSEBHXo0EGSdPHiRV2+fNkZ6CwWi/O9X3/9tf7rv/7rZ2PUqFHjZ9tuZP8fdO/eXXPmzNEnn3yiS5cu6ZFHHrnm+34IQj+d66ef67nnntOzzz4r6eqhrtc678/hcCg6Otp5eKfD4dDJkydVq1at6362H/z4NYfDobCwML3xxhvObSdOnFBISIhef/115eTk6JlnnlHbtm1VWloqwzAkyfnf8j6LJFWrVs352GKxyDAM+fr6/mz/H6/4AgDuPPwrDwC4Je3bt1dSUpKuXLkih8Oh8ePHa86cObLZbGrevLlSU1MlXQ0zffv2VWFhoXx9fVVaWlruuOXt/2M/Hqt69erq0aOHEhISyqzI3eznev/993XhwgVJ0rx585wrij+es3379lq/fr1Onjwp6epVTAcOHHjD84WFhenjjz/Wf/7zH0nS9u3b1aNHDxUXF2vnzp0aOHCgnn76aQUFBSkrK0t2u12NGzeWYRjavn27JGnr1q03dHGaNm3aKC8vTwcPHpQkffDBBzp//nyZ0A0AuLOwAggAuK6fngMoXT0v78erSX/60580a9Ys9ezZU3a7XU2bNlV8fLwk6S9/+YsmT56sFStWyGKxaNq0aQoODlZ4eLhmzpxZ4fzX2//HunTpov79+2v+/Plq1KiRYmJilJycrKeffvqWPnuvXr2Un5+v3r17y2KxqG7dus6a27Vrp1deeUVTpkzR+PHjNWTIEA0aNEgWi0U2m00LFiy44RD14IMP6rXXXtPLL78swzDk5+enRYsW6a677tILL7yg2bNna968ebJarWrTpo2OHDkiq9WqN998U5MmTdKcOXPUtGlTBQUFuTxnQECA5syZo9GjR8vHx0ctWrSQn5+fqlevfkO1AwBuHxbjp8d+AABwmzIMQ0uWLNHx48c1efLkyi7H4124cEELFy7U//zP/6h69er64osv9Pzzz2vHjh2sAgLAHYoVQADAHeOJJ55QSEiIFi5cWNml3BZsNpusVqtiY2Pl5+cnPz8/vfHGG4Q/ALiDsQIIAAAAAF6Ci8AAAAAAgJcgAAIAAACAlyAAAgAAAICXIAACAAAAgJcgAAIAAACAlyAAAgAAAICX+D/flfrnmeO7iQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the target distribution\n",
    "ye.plot(kind='hist', bins=50, title='Target Distribution', xlim=(0, 1e4))\n",
    "plt.xlabel('Electricity meter reading')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw meter readings are highly right-skewed. We may be able to get more accurate predictions if we transform the target variable into a normal distribution to increase its linearity with the features. To do this, we will do a log transformation on the target variable and train our models using the log-transformed target. Of course, when making predictions, the output will be log-transformed values, so the predictions will have to be inverse-transformed to yield the true output.\n",
    "\n",
    "Note: the target variable contains meter readings of 0, so 1 will be added to all readings before taking the log (because log(0) is undefined) like this: `y_log_transformed = log(y + 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Log transform the target variable\n",
    "ye = np.log1p(ye)\n",
    "ye.plot(kind='hist', bins=50, title='Log-transformed Target Distribution', xlim=(0, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (6888971, 15) (6888971,)\n",
      "Validation set: (2296324, 15) (2296324,)\n",
      "Test set: (2296324, 15) (2296324,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>rel_humidity</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction_x</th>\n",
       "      <th>wind_direction_y</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>missing_year</th>\n",
       "      <th>country</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11668719</th>\n",
       "      <td>26.1</td>\n",
       "      <td>82.086754</td>\n",
       "      <td>1015.400024</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Office</td>\n",
       "      <td>26953</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15417488</th>\n",
       "      <td>18.9</td>\n",
       "      <td>78.094246</td>\n",
       "      <td>1020.099976</td>\n",
       "      <td>0.766044</td>\n",
       "      <td>-0.642788</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Education</td>\n",
       "      <td>66203</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>312</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4404673</th>\n",
       "      <td>4.4</td>\n",
       "      <td>50.354458</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>-0.766044</td>\n",
       "      <td>-0.642788</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Public services</td>\n",
       "      <td>400000</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>97</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          air_temperature  rel_humidity  sea_level_pressure  wind_direction_x  \\\n",
       "11668719             26.1     82.086754         1015.400024          0.866025   \n",
       "15417488             18.9     78.094246         1020.099976          0.766044   \n",
       "4404673               4.4     50.354458         1029.000000         -0.766044   \n",
       "\n",
       "          wind_direction_y  wind_speed      primary_use  square_feet  \\\n",
       "11668719          0.500000         3.1           Office        26953   \n",
       "15417488         -0.642788         1.5        Education        66203   \n",
       "4404673          -0.642788         4.6  Public services       400000   \n",
       "\n",
       "          year_built  missing_year country  dayofyear  hour  is_weekend  \\\n",
       "11668719         213             0      US        240     1           1   \n",
       "15417488         223             0      US        312    18           0   \n",
       "4404673          179             0      US         97     8           0   \n",
       "\n",
       "          is_holiday  \n",
       "11668719           0  \n",
       "15417488           0  \n",
       "4404673            0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/val/test split (60/20/20)\n",
    "Xe_train, Xe_test, ye_train, ye_test = train_test_split(Xe, ye, test_size=0.4, random_state=0)\n",
    "Xe_val, Xe_test, ye_val, ye_test = train_test_split(Xe_test, ye_test, test_size=0.5, random_state=0)\n",
    "\n",
    "print('Train set:', Xe_train.shape, ye_train.shape)\n",
    "print('Validation set:', Xe_val.shape, ye_val.shape)\n",
    "print('Test set:', Xe_test.shape, ye_test.shape)\n",
    "Xe_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12587"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del Xe, ye\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical feature encoding\n",
    "\n",
    "Next, we will perform the 2 types of categorical encoding as in the featurization notebook:\n",
    "1. Rare label categorical encoding - categorical labels that occur less than 5% in the data will be encoded as \"Rare\"\n",
    "    - This will be done for `primary_use`\n",
    "2. Mean target categorical encoding - categorical labels will be numerically encoded with the mean value of the target label for that particular label\n",
    "    - This will be done for `primary_use` and `country`\n",
    "    - Note: countries \"UK\" and \"IE\" were grouped into the label \"EU\"\n",
    "    \n",
    "The difference here is that the target label has been log-transformed, so the encoded values here will differ from the featurization notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'primary_use': Index(['Education', 'Office', 'Entertainment/public assembly',\n",
       "        'Public services', 'Lodging/residential'],\n",
       "       dtype='object')}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group all rare primary_use categories\n",
    "Xe_train, Xe_val, Xe_test, rare_dict = udf.rare_encoder(['primary_use'], Xe_train, Xe_test, val=Xe_val)\n",
    "rare_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train set #####\n",
      "Education                        2635696\n",
      "Office                           1310265\n",
      "Entertainment/public assembly     871248\n",
      "Public services                   788379\n",
      "Lodging/residential               678847\n",
      "Rare                              604536\n",
      "Name: primary_use, dtype: int64\n",
      "\n",
      "##### Validation set #####\n",
      "Education                        877922\n",
      "Office                           435865\n",
      "Entertainment/public assembly    291572\n",
      "Public services                  262875\n",
      "Lodging/residential              226541\n",
      "Rare                             201549\n",
      "Name: primary_use, dtype: int64\n",
      "\n",
      "##### Test set #####\n",
      "Education                        879687\n",
      "Office                           435391\n",
      "Entertainment/public assembly    290427\n",
      "Public services                  262464\n",
      "Lodging/residential              226333\n",
      "Rare                             202022\n",
      "Name: primary_use, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Value counts for `primary_use`\n",
    "print('##### Train set #####')\n",
    "print(Xe_train.primary_use.value_counts())\n",
    "print('\\n##### Validation set #####')\n",
    "print(Xe_val.primary_use.value_counts())\n",
    "print('\\n##### Test set #####')\n",
    "print(Xe_test.primary_use.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'primary_use': {'Education': 4.468423366546631,\n",
       "  'Entertainment/public assembly': 3.523334264755249,\n",
       "  'Lodging/residential': 3.9764797687530518,\n",
       "  'Office': 4.195037364959717,\n",
       "  'Public services': 3.760781764984131,\n",
       "  'Rare': 3.770461320877075},\n",
       " 'country': {'CA': 6.6370038986206055,\n",
       "  'EU': 3.4172074794769287,\n",
       "  'US': 4.179385185241699}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode categorical features using the target mean of each category\n",
    "Xe_train, Xe_val, Xe_test, mean_dict = udf.mean_encoder(['primary_use', 'country'], \n",
    "                                                        Xe_train, ye_train, Xe_test, X_val=Xe_val)\n",
    "mean_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train set: primary_use #####\n",
      "4.468423    2635696\n",
      "4.195037    1310265\n",
      "3.523334     871248\n",
      "3.760782     788379\n",
      "3.976480     678847\n",
      "3.770461     604536\n",
      "Name: primary_use, dtype: int64\n",
      "\n",
      "##### Train set: country #####\n",
      "4.179385    5885587\n",
      "3.417207     922469\n",
      "6.637004      80915\n",
      "Name: country, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Encoded value counts in train set\n",
    "print('##### Train set: primary_use #####')\n",
    "print(Xe_train.primary_use.value_counts())\n",
    "print('\\n##### Train set: country #####')\n",
    "print(Xe_train.country.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>rel_humidity</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction_x</th>\n",
       "      <th>wind_direction_y</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>missing_year</th>\n",
       "      <th>country</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.977865</td>\n",
       "      <td>0.741393</td>\n",
       "      <td>-0.120466</td>\n",
       "      <td>1.352629</td>\n",
       "      <td>0.853826</td>\n",
       "      <td>-0.197988</td>\n",
       "      <td>0.256614</td>\n",
       "      <td>-0.589092</td>\n",
       "      <td>1.827039</td>\n",
       "      <td>-1.108092</td>\n",
       "      <td>0.193303</td>\n",
       "      <td>0.495444</td>\n",
       "      <td>-1.517191</td>\n",
       "      <td>1.577058</td>\n",
       "      <td>-0.180158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.291863</td>\n",
       "      <td>0.562860</td>\n",
       "      <td>0.513359</td>\n",
       "      <td>1.204086</td>\n",
       "      <td>-0.880341</td>\n",
       "      <td>-0.886943</td>\n",
       "      <td>1.046239</td>\n",
       "      <td>-0.238802</td>\n",
       "      <td>2.298373</td>\n",
       "      <td>-1.108092</td>\n",
       "      <td>0.193303</td>\n",
       "      <td>1.180861</td>\n",
       "      <td>0.938746</td>\n",
       "      <td>-0.634092</td>\n",
       "      <td>-0.180158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.089669</td>\n",
       "      <td>-0.677575</td>\n",
       "      <td>1.713597</td>\n",
       "      <td>-1.072159</td>\n",
       "      <td>-0.880341</td>\n",
       "      <td>0.447907</td>\n",
       "      <td>-0.997653</td>\n",
       "      <td>2.740196</td>\n",
       "      <td>0.224504</td>\n",
       "      <td>-1.108092</td>\n",
       "      <td>0.193303</td>\n",
       "      <td>-0.865871</td>\n",
       "      <td>-0.505923</td>\n",
       "      <td>-0.634092</td>\n",
       "      <td>-0.180158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.299280</td>\n",
       "      <td>0.175473</td>\n",
       "      <td>1.201131</td>\n",
       "      <td>0.065963</td>\n",
       "      <td>0.095082</td>\n",
       "      <td>-1.532838</td>\n",
       "      <td>-1.683476</td>\n",
       "      <td>4.201882</td>\n",
       "      <td>-0.152563</td>\n",
       "      <td>0.902452</td>\n",
       "      <td>0.193303</td>\n",
       "      <td>-1.522729</td>\n",
       "      <td>-1.661658</td>\n",
       "      <td>-0.634092</td>\n",
       "      <td>-0.180158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.737140</td>\n",
       "      <td>-0.663548</td>\n",
       "      <td>1.956347</td>\n",
       "      <td>-0.192028</td>\n",
       "      <td>1.589516</td>\n",
       "      <td>0.921563</td>\n",
       "      <td>-0.374649</td>\n",
       "      <td>0.087578</td>\n",
       "      <td>-0.482496</td>\n",
       "      <td>-1.108092</td>\n",
       "      <td>-1.819603</td>\n",
       "      <td>1.380774</td>\n",
       "      <td>-0.072522</td>\n",
       "      <td>-0.634092</td>\n",
       "      <td>-0.180158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   air_temperature  rel_humidity  sea_level_pressure  wind_direction_x  \\\n",
       "0         0.977865      0.741393           -0.120466          1.352629   \n",
       "1         0.291863      0.562860            0.513359          1.204086   \n",
       "2        -1.089669     -0.677575            1.713597         -1.072159   \n",
       "3        -1.299280      0.175473            1.201131          0.065963   \n",
       "4        -0.737140     -0.663548            1.956347         -0.192028   \n",
       "\n",
       "   wind_direction_y  wind_speed  primary_use  square_feet  year_built  \\\n",
       "0          0.853826   -0.197988     0.256614    -0.589092    1.827039   \n",
       "1         -0.880341   -0.886943     1.046239    -0.238802    2.298373   \n",
       "2         -0.880341    0.447907    -0.997653     2.740196    0.224504   \n",
       "3          0.095082   -1.532838    -1.683476     4.201882   -0.152563   \n",
       "4          1.589516    0.921563    -0.374649     0.087578   -0.482496   \n",
       "\n",
       "   missing_year   country  dayofyear      hour  is_weekend  is_holiday  \n",
       "0     -1.108092  0.193303   0.495444 -1.517191    1.577058   -0.180158  \n",
       "1     -1.108092  0.193303   1.180861  0.938746   -0.634092   -0.180158  \n",
       "2     -1.108092  0.193303  -0.865871 -0.505923   -0.634092   -0.180158  \n",
       "3      0.902452  0.193303  -1.522729 -1.661658   -0.634092   -0.180158  \n",
       "4     -1.108092 -1.819603   1.380774 -0.072522   -0.634092   -0.180158  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale features using their mean and standard deviation\n",
    "Xe_train_scaled, Xe_val_scaled, Xe_test_scaled = udf.scale_feats(Xe_train, Xe_test, val=Xe_val)\n",
    "Xe_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del Xe_train, Xe_val, Xe_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature sets\n",
    "\n",
    "Building on the featurization notebook, we will be creating several feature sets for model training to try see if we can get better predictions:\n",
    "1. All features (15) - full feature set\n",
    "2. Custom features (10) - drop the 5 features that were selected 0 times in the featurization notebook\n",
    "    - `rel_humidity`, `sea_level_pressure`, `wind_direction_x`, `wind_direction_y`, `wind_speed`\n",
    "3. Lasso RFE features (8) - features selected from the lasso RFE method\n",
    "4. Tree RFE features (7) - features selected from the decision tree RFE method, except for `site_id`, which was just dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_corr</th>\n",
       "      <th>lasso_coef</th>\n",
       "      <th>lasso_coef_recursive</th>\n",
       "      <th>tree_importance</th>\n",
       "      <th>tree_importance_recursive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>square_feet</td>\n",
       "      <td>primary_use</td>\n",
       "      <td>primary_use</td>\n",
       "      <td>square_feet</td>\n",
       "      <td>site_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>country</td>\n",
       "      <td>square_feet</td>\n",
       "      <td>square_feet</td>\n",
       "      <td>year_built</td>\n",
       "      <td>air_temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>country</td>\n",
       "      <td>missing_year</td>\n",
       "      <td>country</td>\n",
       "      <td>primary_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>is_weekend</td>\n",
       "      <td>country</td>\n",
       "      <td></td>\n",
       "      <td>square_feet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>dayofyear</td>\n",
       "      <td></td>\n",
       "      <td>year_built</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hour</td>\n",
       "      <td></td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>is_weekend</td>\n",
       "      <td></td>\n",
       "      <td>dayofyear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>is_holiday</td>\n",
       "      <td></td>\n",
       "      <td>hour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_corr   lasso_coef lasso_coef_recursive tree_importance  \\\n",
       "0  square_feet  primary_use          primary_use     square_feet   \n",
       "1      country  square_feet          square_feet      year_built   \n",
       "2                   country         missing_year         country   \n",
       "3                is_weekend              country                   \n",
       "4                                      dayofyear                   \n",
       "5                                           hour                   \n",
       "6                                     is_weekend                   \n",
       "7                                     is_holiday                   \n",
       "\n",
       "  tree_importance_recursive  \n",
       "0                   site_id  \n",
       "1           air_temperature  \n",
       "2               primary_use  \n",
       "3               square_feet  \n",
       "4                year_built  \n",
       "5                   country  \n",
       "6                 dayofyear  \n",
       "7                      hour  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected features from featurization notebook\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['air_temperature',\n",
       " 'rel_humidity',\n",
       " 'sea_level_pressure',\n",
       " 'wind_direction_x',\n",
       " 'wind_direction_y',\n",
       " 'wind_speed',\n",
       " 'primary_use',\n",
       " 'square_feet',\n",
       " 'year_built',\n",
       " 'missing_year',\n",
       " 'country',\n",
       " 'dayofyear',\n",
       " 'hour',\n",
       " 'is_weekend',\n",
       " 'is_holiday']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full feature set\n",
    "all_feats = Xe_train_scaled.columns.tolist()\n",
    "print(len(all_feats))\n",
    "all_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['air_temperature',\n",
       " 'primary_use',\n",
       " 'square_feet',\n",
       " 'year_built',\n",
       " 'missing_year',\n",
       " 'country',\n",
       " 'dayofyear',\n",
       " 'hour',\n",
       " 'is_weekend',\n",
       " 'is_holiday']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom feature set\n",
    "custom_drop = ['rel_humidity', 'sea_level_pressure', 'wind_direction_x', 'wind_direction_y', 'wind_speed']\n",
    "custom_feats = Xe_train_scaled.drop(custom_drop, axis=1).columns.tolist()\n",
    "\n",
    "print(len(custom_feats))\n",
    "custom_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['primary_use',\n",
       " 'square_feet',\n",
       " 'missing_year',\n",
       " 'country',\n",
       " 'dayofyear',\n",
       " 'hour',\n",
       " 'is_weekend',\n",
       " 'is_holiday']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso RFE feature set\n",
    "lasso_feats = feats['lasso_coef_recursive'].tolist()\n",
    "print(len(lasso_feats))\n",
    "lasso_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['air_temperature',\n",
       " 'primary_use',\n",
       " 'square_feet',\n",
       " 'year_built',\n",
       " 'country',\n",
       " 'dayofyear',\n",
       " 'hour']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree RFE feature set\n",
    "tree_feats = feats['tree_importance_recursive'].tolist()[1:]\n",
    "print(len(tree_feats))\n",
    "tree_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del feats, custom_drop\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section III: Modeling - Electricity\n",
    "\n",
    "With the 4 feature sets we just created, we will be training 3 different models - a linear model and 2 tree-based models:\n",
    "1. `Lasso regression` (linear regression with L1 regularization) - this will be the baseline model for prediction performance\n",
    "    - As we did use lasso regression to create one of the feature sets, that feature set is optimized for lasso regression, so this model may do quite well\n",
    "2. LightGBM - a parallelizable gradient boosting machines (GBM) implementation that grows trees leaf-wise, which can reduce loss more than the commonly used depth-wise implementation *\n",
    "    - Another one of the feature sets was created with decision tree, so that's why we are using tree-based models\n",
    "3. XGBoost - another parallelizable GBM implementation that has a reputation of winning Kaggle competitions involving structured data\n",
    "    - Although not as fast as LightGBM, I suspect this algorithm will produce the best predictions\n",
    "    \n",
    "For each of the 3 models above, we will be tuning the model hyperparameters and training it on each of the 4 feature sets to select the model with the highest scores. The metric we are using to evaluate model performance is the `root mean squared error`. This is the most commonly used metric for evaluating regression models, and for good reason: it is easy to compute and understand, much like the `mean absolute error`, but has the added benefit of penalizing larger errors more so that the optimization process can be more robust to outliers.\n",
    "\n",
    "##### \\* Note: Read more about LightGBM and XGBoost [here](https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/). Pranjal provides a great comparison between the 2 algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso regression\n",
    "\n",
    "Again, this will be the baseline model for performance. This will give us an idea of the performance we can expect with the data. With only 1 hyperparamer to tune, a simple for loop would do the trick. But we are going to take advantage of Scikit-learn's grid search for the detailed results it provides. The only thing we are tuning here is the `alpha` parameter, which controls the degree of L1 regularization in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>-1.116370</td>\n",
       "      <td>-1.116607</td>\n",
       "      <td>-1.115951</td>\n",
       "      <td>-1.117037</td>\n",
       "      <td>-1.116491</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>-1.116380</td>\n",
       "      <td>-1.116616</td>\n",
       "      <td>-1.115960</td>\n",
       "      <td>-1.117044</td>\n",
       "      <td>-1.116500</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>-1.117120</td>\n",
       "      <td>-1.117382</td>\n",
       "      <td>-1.116698</td>\n",
       "      <td>-1.117792</td>\n",
       "      <td>-1.117248</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>-1.139569</td>\n",
       "      <td>-1.139799</td>\n",
       "      <td>-1.139120</td>\n",
       "      <td>-1.140224</td>\n",
       "      <td>-1.139678</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>-1.485414</td>\n",
       "      <td>-1.485675</td>\n",
       "      <td>-1.485209</td>\n",
       "      <td>-1.484830</td>\n",
       "      <td>-1.485282</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0000</th>\n",
       "      <td>-1.485414</td>\n",
       "      <td>-1.485675</td>\n",
       "      <td>-1.485209</td>\n",
       "      <td>-1.484830</td>\n",
       "      <td>-1.485282</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             split0_test_score  split1_test_score  split2_test_score  \\\n",
       "param_alpha                                                            \n",
       "0.0001               -1.116370          -1.116607          -1.115951   \n",
       "0.0010               -1.116380          -1.116616          -1.115960   \n",
       "0.0100               -1.117120          -1.117382          -1.116698   \n",
       "0.1000               -1.139569          -1.139799          -1.139120   \n",
       "1.0000               -1.485414          -1.485675          -1.485209   \n",
       "10.0000              -1.485414          -1.485675          -1.485209   \n",
       "\n",
       "             split3_test_score  mean_test_score  std_test_score  \\\n",
       "param_alpha                                                       \n",
       "0.0001               -1.117037        -1.116491        0.000393   \n",
       "0.0010               -1.117044        -1.116500        0.000392   \n",
       "0.0100               -1.117792        -1.117248        0.000398   \n",
       "0.1000               -1.140224        -1.139678        0.000399   \n",
       "1.0000               -1.484830        -1.485282        0.000309   \n",
       "10.0000              -1.484830        -1.485282        0.000309   \n",
       "\n",
       "             rank_test_score  \n",
       "param_alpha                   \n",
       "0.0001                     1  \n",
       "0.0010                     2  \n",
       "0.0100                     3  \n",
       "0.1000                     4  \n",
       "1.0000                     5  \n",
       "10.0000                    5  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression with full feature set (15)\n",
    "params = {'alpha': [10 ** e for e in range(-4, 2)]}\n",
    "lasso15 = GridSearchCV(Lasso(random_state=0), params, cv=4, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=-1)\n",
    "lasso15.fit(Xe_train_scaled, ye_train)\n",
    "pd.DataFrame(lasso15.cv_results_).set_index('param_alpha').iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>-1.119237</td>\n",
       "      <td>-1.119506</td>\n",
       "      <td>-1.118950</td>\n",
       "      <td>-1.119851</td>\n",
       "      <td>-1.119386</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>-1.119239</td>\n",
       "      <td>-1.119511</td>\n",
       "      <td>-1.118952</td>\n",
       "      <td>-1.119860</td>\n",
       "      <td>-1.119390</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>-1.119598</td>\n",
       "      <td>-1.119892</td>\n",
       "      <td>-1.119296</td>\n",
       "      <td>-1.120267</td>\n",
       "      <td>-1.119763</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>-1.139775</td>\n",
       "      <td>-1.139996</td>\n",
       "      <td>-1.139284</td>\n",
       "      <td>-1.140418</td>\n",
       "      <td>-1.139868</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             split0_test_score  split1_test_score  split2_test_score  \\\n",
       "param_alpha                                                            \n",
       "0.0001               -1.119237          -1.119506          -1.118950   \n",
       "0.0010               -1.119239          -1.119511          -1.118952   \n",
       "0.0100               -1.119598          -1.119892          -1.119296   \n",
       "0.1000               -1.139775          -1.139996          -1.139284   \n",
       "\n",
       "             split3_test_score  mean_test_score  std_test_score  \\\n",
       "param_alpha                                                       \n",
       "0.0001               -1.119851        -1.119386        0.000333   \n",
       "0.0010               -1.119860        -1.119390        0.000335   \n",
       "0.0100               -1.120267        -1.119763        0.000359   \n",
       "0.1000               -1.140418        -1.139868        0.000409   \n",
       "\n",
       "             rank_test_score  \n",
       "param_alpha                   \n",
       "0.0001                     1  \n",
       "0.0010                     2  \n",
       "0.0100                     3  \n",
       "0.1000                     4  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression with custom feature set (10)\n",
    "params = {'alpha': [10 ** e for e in range(-4, 0)]}\n",
    "lasso10 = GridSearchCV(Lasso(random_state=0), params, cv=4, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=-1)\n",
    "lasso10.fit(Xe_train_scaled[custom_feats], ye_train)\n",
    "pd.DataFrame(lasso10.cv_results_).set_index('param_alpha').iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:   46.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>-1.128990</td>\n",
       "      <td>-1.129433</td>\n",
       "      <td>-1.128609</td>\n",
       "      <td>-1.129648</td>\n",
       "      <td>-1.129170</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>-1.128992</td>\n",
       "      <td>-1.129437</td>\n",
       "      <td>-1.128610</td>\n",
       "      <td>-1.129655</td>\n",
       "      <td>-1.129174</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>-1.129291</td>\n",
       "      <td>-1.129730</td>\n",
       "      <td>-1.128896</td>\n",
       "      <td>-1.129977</td>\n",
       "      <td>-1.129473</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>-1.144999</td>\n",
       "      <td>-1.145229</td>\n",
       "      <td>-1.144494</td>\n",
       "      <td>-1.145633</td>\n",
       "      <td>-1.145089</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             split0_test_score  split1_test_score  split2_test_score  \\\n",
       "param_alpha                                                            \n",
       "0.0001               -1.128990          -1.129433          -1.128609   \n",
       "0.0010               -1.128992          -1.129437          -1.128610   \n",
       "0.0100               -1.129291          -1.129730          -1.128896   \n",
       "0.1000               -1.144999          -1.145229          -1.144494   \n",
       "\n",
       "             split3_test_score  mean_test_score  std_test_score  \\\n",
       "param_alpha                                                       \n",
       "0.0001               -1.129648        -1.129170        0.000401   \n",
       "0.0010               -1.129655        -1.129174        0.000404   \n",
       "0.0100               -1.129977        -1.129473        0.000414   \n",
       "0.1000               -1.145633        -1.145089        0.000412   \n",
       "\n",
       "             rank_test_score  \n",
       "param_alpha                   \n",
       "0.0001                     1  \n",
       "0.0010                     2  \n",
       "0.0100                     3  \n",
       "0.1000                     4  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression with lasso RFE feature set (8)\n",
    "lasso8 = GridSearchCV(Lasso(random_state=0), params, cv=4, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=-1)\n",
    "lasso8.fit(Xe_train_scaled[lasso_feats], ye_train)\n",
    "pd.DataFrame(lasso8.cv_results_).set_index('param_alpha').iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:   59.8s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>-1.122640</td>\n",
       "      <td>-1.122912</td>\n",
       "      <td>-1.122351</td>\n",
       "      <td>-1.123326</td>\n",
       "      <td>-1.122807</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>-1.122641</td>\n",
       "      <td>-1.122915</td>\n",
       "      <td>-1.122353</td>\n",
       "      <td>-1.123333</td>\n",
       "      <td>-1.122810</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>-1.122875</td>\n",
       "      <td>-1.123168</td>\n",
       "      <td>-1.122577</td>\n",
       "      <td>-1.123608</td>\n",
       "      <td>-1.123057</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>-1.139775</td>\n",
       "      <td>-1.139996</td>\n",
       "      <td>-1.139284</td>\n",
       "      <td>-1.140418</td>\n",
       "      <td>-1.139868</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             split0_test_score  split1_test_score  split2_test_score  \\\n",
       "param_alpha                                                            \n",
       "0.0001               -1.122640          -1.122912          -1.122351   \n",
       "0.0010               -1.122641          -1.122915          -1.122353   \n",
       "0.0100               -1.122875          -1.123168          -1.122577   \n",
       "0.1000               -1.139775          -1.139996          -1.139284   \n",
       "\n",
       "             split3_test_score  mean_test_score  std_test_score  \\\n",
       "param_alpha                                                       \n",
       "0.0001               -1.123326        -1.122807        0.000359   \n",
       "0.0010               -1.123333        -1.122810        0.000361   \n",
       "0.0100               -1.123608        -1.123057        0.000381   \n",
       "0.1000               -1.140418        -1.139868        0.000409   \n",
       "\n",
       "             rank_test_score  \n",
       "param_alpha                   \n",
       "0.0001                     1  \n",
       "0.0010                     2  \n",
       "0.0100                     3  \n",
       "0.1000                     4  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression with decision tree RFE feature set (7)\n",
    "lasso7 = GridSearchCV(Lasso(random_state=0), params, cv=4, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=-1)\n",
    "lasso7.fit(Xe_train_scaled[tree_feats], ye_train)\n",
    "pd.DataFrame(lasso7.cv_results_).set_index('param_alpha').iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 4 feature sets, the full feature set produced the lowest error with an `alpha` value of `0.0001`. We can see that the error decreases as `alpha` decreases, but going from an `alpha` value of `0.001` to `0.0001` did not decrease the error by much, so it's unnecessary to go any smaller for `alpha`.\n",
    "\n",
    "Even though there is little difference in error between the 4 feature sets, it's clear that using less features increases the error. But interestingly, the decision tree set (with 7 features) did slightly better than the lasso set (with 8 features). This suggests 2 things:\n",
    "1. The 3 features present in both the custom set and lasso set, but absent from the tree set - `missing_year`, `is_weekend`, and `is_holiday` - are not providing much information to the model. This is because of the minimal difference in error with or without these features.\n",
    "2. Either (or both) the features present in the tree set, but absent from the lasso set - `air_temperature` and `year_built` - are important features because the model did worse without them.\n",
    "\n",
    "The top 2 choices here are:\n",
    "1. Full set (15 features) - This would be the better option if the goal is to minimize prediction error\n",
    "2. Decision tree set (7 features) - This would be the better option if the goal was to keep the model simple (minimize complexity) for better explainability without losing too much prediction performance\n",
    "\n",
    "Since the goal here is to minimize the prediction error, we will be going with the full feature set. But first, let's check if the difference in prediction error between these two sets is similar when makinng predictions on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Feature Set\n",
      "-------------------------\n",
      "Training RMSE: 1.122805826563009\n",
      "Validation RMSE: 1.1240332870128327\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>square_feet</td>\n",
       "      <td>0.816805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>primary_use</td>\n",
       "      <td>0.289410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>country</td>\n",
       "      <td>0.200245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>year_built</td>\n",
       "      <td>0.149502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hour</td>\n",
       "      <td>0.057963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_temperature</td>\n",
       "      <td>0.002877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dayofyear</td>\n",
       "      <td>-0.010735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feat      coef\n",
       "2      square_feet  0.816805\n",
       "1      primary_use  0.289410\n",
       "4          country  0.200245\n",
       "3       year_built  0.149502\n",
       "6             hour  0.057963\n",
       "0  air_temperature  0.002877\n",
       "5        dayofyear -0.010735"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression with tree set (7)\n",
    "lasso7 = Lasso(alpha=1e-4, random_state=0).fit(Xe_train_scaled[tree_feats], ye_train)\n",
    "\n",
    "# RMSE for predictions on train and validation sets\n",
    "print('Decision Tree Feature Set')\n",
    "print('-------------------------')\n",
    "print('Training RMSE:', np.sqrt(mean_squared_error(ye_train, lasso7.predict(Xe_train_scaled[tree_feats]))))\n",
    "print('Validation RMSE:', np.sqrt(mean_squared_error(ye_val, lasso7.predict(Xe_val_scaled[tree_feats]))))\n",
    "print('-------------------------')\n",
    "\n",
    "# Feature coefficients\n",
    "pd.DataFrame(zip(tree_feats, lasso7.coef_), columns=['feat', 'coef']).sort_values('coef', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Feature Set\n",
      "----------------\n",
      "Training RMSE: 1.116488426422704\n",
      "Validation RMSE: 1.1178666422033643\n",
      "----------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>square_feet</td>\n",
       "      <td>0.818479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>primary_use</td>\n",
       "      <td>0.293400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>country</td>\n",
       "      <td>0.179818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>year_built</td>\n",
       "      <td>0.146047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hour</td>\n",
       "      <td>0.044884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>missing_year</td>\n",
       "      <td>0.039700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dayofyear</td>\n",
       "      <td>0.011316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wind_direction_y</td>\n",
       "      <td>-0.005384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wind_speed</td>\n",
       "      <td>-0.019623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wind_direction_x</td>\n",
       "      <td>-0.021407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is_holiday</td>\n",
       "      <td>-0.025455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sea_level_pressure</td>\n",
       "      <td>-0.027101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_temperature</td>\n",
       "      <td>-0.036747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>is_weekend</td>\n",
       "      <td>-0.074217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rel_humidity</td>\n",
       "      <td>-0.085652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feat      coef\n",
       "7          square_feet  0.818479\n",
       "6          primary_use  0.293400\n",
       "10             country  0.179818\n",
       "8           year_built  0.146047\n",
       "12                hour  0.044884\n",
       "9         missing_year  0.039700\n",
       "11           dayofyear  0.011316\n",
       "4     wind_direction_y -0.005384\n",
       "5           wind_speed -0.019623\n",
       "3     wind_direction_x -0.021407\n",
       "14          is_holiday -0.025455\n",
       "2   sea_level_pressure -0.027101\n",
       "0      air_temperature -0.036747\n",
       "13          is_weekend -0.074217\n",
       "1         rel_humidity -0.085652"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression with full feature set (15)\n",
    "lasso = Lasso(alpha=1e-4, random_state=0).fit(Xe_train_scaled, ye_train)\n",
    "\n",
    "# RMSE for predictions on train and validation sets\n",
    "print('Full Feature Set')\n",
    "print('----------------')\n",
    "print('Training RMSE:', np.sqrt(mean_squared_error(ye_train, lasso.predict(Xe_train_scaled))))\n",
    "print('Validation RMSE:', np.sqrt(mean_squared_error(ye_val, lasso.predict(Xe_val_scaled))))\n",
    "print('----------------')\n",
    "\n",
    "# Feature coefficients\n",
    "coefs = pd.DataFrame(zip(Xe_train_scaled.columns, lasso.coef_), columns=['feat', 'coef'])\\\n",
    "          .sort_values('coef', ascending=False)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "832"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del lasso8, lasso10, lasso15, params, coefs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction error of the validation set confirms that training the model on the full feature set does a little better than using a reduced set, with the following root mean squared error (RMSE) scores:\n",
    "- Full feature set: 1.1165 (train) and 1.1179 (validation)\n",
    "- Decision tree RFE feature set: 1.1228 (train) and 1.1240 (validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM\n",
    "\n",
    "Now that we have a baseline model, let's see if we can do better with a gradient boosting model. With LightGBM, there are quite a bit of hyperparameters to tune. And with the cross-validation folds and number of options for each parameter, the number of trials can get exponentially high, so a parameter grid search is not feasible here.\n",
    "\n",
    "Instead, we will use `Optuna` to optimize LightGBM's parameters. `Optuna` takes a Bayesian approach to hyperparameter tuning, learning from previous trials to optimize each parameter. This is much more efficient than a grid search, which does a brute force search through every parameter combination.\n",
    "\n",
    "To use `Optuna`, we must define the objective function for the parameter optimization process. This objective function will be used on every trial to evaluate the model's prediction performance using that trial's parameters. On every trial of the `Optuna` study, the function will do the following:\n",
    "1. Save the study object - to save progress in case it is interrupted\n",
    "2. Define the parameters to tune and distribution of values to search for each parameter - `Optuna` uses a distribution of values, instead of a list of explicit values\n",
    "    - This allows us to get more fine-grained with the parameter values\n",
    "3. Create a LightGBM `Dataset` object for the data - the LightGBM model has its own data object so we must convert the data to said object in order to train the model\n",
    "4. Train and evaluate model on the validation set - predictions are made on the validation set and evaluated using the root mean squared error (RMSE)\n",
    "    - Negative prerdictions are replaced with 0 because there can't be negative energy consumption\n",
    "5. Return evaluation metric to minimize (model loss) - in this case, we are trying to minimize the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for Optuna study\n",
    "lgb_path = '../models/electricity/lgb/'\n",
    "udf.mkdir(lgb_path)\n",
    "\n",
    "\n",
    "def objective_lgb(trial):\n",
    "    \n",
    "    \"\"\" Objective function for Optuna study to optimize model hyperparameters \"\"\"\n",
    "    \n",
    "    # Save study\n",
    "    joblib.dump(study_lgb, lgb_path + 'study_lgb.pkl')\n",
    "    \n",
    "    # LightGBM parameters to tune\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-4, 1e1),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-4, 1e1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 100),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 2048),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 5000),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.5, 1.0),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.5, 1.0),\n",
    "        'num_iterations': 1000,\n",
    "        'early_stopping_round': 10,\n",
    "        'metric': 'rmse',\n",
    "        'num_threads': -1,\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    # LightGBM dataset objects\n",
    "    dtrain = lgb.Dataset(Xe_train_scaled, label=ye_train)\n",
    "    dval = lgb.Dataset(Xe_val_scaled, label=ye_val)\n",
    "    \n",
    "    # Train and evaluate model\n",
    "    lgbm = lgb.train(params, dtrain, valid_sets=[dtrain, dval], valid_names=['train', 'valid'], verbose_eval=False)\n",
    "    pred = lgbm.predict(Xe_val_scaled)\n",
    "    pred[pred < 0] = 0 # replace negative predictions with 0\n",
    "    loss = np.sqrt(mean_squared_error(ye_val, pred)) # RMSE\n",
    "\n",
    "#     # Cross validation on train set (no validation set)\n",
    "#     cv = lgb.cv(params, dtrain, folds=KFold(10, shuffle=True, random_state=0), verbose_eval=False)\n",
    "#     loss = cv['rmse-mean'][-1]\n",
    "    \n",
    "    # RMSE\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the objective function defined, we can now run the trials to optimize our parameters. Since we are evaluating the model using the RMSE, the goal is to minimize this metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-04 16:00:23,114]\u001b[0m A new study created in memory with name: no-name-f374a28b-33a3-435b-88c6-84fe150f8da9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2021-01-04 16:00:23.113271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tribui/miniconda3/envs/minds/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/tribui/miniconda3/envs/minds/lib/python3.7/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.279312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1875\n",
      "[LightGBM] [Info] Number of data points in the train set: 6888971, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.106192\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-fb5e3efabf96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Run trials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mstudy_lgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mstudy_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_lgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# End time and total run time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tribui/miniconda3/envs/minds/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 self._optimize_sequential(\n\u001b[0;32m--> 328\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m                 )\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tribui/miniconda3/envs/minds/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[1;32m    724\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tribui/miniconda3/envs/minds/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    753\u001b[0m     ) -> None:\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tribui/miniconda3/envs/minds/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Trial {} pruned. {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-790ddfa805ef>\u001b[0m in \u001b[0;36mobjective_lgb\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Train and evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mlgbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXe_val_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# replace negative predictions with 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tribui/miniconda3/envs/minds/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    250\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tribui/miniconda3/envs/minds/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2370\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   2371\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2372\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   2373\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2374\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start time\n",
    "start_lgb = dt.datetime.now()\n",
    "print('Start:', start_lgb)\n",
    "\n",
    "# Enable logging\n",
    "optuna.logging.enable_default_handler()\n",
    "\n",
    "# Run trials\n",
    "study_lgb = optuna.create_study(direction='minimize')\n",
    "study_lgb.optimize(objective_lgb, n_trials=100)\n",
    "joblib.dump(study_lgb, lgb_path + 'study_lgb.pkl') # Save study after last trial\n",
    "\n",
    "# End time and total run time\n",
    "end_lgb = dt.datetime.now()\n",
    "print('End:', end_lgb)\n",
    "print('Run time:', end_lgb - start_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trials: 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No trials are completed yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-f1e335f2312b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstudy_lgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgb_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'study_lgb.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished trials:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best trial:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mstudy_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tribui/miniconda3/envs/minds/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36mbest_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \"\"\"\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_study_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tribui/miniconda3/envs/minds/lib/python3.7/site-packages/optuna/storages/_in_memory.py\u001b[0m in \u001b[0;36mget_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mbest_trial_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_studies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_trial_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No trials are completed yet.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No trials are completed yet."
     ]
    }
   ],
   "source": [
    "# Study results\n",
    "study_lgb = joblib.load(lgb_path + 'study_lgb.pkl')\n",
    "print('Finished trials:', len(study_lgb.trials))\n",
    "print('Best trial:', study_lgb.best_trial.value)\n",
    "study_lgb.best_trial.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters yielded from the best trial are the optimized parameters and will be the final setting to train our LightGBM model. One caveat is that the Optuna study was run with a LightGBM model that builds 1,000 estimators (`num_iterations` = 1000) so the parameters were optimized to this value, more specifically the `learning_rate`, which is inversely proportional to `num_iterations`.\n",
    "\n",
    "We will be increasing `num_iterations` to 10,000 (10x the original value) to try to improve the gradient descent process. To adjust the `learning_rate` accordingly, we will divide it by 10 (the same factor `num_iterations` was increased by). \n",
    "\n",
    "Let's train a LightGBM model using the optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tri/miniconda3/envs/minimal_ds/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/tri/miniconda3/envs/minimal_ds/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "# LightGBM datasets\n",
    "edtrain = lgb.Dataset(Xe_train_scaled, label=ye_train)\n",
    "edval = lgb.Dataset(Xe_val_scaled, label=ye_val)\n",
    "\n",
    "# Fixed parameters\n",
    "params_lgb['num_iterations'] = 10000\n",
    "params_lgb['early_stopping_round'] = 10\n",
    "params_lgb['metric'] = 'rmse'\n",
    "params_lgb['num_threads'] = -1\n",
    "params_lgb['seed'] = 0\n",
    "\n",
    "# Parameters from Optuna\n",
    "params_lgb = dict(study_lgb.best_trial.params)\n",
    "params_lgb['learning_rate'] /= 10 # adjust learning rate for the increase in iterations\n",
    "\n",
    "# Train data\n",
    "lgbm = lgb.train(params_lgb, edtrain, valid_sets=[edtrain, edval], verbose_eval=False)\n",
    "joblib.dump(lgbm, lgb_path + 'lgbm.pkl') # save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSLE: 0.026196208827996406\n",
      "Validation RMSLE: 0.04244904812929961\n",
      "Test RMSLE: 0.04243108424829185\n"
     ]
    }
   ],
   "source": [
    "# Train set RMSE\n",
    "pred_train = lgbm.predict(Xe_train_scaled) # make predictions\n",
    "pred_train[pred_train < 0] = 0 # replace negative predictions with 0\n",
    "rmse_train = np.sqrt(mean_squared_error(ye_train, pred_train)) # RMSE\n",
    "print('Train RMSE:', rmse_train)\n",
    "\n",
    "# Validation set RMSE\n",
    "pred_val = lgbm.predict(Xe_val_scaled) # make predictions\n",
    "pred_val[pred_val < 0] = 0 # replace negative predictions with 0\n",
    "rmse_val = np.sqrt(mean_squared_error(ye_val, pred_val)) # RMSE\n",
    "print('Validation RMSE:', rmse_val)\n",
    "\n",
    "# Test set RMSE\n",
    "pred_test = lgbm.predict(Xe_test_scaled) # make predictions\n",
    "pred_test[pred_test < 0] = 0 # replace negative predictions with 0\n",
    "rmse_test = np.sqrt(mean_squared_error(ye_test, pred_test)) # RMSE\n",
    "print('Test RMSE:', rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del edtrain, edval, pred_train, rmsle_train, pred_val, rmsle_val, pred_test, rmsle_test, lgb_path\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function for parameter optimization\n",
    "def objective_xgb(trial):\n",
    "    \n",
    "    joblib.dump(study_xgb, '../objects/study_xgb.pkl')\n",
    "    \n",
    "    dtrain = xgb.DMatrix(Xe_val_scaled, label=ye_val)\n",
    "    dval = xgb.DMatrix(Xe_test_scaled, label=ye_test)\n",
    "\n",
    "    params = {\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e1),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-4, 1e1),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 100),\n",
    "        'max_leaves': trial.suggest_int('max_leaves', 2, 2024),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        'eval_metric': 'rmse',\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    xg = xgb.train(params, dtrain, \n",
    "                   evals=[(dtrain, 'train'), (dval, 'valid')],\n",
    "                   num_boost_round=1000, \n",
    "                   early_stopping_rounds=10,\n",
    "                   verbose_eval=False)\n",
    "    pred = xg.predict(dval)\n",
    "    pred[pred < 0] = 0\n",
    "    loss = mean_squared_log_error(ye_test, pred)\n",
    "\n",
    "#     cv = xgb.cv(params, dtrain, folds=KFold(10, shuffle=True, random_state=42), verbose_eval=False)\n",
    "#     loss = cv['rmse-mean'][-1]\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2020-02-23 13:13:18.932007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-23 14:26:00,411] Finished trial#0 resulted in value: 1.014672040939331. Current best value is 1.014672040939331 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.00010069183554683488, 'alpha': 0.14384678195306266, 'lambda': 0.1317389907961515, 'gamma': 0.008574945454197852, 'max_depth': 51, 'max_leaves': 492, 'subsample': 0.7480647963609484, 'colsample_bytree': 0.6682914717308165}.\n",
      "[I 2020-02-23 15:51:13,613] Finished trial#1 resulted in value: 0.003139552427455783. Current best value is 0.003139552427455783 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.010676140508226309, 'alpha': 7.6730547426007245, 'lambda': 0.26342508503760165, 'gamma': 0.16128207492657728, 'max_depth': 77, 'max_leaves': 1442, 'subsample': 0.9948830575483186, 'colsample_bytree': 0.7813337482336993}.\n",
      "[I 2020-02-23 16:43:50,431] Finished trial#2 resulted in value: 1.0121127367019653. Current best value is 0.003139552427455783 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.010676140508226309, 'alpha': 7.6730547426007245, 'lambda': 0.26342508503760165, 'gamma': 0.16128207492657728, 'max_depth': 77, 'max_leaves': 1442, 'subsample': 0.9948830575483186, 'colsample_bytree': 0.7813337482336993}.\n",
      "[I 2020-02-23 18:02:16,604] Finished trial#3 resulted in value: 0.589996337890625. Current best value is 0.003139552427455783 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.010676140508226309, 'alpha': 7.6730547426007245, 'lambda': 0.26342508503760165, 'gamma': 0.16128207492657728, 'max_depth': 77, 'max_leaves': 1442, 'subsample': 0.9948830575483186, 'colsample_bytree': 0.7813337482336993}.\n",
      "[I 2020-02-23 19:30:45,653] Finished trial#4 resulted in value: 0.0021906262263655663. Current best value is 0.0021906262263655663 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.01923549904711526, 'alpha': 0.1018002537705981, 'lambda': 0.07109124032962286, 'gamma': 0.0005227032677978012, 'max_depth': 31, 'max_leaves': 697, 'subsample': 0.9136901197365177, 'colsample_bytree': 0.9069341711179606}.\n",
      "[I 2020-02-23 20:51:04,223] Finished trial#5 resulted in value: 0.0039164284244179726. Current best value is 0.0021906262263655663 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.01923549904711526, 'alpha': 0.1018002537705981, 'lambda': 0.07109124032962286, 'gamma': 0.0005227032677978012, 'max_depth': 31, 'max_leaves': 697, 'subsample': 0.9136901197365177, 'colsample_bytree': 0.9069341711179606}.\n",
      "[I 2020-02-23 22:21:35,268] Finished trial#6 resulted in value: 0.19638270139694214. Current best value is 0.0021906262263655663 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.01923549904711526, 'alpha': 0.1018002537705981, 'lambda': 0.07109124032962286, 'gamma': 0.0005227032677978012, 'max_depth': 31, 'max_leaves': 697, 'subsample': 0.9136901197365177, 'colsample_bytree': 0.9069341711179606}.\n",
      "[I 2020-02-24 00:05:01,542] Finished trial#7 resulted in value: 0.042506780475378036. Current best value is 0.0021906262263655663 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.01923549904711526, 'alpha': 0.1018002537705981, 'lambda': 0.07109124032962286, 'gamma': 0.0005227032677978012, 'max_depth': 31, 'max_leaves': 697, 'subsample': 0.9136901197365177, 'colsample_bytree': 0.9069341711179606}.\n",
      "[I 2020-02-24 04:00:29,008] Finished trial#8 resulted in value: 0.002571755787357688. Current best value is 0.0021906262263655663 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.01923549904711526, 'alpha': 0.1018002537705981, 'lambda': 0.07109124032962286, 'gamma': 0.0005227032677978012, 'max_depth': 31, 'max_leaves': 697, 'subsample': 0.9136901197365177, 'colsample_bytree': 0.9069341711179606}.\n",
      "[I 2020-02-24 04:29:21,187] Finished trial#9 resulted in value: 0.003922561649233103. Current best value is 0.0021906262263655663 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.01923549904711526, 'alpha': 0.1018002537705981, 'lambda': 0.07109124032962286, 'gamma': 0.0005227032677978012, 'max_depth': 31, 'max_leaves': 697, 'subsample': 0.9136901197365177, 'colsample_bytree': 0.9069341711179606}.\n",
      "[I 2020-02-24 04:35:49,452] Finished trial#10 resulted in value: 0.02013256587088108. Current best value is 0.0021906262263655663 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.01923549904711526, 'alpha': 0.1018002537705981, 'lambda': 0.07109124032962286, 'gamma': 0.0005227032677978012, 'max_depth': 31, 'max_leaves': 697, 'subsample': 0.9136901197365177, 'colsample_bytree': 0.9069341711179606}.\n",
      "[I 2020-02-24 07:15:31,084] Finished trial#11 resulted in value: 0.00219178618863225. Current best value is 0.0021906262263655663 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.01923549904711526, 'alpha': 0.1018002537705981, 'lambda': 0.07109124032962286, 'gamma': 0.0005227032677978012, 'max_depth': 31, 'max_leaves': 697, 'subsample': 0.9136901197365177, 'colsample_bytree': 0.9069341711179606}.\n",
      "[I 2020-02-24 09:02:59,230] Finished trial#12 resulted in value: 0.0022509098052978516. Current best value is 0.0021906262263655663 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.01923549904711526, 'alpha': 0.1018002537705981, 'lambda': 0.07109124032962286, 'gamma': 0.0005227032677978012, 'max_depth': 31, 'max_leaves': 697, 'subsample': 0.9136901197365177, 'colsample_bytree': 0.9069341711179606}.\n",
      "[I 2020-02-24 10:07:03,791] Finished trial#13 resulted in value: 0.003523538587614894. Current best value is 0.0021906262263655663 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.01923549904711526, 'alpha': 0.1018002537705981, 'lambda': 0.07109124032962286, 'gamma': 0.0005227032677978012, 'max_depth': 31, 'max_leaves': 697, 'subsample': 0.9136901197365177, 'colsample_bytree': 0.9069341711179606}.\n",
      "[I 2020-02-24 10:16:40,063] Finished trial#14 resulted in value: 0.015982912853360176. Current best value is 0.0021906262263655663 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.01923549904711526, 'alpha': 0.1018002537705981, 'lambda': 0.07109124032962286, 'gamma': 0.0005227032677978012, 'max_depth': 31, 'max_leaves': 697, 'subsample': 0.9136901197365177, 'colsample_bytree': 0.9069341711179606}.\n",
      "[I 2020-02-24 12:37:36,643] Finished trial#15 resulted in value: 0.002588067203760147. Current best value is 0.0021906262263655663 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.01923549904711526, 'alpha': 0.1018002537705981, 'lambda': 0.07109124032962286, 'gamma': 0.0005227032677978012, 'max_depth': 31, 'max_leaves': 697, 'subsample': 0.9136901197365177, 'colsample_bytree': 0.9069341711179606}.\n",
      "[I 2020-02-24 13:21:59,738] Finished trial#16 resulted in value: 0.0030491792131215334. Current best value is 0.0021906262263655663 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.01923549904711526, 'alpha': 0.1018002537705981, 'lambda': 0.07109124032962286, 'gamma': 0.0005227032677978012, 'max_depth': 31, 'max_leaves': 697, 'subsample': 0.9136901197365177, 'colsample_bytree': 0.9069341711179606}.\n",
      "[I 2020-02-24 14:53:23,306] Finished trial#17 resulted in value: 0.002259443514049053. Current best value is 0.0021906262263655663 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.01923549904711526, 'alpha': 0.1018002537705981, 'lambda': 0.07109124032962286, 'gamma': 0.0005227032677978012, 'max_depth': 31, 'max_leaves': 697, 'subsample': 0.9136901197365177, 'colsample_bytree': 0.9069341711179606}.\n",
      "[I 2020-02-24 15:30:15,488] Finished trial#18 resulted in value: 0.010032287798821926. Current best value is 0.0021906262263655663 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.01923549904711526, 'alpha': 0.1018002537705981, 'lambda': 0.07109124032962286, 'gamma': 0.0005227032677978012, 'max_depth': 31, 'max_leaves': 697, 'subsample': 0.9136901197365177, 'colsample_bytree': 0.9069341711179606}.\n",
      "[I 2020-02-24 19:43:25,910] Finished trial#19 resulted in value: 0.00602253433316946. Current best value is 0.0021906262263655663 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.01923549904711526, 'alpha': 0.1018002537705981, 'lambda': 0.07109124032962286, 'gamma': 0.0005227032677978012, 'max_depth': 31, 'max_leaves': 697, 'subsample': 0.9136901197365177, 'colsample_bytree': 0.9069341711179606}.\n",
      "[I 2020-02-24 21:36:28,907] Finished trial#20 resulted in value: 0.00226376811042428. Current best value is 0.0021906262263655663 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.01923549904711526, 'alpha': 0.1018002537705981, 'lambda': 0.07109124032962286, 'gamma': 0.0005227032677978012, 'max_depth': 31, 'max_leaves': 697, 'subsample': 0.9136901197365177, 'colsample_bytree': 0.9069341711179606}.\n",
      "[I 2020-02-24 23:09:01,068] Finished trial#21 resulted in value: 0.0021999296732246876. Current best value is 0.0021906262263655663 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.01923549904711526, 'alpha': 0.1018002537705981, 'lambda': 0.07109124032962286, 'gamma': 0.0005227032677978012, 'max_depth': 31, 'max_leaves': 697, 'subsample': 0.9136901197365177, 'colsample_bytree': 0.9069341711179606}.\n",
      "[I 2020-02-25 00:21:53,995] Finished trial#22 resulted in value: 0.002114127157256007. Current best value is 0.002114127157256007 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.010975451868313961, 'alpha': 0.012528312529165489, 'lambda': 0.00010012399459659736, 'gamma': 0.0005632756018115597, 'max_depth': 23, 'max_leaves': 1733, 'subsample': 0.8743982345827248, 'colsample_bytree': 0.9559994294130508}.\n",
      "[I 2020-02-25 00:42:58,695] Finished trial#23 resulted in value: 0.011330334469676018. Current best value is 0.002114127157256007 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.010975451868313961, 'alpha': 0.012528312529165489, 'lambda': 0.00010012399459659736, 'gamma': 0.0005632756018115597, 'max_depth': 23, 'max_leaves': 1733, 'subsample': 0.8743982345827248, 'colsample_bytree': 0.9559994294130508}.\n",
      "[I 2020-02-25 01:55:47,429] Finished trial#24 resulted in value: 0.002366458298638463. Current best value is 0.002114127157256007 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.010975451868313961, 'alpha': 0.012528312529165489, 'lambda': 0.00010012399459659736, 'gamma': 0.0005632756018115597, 'max_depth': 23, 'max_leaves': 1733, 'subsample': 0.8743982345827248, 'colsample_bytree': 0.9559994294130508}.\n",
      "[I 2020-02-25 03:52:29,582] Finished trial#25 resulted in value: 0.059334054589271545. Current best value is 0.002114127157256007 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.010975451868313961, 'alpha': 0.012528312529165489, 'lambda': 0.00010012399459659736, 'gamma': 0.0005632756018115597, 'max_depth': 23, 'max_leaves': 1733, 'subsample': 0.8743982345827248, 'colsample_bytree': 0.9559994294130508}.\n",
      "[I 2020-02-25 05:21:34,243] Finished trial#26 resulted in value: 0.0022468571551144123. Current best value is 0.002114127157256007 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.010975451868313961, 'alpha': 0.012528312529165489, 'lambda': 0.00010012399459659736, 'gamma': 0.0005632756018115597, 'max_depth': 23, 'max_leaves': 1733, 'subsample': 0.8743982345827248, 'colsample_bytree': 0.9559994294130508}.\n",
      "[I 2020-02-25 06:23:41,982] Finished trial#27 resulted in value: 0.0021142135374248028. Current best value is 0.002114127157256007 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.010975451868313961, 'alpha': 0.012528312529165489, 'lambda': 0.00010012399459659736, 'gamma': 0.0005632756018115597, 'max_depth': 23, 'max_leaves': 1733, 'subsample': 0.8743982345827248, 'colsample_bytree': 0.9559994294130508}.\n",
      "[I 2020-02-25 06:41:58,702] Finished trial#28 resulted in value: 0.010229770094156265. Current best value is 0.002114127157256007 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.010975451868313961, 'alpha': 0.012528312529165489, 'lambda': 0.00010012399459659736, 'gamma': 0.0005632756018115597, 'max_depth': 23, 'max_leaves': 1733, 'subsample': 0.8743982345827248, 'colsample_bytree': 0.9559994294130508}.\n",
      "[I 2020-02-25 09:12:36,377] Finished trial#29 resulted in value: 0.0031233076006174088. Current best value is 0.002114127157256007 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.010975451868313961, 'alpha': 0.012528312529165489, 'lambda': 0.00010012399459659736, 'gamma': 0.0005632756018115597, 'max_depth': 23, 'max_leaves': 1733, 'subsample': 0.8743982345827248, 'colsample_bytree': 0.9559994294130508}.\n",
      "[I 2020-02-25 10:00:23,158] Finished trial#30 resulted in value: 0.0022654933854937553. Current best value is 0.002114127157256007 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.010975451868313961, 'alpha': 0.012528312529165489, 'lambda': 0.00010012399459659736, 'gamma': 0.0005632756018115597, 'max_depth': 23, 'max_leaves': 1733, 'subsample': 0.8743982345827248, 'colsample_bytree': 0.9559994294130508}.\n",
      "[I 2020-02-25 13:26:25,587] Finished trial#31 resulted in value: 0.0022064796648919582. Current best value is 0.002114127157256007 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.010975451868313961, 'alpha': 0.012528312529165489, 'lambda': 0.00010012399459659736, 'gamma': 0.0005632756018115597, 'max_depth': 23, 'max_leaves': 1733, 'subsample': 0.8743982345827248, 'colsample_bytree': 0.9559994294130508}.\n",
      "[I 2020-02-25 13:52:19,312] Finished trial#32 resulted in value: 0.005549949128180742. Current best value is 0.002114127157256007 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.010975451868313961, 'alpha': 0.012528312529165489, 'lambda': 0.00010012399459659736, 'gamma': 0.0005632756018115597, 'max_depth': 23, 'max_leaves': 1733, 'subsample': 0.8743982345827248, 'colsample_bytree': 0.9559994294130508}.\n",
      "[I 2020-02-25 18:20:52,193] Finished trial#33 resulted in value: 0.011785007081925869. Current best value is 0.002114127157256007 with parameters: {'grow_policy': 'depthwise', 'learning_rate': 0.010975451868313961, 'alpha': 0.012528312529165489, 'lambda': 0.00010012399459659736, 'gamma': 0.0005632756018115597, 'max_depth': 23, 'max_leaves': 1733, 'subsample': 0.8743982345827248, 'colsample_bytree': 0.9559994294130508}.\n",
      "[I 2020-02-25 19:28:38,138] Finished trial#34 resulted in value: 0.0020912776235491037. Current best value is 0.0020912776235491037 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.014754037383886122, 'alpha': 0.005261717289274988, 'lambda': 0.10981652452119427, 'gamma': 0.00015007710756172543, 'max_depth': 23, 'max_leaves': 1598, 'subsample': 0.8406224713599797, 'colsample_bytree': 0.9175035245877109}.\n",
      "[I 2020-02-25 20:28:18,456] Finished trial#35 resulted in value: 0.0021427415776997805. Current best value is 0.0020912776235491037 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.014754037383886122, 'alpha': 0.005261717289274988, 'lambda': 0.10981652452119427, 'gamma': 0.00015007710756172543, 'max_depth': 23, 'max_leaves': 1598, 'subsample': 0.8406224713599797, 'colsample_bytree': 0.9175035245877109}.\n",
      "[I 2020-02-25 21:27:07,922] Finished trial#36 resulted in value: 0.0021336975041776896. Current best value is 0.0020912776235491037 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.014754037383886122, 'alpha': 0.005261717289274988, 'lambda': 0.10981652452119427, 'gamma': 0.00015007710756172543, 'max_depth': 23, 'max_leaves': 1598, 'subsample': 0.8406224713599797, 'colsample_bytree': 0.9175035245877109}.\n",
      "[I 2020-02-25 21:41:58,452] Finished trial#37 resulted in value: 0.011947489343583584. Current best value is 0.0020912776235491037 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.014754037383886122, 'alpha': 0.005261717289274988, 'lambda': 0.10981652452119427, 'gamma': 0.00015007710756172543, 'max_depth': 23, 'max_leaves': 1598, 'subsample': 0.8406224713599797, 'colsample_bytree': 0.9175035245877109}.\n",
      "[I 2020-02-25 22:06:27,355] Finished trial#38 resulted in value: 0.004990720190107822. Current best value is 0.0020912776235491037 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.014754037383886122, 'alpha': 0.005261717289274988, 'lambda': 0.10981652452119427, 'gamma': 0.00015007710756172543, 'max_depth': 23, 'max_leaves': 1598, 'subsample': 0.8406224713599797, 'colsample_bytree': 0.9175035245877109}.\n",
      "[I 2020-02-25 23:13:28,515] Finished trial#39 resulted in value: 0.0027108369395136833. Current best value is 0.0020912776235491037 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.014754037383886122, 'alpha': 0.005261717289274988, 'lambda': 0.10981652452119427, 'gamma': 0.00015007710756172543, 'max_depth': 23, 'max_leaves': 1598, 'subsample': 0.8406224713599797, 'colsample_bytree': 0.9175035245877109}.\n",
      "[I 2020-02-25 23:17:58,753] Finished trial#40 resulted in value: 0.05181986838579178. Current best value is 0.0020912776235491037 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.014754037383886122, 'alpha': 0.005261717289274988, 'lambda': 0.10981652452119427, 'gamma': 0.00015007710756172543, 'max_depth': 23, 'max_leaves': 1598, 'subsample': 0.8406224713599797, 'colsample_bytree': 0.9175035245877109}.\n",
      "[I 2020-02-25 23:59:33,710] Finished trial#41 resulted in value: 0.0022704703733325005. Current best value is 0.0020912776235491037 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.014754037383886122, 'alpha': 0.005261717289274988, 'lambda': 0.10981652452119427, 'gamma': 0.00015007710756172543, 'max_depth': 23, 'max_leaves': 1598, 'subsample': 0.8406224713599797, 'colsample_bytree': 0.9175035245877109}.\n",
      "[I 2020-02-26 00:58:24,920] Finished trial#42 resulted in value: 0.002172107109799981. Current best value is 0.0020912776235491037 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.014754037383886122, 'alpha': 0.005261717289274988, 'lambda': 0.10981652452119427, 'gamma': 0.00015007710756172543, 'max_depth': 23, 'max_leaves': 1598, 'subsample': 0.8406224713599797, 'colsample_bytree': 0.9175035245877109}.\n",
      "[I 2020-02-26 03:48:12,825] Finished trial#43 resulted in value: 0.0022567708510905504. Current best value is 0.0020912776235491037 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.014754037383886122, 'alpha': 0.005261717289274988, 'lambda': 0.10981652452119427, 'gamma': 0.00015007710756172543, 'max_depth': 23, 'max_leaves': 1598, 'subsample': 0.8406224713599797, 'colsample_bytree': 0.9175035245877109}.\n",
      "[I 2020-02-26 05:09:05,042] Finished trial#44 resulted in value: 0.002404839266091585. Current best value is 0.0020912776235491037 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.014754037383886122, 'alpha': 0.005261717289274988, 'lambda': 0.10981652452119427, 'gamma': 0.00015007710756172543, 'max_depth': 23, 'max_leaves': 1598, 'subsample': 0.8406224713599797, 'colsample_bytree': 0.9175035245877109}.\n",
      "[I 2020-02-26 05:59:54,190] Finished trial#45 resulted in value: 0.842746376991272. Current best value is 0.0020912776235491037 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.014754037383886122, 'alpha': 0.005261717289274988, 'lambda': 0.10981652452119427, 'gamma': 0.00015007710756172543, 'max_depth': 23, 'max_leaves': 1598, 'subsample': 0.8406224713599797, 'colsample_bytree': 0.9175035245877109}.\n",
      "[I 2020-02-26 06:41:05,227] Finished trial#46 resulted in value: 0.002345948712900281. Current best value is 0.0020912776235491037 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.014754037383886122, 'alpha': 0.005261717289274988, 'lambda': 0.10981652452119427, 'gamma': 0.00015007710756172543, 'max_depth': 23, 'max_leaves': 1598, 'subsample': 0.8406224713599797, 'colsample_bytree': 0.9175035245877109}.\n",
      "[I 2020-02-26 09:36:23,687] Finished trial#47 resulted in value: 0.0033433642238378525. Current best value is 0.0020912776235491037 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.014754037383886122, 'alpha': 0.005261717289274988, 'lambda': 0.10981652452119427, 'gamma': 0.00015007710756172543, 'max_depth': 23, 'max_leaves': 1598, 'subsample': 0.8406224713599797, 'colsample_bytree': 0.9175035245877109}.\n",
      "[I 2020-02-26 13:31:45,761] Finished trial#48 resulted in value: 0.0021586348302662373. Current best value is 0.0020912776235491037 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.014754037383886122, 'alpha': 0.005261717289274988, 'lambda': 0.10981652452119427, 'gamma': 0.00015007710756172543, 'max_depth': 23, 'max_leaves': 1598, 'subsample': 0.8406224713599797, 'colsample_bytree': 0.9175035245877109}.\n",
      "[I 2020-02-26 15:52:59,265] Finished trial#49 resulted in value: 0.00836394727230072. Current best value is 0.0020912776235491037 with parameters: {'grow_policy': 'lossguide', 'learning_rate': 0.014754037383886122, 'alpha': 0.005261717289274988, 'lambda': 0.10981652452119427, 'gamma': 0.00015007710756172543, 'max_depth': 23, 'max_leaves': 1598, 'subsample': 0.8406224713599797, 'colsample_bytree': 0.9175035245877109}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End: 2020-02-26 15:52:59.271846\n",
      "Finished trials: 50\n",
      "Best trial: 0.0020912776235491037\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_trial_xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-5e1e8c17e602>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Finished trials: {len(study_xgb.trials)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Best trial: {study_xgb.best_trial.value}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mbest_trial_xgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_trial_xgb' is not defined"
     ]
    }
   ],
   "source": [
    "# print(f'Start: {datetime.datetime.now()}')\n",
    "\n",
    "# # Optimize parameters\n",
    "# study_xgb = optuna.create_study(direction='minimize')\n",
    "# study_xgb.optimize(objective_xgb, n_trials=50)\n",
    "\n",
    "# print(f'End: {datetime.datetime.now()}')\n",
    "\n",
    "# print(f'Finished trials: {len(study_xgb.trials)}')\n",
    "# print(f'Best trial: {study_xgb.best_trial.value}')\n",
    "# study_xgb.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study results\n",
    "study_xgb = joblib.load('../objects/electricity/study_xgb.pkl')\n",
    "print(f'Finished trials: {len(study_xgb.trials)}')\n",
    "print(f'Best trial: {study_xgb.best_trial.value}')\n",
    "study_xgb.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost datasets for validation\n",
    "edtrain = xgb.DMatrix(Xe_train_scaled, label=ye_train)\n",
    "edval = xgb.DMatrix(Xe_val_scaled, label=ye_val)\n",
    "edtest = xgb.DMatrix(Xe_test_scaled, label=ye_test)\n",
    "\n",
    "# Parameters from Optuna\n",
    "params_xgb = dict(study_xgb.best_trial.params)\n",
    "params_xgb['eval_metric'] = 'rmse'\n",
    "params_xgb['seed'] = 42\n",
    "\n",
    "# Train data\n",
    "xg = xgb.train(params_xgb, edtrain, \n",
    "               evals=[(edtrain, 'train'), (edval, 'valid')], \n",
    "               num_boost_round=1000,\n",
    "               early_stopping_rounds=10,\n",
    "               verbose_eval=False)\n",
    "xg.save_model('../objects/electricity/xg.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set RMSLE\n",
    "pred_train = xg.predict(edtrain)\n",
    "pred_train[pred_train < 0] = 0\n",
    "rmsle_train = np.sqrt(mean_squared_log_error(ye_train, pred_train))\n",
    "print('Train RMSLE:', rmsle_train)\n",
    "\n",
    "# Validation set RMSLE\n",
    "pred_val = xg.predict(edval)\n",
    "pred_val[pred_val < 0] = 0\n",
    "rmsle_val = np.sqrt(mean_squared_log_error(ye_val, pred_val))\n",
    "print('Validation RMSLE:', rmsle_val)\n",
    "\n",
    "# Test set RMSLE\n",
    "pred_test = xg.predict(edtest)\n",
    "pred_test[pred_test < 0] = 0\n",
    "rmsle_test = np.sqrt(mean_squared_log_error(ye_test, pred_test))\n",
    "print('Test RMSLE:', rmsle_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del edtrain, edval, edtest, pred_train, rmsle_train, pred_val, rmsle_val, pred_test, rmsle_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:minds] *",
   "language": "python",
   "name": "conda-env-minds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
