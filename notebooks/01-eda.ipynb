{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Energy Predictor - Exploratory Data Analysis\n",
    "#### Hosted by: ASHRAE\n",
    "##### Source: https://www.kaggle.com/c/ashrae-energy-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import zipfile\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import src.utils as udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "sns.set(rc={'figure.figsize': (16, 4),\n",
    "            'font.size': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory\n",
    "data_path = '../data/'\n",
    "udf.mkdir(data_path)\n",
    "\n",
    "# Create subdirectory for raw data\n",
    "data_path += 'raw/'\n",
    "udf.mkdir(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data from Kaggle\n",
    "\n",
    "##### Download manually\n",
    "1. Create a Kaggle account [here](https://www.kaggle.com/account/login?phase=startRegisterTab&returnUrl=%2F)\n",
    "2. Download the data manually [here](https://www.kaggle.com/c/ashrae-energy-prediction/data)\n",
    "3. Unzip the .zip file and move all extracted files into the `data/raw/` directory created in the code cell above\n",
    "\n",
    "##### Download programatically\n",
    "1. Create a Kaggle account [here](https://www.kaggle.com/account/login?phase=startRegisterTab&returnUrl=%2F)\n",
    "2. Navigate to `Account` in the menu and scroll down to `API`\n",
    "3. Click `Create New API Token` - this downloads a json file called `kaggle.json` that contains the API credentials\n",
    "4. If Kaggle API is not already installed, use `pip install kaggle` or `conda install kaggle` in the terminal\n",
    "5. Uncomment and run the code cell below (may take a while to run)\n",
    "\n",
    "Source: https://github.com/Kaggle/kaggle-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Move Kaggle credentials into ~/.kaggle/\n",
    "# !mv ~/Downloads/kaggle.json ~/.kaggle/kaggle.json\n",
    "\n",
    "# # Remove read permission for other users\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# # Download zipped data from Kaggle\n",
    "# !kaggle competitions download -c ashrae-energy-prediction\n",
    "# zip_file = 'ashrae-energy-prediction.zip'\n",
    "\n",
    "# # Unzip the data into the raw data directory\n",
    "# with zipfile.ZipFile(zip_file, 'r') as f:\n",
    "#     f.extractall(data_path)\n",
    "    \n",
    "# # Delete zip file\n",
    "# !rm $zip_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20216100 entries, 0 to 20216099\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   building_id    int64         \n",
      " 1   meter          int64         \n",
      " 2   timestamp      datetime64[ns]\n",
      " 3   meter_reading  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2)\n",
      "memory usage: 616.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Meter data\n",
    "meter = pd.read_csv(data_path + 'train.csv', parse_dates=['timestamp'])\n",
    "meter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20216100 entries, 0 to 20216099\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   building_id    uint16        \n",
      " 1   meter          uint8         \n",
      " 2   timestamp      datetime64[ns]\n",
      " 3   meter_reading  float32       \n",
      "dtypes: datetime64[ns](1), float32(1), uint16(1), uint8(1)\n",
      "memory usage: 289.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Reduce memory in meter data\n",
    "meter = udf.reduce_mem_usage(meter)\n",
    "meter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 139773 entries, 0 to 139772\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   site_id             139773 non-null  int64         \n",
      " 1   timestamp           139773 non-null  datetime64[ns]\n",
      " 2   air_temperature     139718 non-null  float64       \n",
      " 3   cloud_coverage      70600 non-null   float64       \n",
      " 4   dew_temperature     139660 non-null  float64       \n",
      " 5   precip_depth_1_hr   89484 non-null   float64       \n",
      " 6   sea_level_pressure  129155 non-null  float64       \n",
      " 7   wind_direction      133505 non-null  float64       \n",
      " 8   wind_speed          139469 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(7), int64(1)\n",
      "memory usage: 9.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Weather data\n",
    "weather = pd.read_csv(data_path + 'weather_train.csv', parse_dates=['timestamp'])\n",
    "weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 139773 entries, 0 to 139772\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   site_id             139773 non-null  uint8         \n",
      " 1   timestamp           139773 non-null  datetime64[ns]\n",
      " 2   air_temperature     139718 non-null  float32       \n",
      " 3   cloud_coverage      70600 non-null   float32       \n",
      " 4   dew_temperature     139660 non-null  float32       \n",
      " 5   precip_depth_1_hr   89484 non-null   float32       \n",
      " 6   sea_level_pressure  129155 non-null  float32       \n",
      " 7   wind_direction      133505 non-null  float32       \n",
      " 8   wind_speed          139469 non-null  float32       \n",
      "dtypes: datetime64[ns](1), float32(7), uint8(1)\n",
      "memory usage: 4.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Reduce memory in weather data\n",
    "weather = udf.reduce_mem_usage(weather)\n",
    "weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1449 entries, 0 to 1448\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   site_id      1449 non-null   int64  \n",
      " 1   building_id  1449 non-null   int64  \n",
      " 2   primary_use  1449 non-null   object \n",
      " 3   square_feet  1449 non-null   int64  \n",
      " 4   year_built   675 non-null    float64\n",
      " 5   floor_count  355 non-null    float64\n",
      "dtypes: float64(2), int64(3), object(1)\n",
      "memory usage: 68.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Building data\n",
    "building = pd.read_csv(data_path + 'building_metadata.csv')\n",
    "building.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1449 entries, 0 to 1448\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   site_id      1449 non-null   uint8  \n",
      " 1   building_id  1449 non-null   uint16 \n",
      " 2   primary_use  1449 non-null   object \n",
      " 3   square_feet  1449 non-null   uint32 \n",
      " 4   year_built   675 non-null    float32\n",
      " 5   floor_count  355 non-null    float32\n",
      "dtypes: float32(2), object(1), uint16(1), uint32(1), uint8(1)\n",
      "memory usage: 32.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Reduce memory in building data\n",
    "building = udf.reduce_mem_usage(building)\n",
    "building.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'zip_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f59b7c120520>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'zip_file' is not defined"
     ]
    }
   ],
   "source": [
    "del data_path, zip_file\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert units for site 0 meter types 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add site column to meter dataframe\n",
    "meter = pd.merge(meter, building[['site_id', 'building_id']], on='building_id', how='left')\n",
    "\n",
    "# Positive electric readings in site 0 (in kBTU)\n",
    "meter[(meter.site_id == 0) & (meter.meter == 0) & (meter.meter_reading > 0)].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert site 0 electric readings to kWh: 1 kBTU * 0.2931 = 1kWh\n",
    "meter = udf.convert_readings(meter, site_num=0, meter_num=0, convert_from='kbtu', convert_to='kwh')\n",
    "meter[(meter.site_id == 0) & (meter.meter == 0) & (meter.meter_reading > 0)].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chilled water readings in site 0 (in kBTU)\n",
    "meter[(meter.site_id == 0) & (meter.meter == 1)].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert site 0 chilled water readings to tons: 1 kBTU/hr * 0.0833 = 1 ton (refridgeration)\n",
    "meter = udf.convert_readings(meter, site_num=0, meter_num=1, convert_from='kbtu', convert_to='ton')\n",
    "meter[(meter.site_id == 0) & (meter.meter == 1)].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicated observations and missing values in meter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicated observations\n",
    "meter.duplicated(subset=['building_id', 'meter', 'timestamp']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "meter.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing timestamps\n",
    "timestamp_count = meter.groupby(['building_id', 'meter']).count()\n",
    "n_meters = timestamp_count.shape[0] # number of different meters in the dataset\n",
    "n_timestamps = 366 * 24 # every meter should have this many readings\n",
    "(n_meters * n_timestamps) - meter.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf.print_missing_readings(meter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore meter readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of meter readings less than or equal to 1000\n",
    "meter_lte1000 = meter[(meter.meter_reading > 0) & (meter.meter_reading <= 1000)]\n",
    "meter_lte1000.meter_reading.plot(kind='hist', bins=40)\n",
    "plt.autoscale(enable=True, axis='x', tight=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check high meter readings\n",
    "high_readings = meter[meter.meter_reading >= 1e6]\n",
    "print(high_readings.shape[0])\n",
    "high_readings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check buildings and meters with high readings\n",
    "print('Buildings:', high_readings.building_id.unique())\n",
    "print('Meters:', high_readings.meter.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check building 1099 meter 2\n",
    "b1099m2 = meter[(meter.building_id == 1099) & (meter.meter == 2)].set_index('timestamp')\n",
    "b1099m2.meter_reading.plot(title='Building 1099 Meter 2 (Steam) Readings')\n",
    "plt.ylabel('meter_reading')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See readings less than or equal to 100,000\n",
    "b1099m2_lte100k = b1099m2[b1099m2.meter_reading <= 1e5].meter_reading\n",
    "b1099m2_lte100k.plot(title='Building 1099 Meter 2 (Steam) Readings Less Than 100k')\n",
    "plt.ylabel('meter_reading')\n",
    "plt.autoscale(enable=True, axis='x', tight=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier meter readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set outlier threshold\n",
    "lower, upper = udf.get_outlier_threshold(meter, 'meter_reading', stat='iqr', multiplier=50)\n",
    "lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier count based on threshold\n",
    "outliers = meter[meter.meter_reading > upper].shape[0]\n",
    "print(f'{outliers} outliers ({round(outliers * 100 / meter.shape[0], 2)}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "meter = meter[meter.meter_reading <= upper]\n",
    "meter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del timestamp_count, n_meters, n_timestamps, meter_lte1000, b1099m2, b1099m2_lte100k, \\\n",
    "    high_readings, lower, upper, outliers\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add meter type string in a new column\n",
    "meter_types = {0: 'electricity', 1: 'chilledwater', 2: 'steam', 3: 'hotwater'}\n",
    "meter['meter_type'] = meter.meter.map(meter_types)\n",
    "\n",
    "# How many buildings have a certain meter?\n",
    "meter_type_count = meter.groupby('meter_type').building_id.nunique().sort_values()\n",
    "meter_type_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of buildings with each meter type\n",
    "meter_type_count.plot.barh(title='Number of Buildings with Each Meter Type')\n",
    "plt.ylabel('Meter')\n",
    "plt.xlabel('Number of buildings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many buildings have a certain number of meters?\n",
    "meter_count = meter.groupby('building_id').meter.nunique().value_counts().sort_values()\n",
    "meter_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of buildings with n meters\n",
    "meter_count.plot.barh(title='Number of Buildings with n Meters')\n",
    "plt.ylabel('Number of meters in the building (n)')\n",
    "plt.xlabel('Number of buildings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of meter readings from each building\n",
    "meter.groupby('building_id').timestamp.count().plot(title='Number of Meter Readings from Each Building')\n",
    "plt.ylabel('Number of meter readings')\n",
    "plt.autoscale(enable=True, axis='x', tight=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample meter readings from each meter type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meter readings from each meter type\n",
    "meter_groups = [meter[meter.meter == m].building_id.unique() for m in range(4)]\n",
    "udf.plot_readings(meter, meter_groups, resample='d', start=25, end=26)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time components from timestamp\n",
    "time_comps = ['dayofyear', 'month', 'day', 'dayofweek', 'hour']\n",
    "meter = udf.extract_dt_components(meter, time_comps)\n",
    "meter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meter readings by weekday\n",
    "udf.plot_readings(meter, meter_groups, groupby=['dayofweek', 'hour'],\n",
    "                  start=50, end=51, ticks=range(0, 7 * 24, 12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meter readings by hour\n",
    "udf.plot_readings(meter, meter_groups, groupby=['hour'], start=75, end=76, ticks=range(24))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly average meter readings of each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Electric meters only\n",
    "e_meter = meter[meter.meter == 0]\n",
    "\n",
    "# Electric meter readings by site (readings from site 7 are on a greater scale)\n",
    "udf.pivot_elec_readings(e_meter, pivot_col='site_id', freq='m', cols_to_sep=[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del meter_types, meter_type_count, meter_count, meter_groups, time_comps, e_meter\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicated observations and missing values in weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicated observations\n",
    "weather.duplicated(subset=['site_id', 'timestamp']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing timestamps\n",
    "(16 * 366 * 24) - weather.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value distributions\n",
    "udf.hist_subplots(weather, range(2, 9))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily weather in site 4\n",
    "weather4 = udf.get_site(weather, 4, time_idx=True).resample('d').mean()\n",
    "weather4.plot(subplots=True, figsize=(16, 28))\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hour from timestamp\n",
    "weather = udf.extract_dt_components(weather, ['hour'])\n",
    "\n",
    "# Site 8 hourly weather\n",
    "weather8 = udf.get_site(weather, 8).groupby('hour').mean()\n",
    "weather8.plot(subplots=True, figsize=(16, 28))\n",
    "plt.xlim(0, 23)\n",
    "plt.xticks(range(24), rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly temperature from all sites\n",
    "airtemp = pd.pivot_table(weather, index='hour', columns='site_id', values='air_temperature', aggfunc='mean')\n",
    "airtemp.plot(figsize=(16, 6), xticks=range(24), title='Hourly air temperature by site')\n",
    "plt.ylabel('air temperature')\n",
    "plt.xlim(0, 23)\n",
    "plt.legend(bbox_to_anchor=(1, 1), fancybox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert UTC to local time\n",
    "\n",
    "Sites:\n",
    "- 0 - Orlando, Florida (GMT-5)\n",
    "- 1 - United Kingdom (GMT+0)\n",
    "- 2 - Arizona (GMT-7)\n",
    "- 3 - U.S. Eastern Time Zone (GMT-5)\n",
    "- 4 - Northern California (GMT-8)\n",
    "- 5 - United Kingdom (GMT+0)\n",
    "- 6 - U.S. Eastern Time Zone (GMT-5)\n",
    "- 7 - Southeastern Canada (GMT-5)\n",
    "- 8 - Orlando, Florida (GMT-5)\n",
    "- 9 - Texas (GMT-6)\n",
    "- 10 - U.S. Mountain Time Zone (GMT-7)\n",
    "- 11 - Southeastern Canada (GMT-5)\n",
    "- 12 - Dublin, Ireland (GMT+0)\n",
    "- 13 - Minnesota (GMT-6)\n",
    "- 14 - U.S. Eastern Time Zone (GMT-5)\n",
    "- 15 - U.S. Eastern Time Zone (GMT-5)\n",
    "\n",
    "Sources:\n",
    "- https://www.kaggle.com/c/ashrae-energy-prediction/discussion/115698\n",
    "- https://www.kaggle.com/patrick0302/locate-cities-according-weather-temperature\n",
    "- https://www.kaggle.com/datadugong/locate-better-cities-by-weather-temp-fill-nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offsets for timezones\n",
    "timezones = [-5, 0, -7, -5, -8, 0, -5, -5, -5, -6, -7, -5, 0, -6, -5, -5]\n",
    "\n",
    "# Convert UTC to local time\n",
    "weather = udf.to_local_time(weather, timezones)\n",
    "weather['hour'] = weather.timestamp.dt.hour\n",
    "\n",
    "# Hourly temperature from all sites\n",
    "airtemp = pd.pivot_table(weather, index='hour', columns='site_id', values='air_temperature', aggfunc='mean')\n",
    "airtemp.plot(figsize=(16, 6), xticks=range(24), title='Hourly air temperature by site')\n",
    "plt.ylabel('air temperature')\n",
    "plt.xlim(0, 23)\n",
    "plt.legend(bbox_to_anchor=(1, 1), fancybox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Air temperature by site\n",
    "sns.jointplot(data=weather, x='air_temperature', y='site_id')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del weather4, weather8, airtemp, timezones\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicated observations and missing values in building data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicated observations\n",
    "building.duplicated(subset=['building_id']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "building.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value distributions\n",
    "udf.hist_subplots(building, range(3, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of buildings in each site\n",
    "building.groupby('site_id').building_id.count().plot.bar(title='Number of buildings in each site')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average values by site\n",
    "bldg_avg_by_site = building.drop('building_id', axis=1).groupby('site_id').mean()\n",
    "bldg_avg_by_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average square footage and floor count by site\n",
    "plot_titles = ['Average %s in each site' % col for col in ['square feet', 'floor count']]\n",
    "bldg_avg_by_site.drop('year_built', axis=1).plot.bar(subplots=True, figsize=(16, 8), title=plot_titles,\n",
    "                                              legend=False, color=['r', 'g'])\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average year-built by site\n",
    "bldg_avg_by_site.year_built.plot.bar(title='Average year built of buildings in each site', ylim=(1900, 2000))\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of each type of building\n",
    "bldg_use_counts = building.groupby('primary_use').building_id.count().sort_values()\n",
    "bldg_use_counts.plot.barh(figsize=(16, 6), title='Number of each type of building')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of each type of building in each site\n",
    "bldg_use_by_site = pd.pivot_table(building, index='site_id', columns='primary_use', values='building_id',\n",
    "                           aggfunc='count', fill_value=0)\n",
    "bldg_use_by_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of each type of building in each site\n",
    "bldg_use_by_site.plot.bar(stacked=True, figsize=(16, 6), title='Number of each type of building in each site')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(bbox_to_anchor=(0.9, -0.15), ncol=4, fancybox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average values by primary use\n",
    "bldg_avg_by_use = building.drop(['site_id', 'building_id'], axis=1).groupby('primary_use').mean()\n",
    "bldg_avg_by_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subplot titles\n",
    "plot_titles = ['Average %s for each type' % col for col in ['square feet', 'floor count']]\n",
    "\n",
    "# Average square footage and floor count by primary use\n",
    "bldg_avg_by_use.drop('year_built', axis=1).plot.bar(subplots=True, figsize=(16, 8), title=plot_titles,\n",
    "                                             legend=False, color=['c', 'm'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average year-built by primary uuse\n",
    "bldg_avg_by_use.year_built.plot.bar(figsize=(16, 4), title='Average year built of buildings for each type',\n",
    "                             ylim=(1900, 2020), color='y')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bldg_avg_by_site, plot_titles, bldg_use_counts, bldg_use_by_site, bldg_avg_by_use\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new subdirectory in data directory\n",
    "output_path = '../data/from_eda/'\n",
    "udf.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save meter data\n",
    "meter.to_pickle(f'{output_path}meter.pkl')\n",
    "pd.read_pickle(f'{output_path}meter.pkl').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weather data\n",
    "weather.drop('hour', axis=1).to_pickle(f'{output_path}weather.pkl')\n",
    "pd.read_pickle(f'{output_path}weather.pkl').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save building data\n",
    "building.to_pickle(f'{output_path}building.pkl')\n",
    "pd.read_pickle(f'{output_path}building.pkl').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del output_path\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:minds] *",
   "language": "python",
   "name": "conda-env-minds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
